I"jƒ<p><strong>Trong trang nÃ y:</strong></p>

<!-- MarkdownTOC -->

<ul>
  <li><a href="#-gioi-thieu">1. Giá»›i thiá»‡u</a></li>
  <li><a href="#-mo-hinh-chung-cho-cac-bai-toan-machine-learning">2. MÃ´ hÃ¬nh chung cho cÃ¡c bÃ i toÃ¡n Machine Learning</a>
    <ul>
      <li><a href="#training-phase">TRAINING PHASE</a>
        <ul>
          <li><a href="#feature-extractor">Feature Extractor</a></li>
          <li><a href="#main-algorithms">Main Algorithms</a></li>
        </ul>
      </li>
      <li><a href="#testing-phase">TESTING PHASE</a></li>
    </ul>
  </li>
  <li><a href="#-mot-so-vi-du-ve-feature-engineering">3. Má»™t sá»‘ vÃ­ dá»¥ vá» Feature Engineering</a>
    <ul>
      <li><a href="#truc-tiep-lay-raw-data">Trá»±c tiáº¿p láº¥y raw data</a></li>
      <li><a href="#feature-selection">Feature selection</a></li>
      <li><a href="#dimensionality-reduction">Dimensionality reduction</a></li>
      <li><a href="#bag-of-words">Bag-of-words</a></li>
      <li><a href="#bag-of-words-trong-computer-vision">Bag-of-Words trong Computer Vision</a></li>
      <li><a href="#feature-scaling-and-normalization">Feature Scaling and Normalization</a>
        <ul>
          <li><a href="#rescaling">Rescaling</a></li>
          <li><a href="#standardization">Standardization</a></li>
          <li><a href="#scaling-to-unit-length">Scaling to unit length</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#-thao-luan">4. Tháº£o luáº­n</a></li>
  <li><a href="#-tai-lieu-tham-khao">5. TÃ i liá»‡u tham kháº£o</a></li>
</ul>

<!-- /MarkdownTOC -->

<p><a name="-gioi-thieu"></a></p>

<h2 id="1-giá»›i-thiá»‡u">1. Giá»›i thiá»‡u</h2>

<p>Cho tá»›i lÃºc nÃ y, tÃ´i Ä‘Ã£ trÃ¬nh bÃ y 5 thuáº­t toÃ¡n Machine Learning cÆ¡ báº£n: <a href="/2016/12/28/linearregression/">Linear Regression</a>, <a href="/2017/01/01/kmeans/">K-means Clusterning</a>, <a href="/2017/01/08/knn/">K-nearest neighbors</a>, <a href="/2017/01/21/perceptron/">Perceptron Learning Algorithm</a> vÃ  <a href="/2017/01/27/logisticregression/">Logistic Regression</a>. Trong táº¥t cáº£ cÃ¡c thuáº­t toÃ¡n nÃ y, tÃ´i Ä‘á»u giáº£ sá»­ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng cÃ¡c vector, Ä‘Æ°á»£c gá»i lÃ  <em>feature vector</em> hay <em>vector Ä‘áº·c trÆ°ng</em>, cÃ³ Ä‘á»™ dÃ i báº±ng nhau, vÃ  cÃ¹ng lÃ  vector cá»™t hoáº·c vector hÃ ng. Tuy nhiÃªn, trong cÃ¡c bÃ i toÃ¡n thá»±c táº¿, má»i chuyá»‡n khÃ´ng Ä‘Æ°á»£c tá»‘t Ä‘áº¹p nhÆ° váº­y!</p>

<p>Vá»›i cÃ¡c bÃ i toÃ¡n vá» Computer Vision, cÃ¡c bá»©c áº£nh lÃ  cÃ¡c ma tráº­n cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau. Tháº­m chÃ­ Ä‘á»ƒ nháº­n dáº¡ng váº­t thá»ƒ trong áº£nh, ta cáº§n thÃªm má»™t bÆ°á»›c ná»¯a lÃ  <em>object detection</em>, tá»©c lÃ  tÃ¬m cÃ¡i khung chá»©a váº­t thá»ƒ chÃºng ta cáº§n dá»± Ä‘oÃ¡n. VÃ­ dá»¥, trong bÃ i toÃ¡n nháº­n dáº¡ng khuÃ´n máº·t, chÃºng ta cáº§n tÃ¬m Ä‘Æ°á»£c vá»‹ trÃ­ cÃ¡c khuÃ´n máº·t trong áº£nh vÃ  <em>crop</em> cÃ¡c khuÃ´n máº·t Ä‘Ã³ trÆ°á»›c khi lÃ m cÃ¡c bÆ°á»›c tiáº¿p theo. Ngay cáº£ khi Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cÃ¡c khung chá»©a cÃ¡c khuÃ´n máº·t (vÃ  cÃ³ thá»ƒ resize cÃ¡c khung Ä‘Ã³ vá» cÃ¹ng má»™t kÃ­ch thÆ°á»›c), ta váº«n pháº£i lÃ m ráº¥t nhiá»u viá»‡c ná»¯a vÃ¬ hÃ¬nh áº£nh cá»§a khuÃ´n máº·t cÃ²n phá»¥ thÆ°á»™c vÃ o gÃ³c chá»¥p, Ã¡nh sÃ¡ng, â€¦ vÃ  ráº¥t nhiá»u yáº¿u tá»‘ khÃ¡c ná»¯a.</p>

<p>CÃ¡c bÃ i toÃ¡n NLP (Natural Language Processing - Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn) cÅ©ng cÃ³ khÃ³ khÄƒn tÆ°Æ¡ng tá»± khi Ä‘á»™ dÃ i cá»§a cÃ¡c vÄƒn báº£n lÃ  khÃ¡c nhau, tháº­m chÃ­ cÃ³ nhá»¯ng tá»« ráº¥t hiáº¿m gáº·p hoáº·c khÃ´ng cÃ³ trong tá»« Ä‘iá»ƒn. CÅ©ng cÃ³ khi thÃªm má»™t vÃ i tá»« vÃ o vÄƒn báº£n mÃ  ná»™i dung cá»§a vÄƒn báº£n khÃ´ng Ä‘á»•i hoáº·c hoÃ n toÃ n mang nghÄ©a ngÆ°á»£c láº¡i. Hoáº·c cÃ¹ng lÃ  má»™t cÃ¢u nÃ³i nhÆ°ng tá»‘c Ä‘á»™, Ã¢m giá»ng cá»§a má»—i ngÆ°á»i lÃ  khÃ¡c nhau, tháº­m chÃ­ cá»§a cÃ¹ng má»™t ngÆ°á»i nhÆ°ng lÃºc á»‘m lÃºc khá»e cÅ©ng khÃ¡c nhau.</p>

<p>Khi lÃ m viá»‡c vá»›i cÃ¡c bÃ i toÃ¡n Machine Learning thá»±c táº¿, nhÃ¬n chung chÃºng ta chá»‰ cÃ³ Ä‘Æ°á»£c dá»¯ liá»‡u thÃ´ (raw) chÆ°a qua chá»‰nh sá»­a, chá»n lá»c. ChÃºng ta cáº§n pháº£i tÃ¬m má»™t phÃ©p biáº¿n Ä‘á»•i Ä‘á»ƒ loáº¡i ra nhá»¯ng dá»¯ liá»‡u nhiá»…u (noise), vÃ  Ä‘á»ƒ Ä‘Æ°a dá»¯ liá»‡u thÃ´ vá»›i sá»‘ chiá»u khÃ¡c nhau vá» cÃ¹ng má»™t chuáº©n (cÃ¹ng lÃ  cÃ¡c vector hoáº·c ma tráº­n). Dá»¯ liá»‡u chuáº©n má»›i nÃ y pháº£i Ä‘áº£m báº£o giá»¯ Ä‘Æ°á»£c nhá»¯ng thÃ´ng tin Ä‘áº·c trÆ°ng (features) cho dá»¯ liá»‡u thÃ´ ban Ä‘áº§u. KhÃ´ng nhá»¯ng tháº¿, tÃ¹y vÃ o tá»«ng bÃ i toÃ¡n, ta cáº§n <em>thiáº¿t káº¿</em> nhá»¯ng phÃ©p biáº¿n Ä‘á»•i Ä‘á»ƒ cÃ³ nhá»¯ng features phÃ¹ há»£p. QuÃ¡ trÃ¬nh quan trá»ng nÃ y Ä‘Æ°á»£c gá»i lÃ  <em>Feature Extraction</em>, hoáº·c <em>Feature Engineering</em>, má»™t sá»‘ tÃ i liá»‡u tiáº¿ng Viá»‡t gá»i nÃ³ lÃ  <em>trÃ­ch chá»n Ä‘áº·c trÆ°ng</em>.</p>

<p>TÃ´i xin trÃ­ch má»™t cÃ¢u nÃ³i cá»§a tháº§y Andrew Ng vÃ  xin phÃ©p thÃªm khÃ´ng dá»‹ch ra tiáº¿ng Viá»‡t (Nguá»“n <a href="https://en.wikipedia.org/wiki/Feature_engineering">Feature Engineering - wiki</a>):</p>

<blockquote>
  <p>Coming up with features is difficult, time-consuming, requires expert knowledge. â€œApplied machine learningâ€ is basically feature engineering.</p>
</blockquote>

<p>Äá»ƒ giÃºp cÃ¡c báº¡n cÃ³ cÃ¡i nhÃ¬n tá»•ng quan hÆ¡n, trong pháº§n tiáº¿p theo tÃ´i xin Ä‘áº·t bÆ°á»›c Feature Engineering nÃ y trong má»™t bá»©c tranh lá»›n hÆ¡n.</p>

<p><a name="-mo-hinh-chung-cho-cac-bai-toan-machine-learning"></a></p>

<h2 id="2-mÃ´-hÃ¬nh-chung-cho-cÃ¡c-bÃ i-toÃ¡n-machine-learning">2. MÃ´ hÃ¬nh chung cho cÃ¡c bÃ i toÃ¡n Machine Learning</h2>
<p>Pháº§n lá»›n cÃ¡c bÃ i toÃ¡n Machine Learning cÃ³ thá»ƒ Ä‘Æ°á»£c thá»ƒ hiá»‡n trong hÃ¬nh váº½ dÆ°á»›i Ä‘Ã¢y:</p>

<div class="imgcap">
<img src="\assets\FeatureEngineering\ML_models.png" align="center" width="800" />
<div class="thecap">HÃ¬nh 1: MÃ´ hÃ¬nh chung cho cÃ¡c bÃ i toÃ¡n Machine Learning.</div>
</div>

<p>CÃ³ hai phases lá»›n lÃ  Training phase vÃ  Testing phase. Xin nháº¯c láº¡i lÃ  vá»›i cÃ¡c bÃ i toÃ¡n Supervised learning, ta cÃ³ cÃ¡c cáº·p dá»¯ liá»‡u (<em>input, output</em>), vá»›i cÃ¡c bÃ i toÃ¡n Unsupervised learing, ta chá»‰ cÃ³ <em>input</em> mÃ  thÃ´i.</p>

<p><a name="training-phase"></a></p>

<h3 id="training-phase">TRAINING PHASE</h3>
<p>CÃ³ hai khá»‘i cÃ³ ná»n mÃ u xanh lá»¥c chÃºng ta cáº§n pháº£i thiáº¿t káº¿:</p>

<p><a name="feature-extractor"></a></p>

<h4 id="feature-extractor">Feature Extractor</h4>
<p><strong>Äáº¦U RA</strong></p>

<p>TÃ´i xin Ä‘á» cáº­p Ä‘áº§u ra cá»§a khá»‘i nÃ y trÆ°á»›c vÃ¬ má»¥c Ä‘Ã­ch cá»§a Feature Engineering lÃ  táº¡o ra má»™t Feature Extractor biáº¿n dá»¯ liá»‡u thÃ´ ban Ä‘áº§u thÃ nh dá»¯ liá»‡u phÃ¹ há»£p vá»›i tá»«ng má»¥c Ä‘Ã­ch khÃ¡c nhau.</p>

<p><strong>Äáº¦U VÃ€O</strong></p>

<ul>
  <li>
    <p><strong><em>raw training input</em></strong>. Raw input lÃ  táº¥t cáº£ cÃ¡c thÃ´ng tin ta biáº¿t vá» dá»¯ liá»‡u. VÃ­ dá»¥: vá»›i áº£nh thÃ¬ lÃ  giÃ¡ trá»‹ cá»§a tá»«ng pixel; vá»›i vÄƒn báº£n thÃ¬ lÃ  tá»«ng tá»«, tá»«ng cÃ¢u; vá»›i file Ã¢m thanh thÃ¬ nÃ³ lÃ  má»™t Ä‘oáº¡n tÃ­n hiá»‡u; vá»›i cÆ¡ sá»Ÿ dá»¯ liá»‡u <a href="/2017/01/08/knn/#bo-co-so-du-lieu-iris-iris-flower-dataset">Iris</a> thÃ¬ nÃ³ lÃ  Ä‘á»™ dÃ i cÃ¡c cÃ¡nh hoa vÃ  Ä‘Ã i hoa, â€¦ Dá»¯ liá»‡u thÃ´ nÃ y thÆ°á»ng khÃ´ng á»Ÿ dáº¡ng vector, khÃ´ng cÃ³ sá»‘ chiá»u nhÆ° nhau. Tháº­m chÃ­ cÃ³ thá»ƒ cÃ³ sá»‘ chiá»u nhÆ° nhau nhÆ°ng sá»‘ chiá»u quÃ¡ lá»›n, nhÆ° má»™t bá»©c áº£nh mÃ u 1000 pixel x 1000 pixel thÃ¬ sá»‘ <em>elements</em> Ä‘Ã£ lÃ  \(3 \times 10^6\) (3 vÃ¬ áº£nh mÃ u thÆ°á»ng cÃ³ 3 channels: Red, Green, Blue). ÄÃ¢y lÃ  má»™t con sá»‘ quÃ¡ lá»›n, khÃ´ng lá»£i cho lÆ°u trá»¯ vÃ  tÃ­nh toÃ¡n.</p>
  </li>
  <li>
    <p><strong>(optional) <em>output</em> cá»§a <em>training set</em></strong>. Trong cÃ¡c bÃ i toÃ¡n Unsupervised
learning, ta khÃ´ng biáº¿t <em>output</em> nÃªn hiá»ƒn nhiÃªn sáº½ khÃ´ng cÃ³ Ä‘áº§u vÃ o nÃ y. Trong
cÃ¡c bÃ i toÃ¡n Supervised learning, cÃ³ khi dá»¯ liá»‡u nÃ y cÅ©ng khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng.
VÃ­ dá»¥: náº¿u <em>raw input</em> Ä‘Ã£ cÃ³ cÃ¹ng sá»‘ chiá»u rá»“i nhÆ°ng sá»‘ chiá»u quÃ¡ lá»›n,  ta
muá»‘n giáº£m sá»‘ chiá»u cá»§a nÃ³ thÃ¬ cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  <em>chiáº¿u</em> vector Ä‘Ã³ xuá»‘ng
má»™t khÃ´ng gian cÃ³ sá»‘ chiá»u nhá» hÆ¡n báº±ng cÃ¡ch láº¥y má»™t ma tráº­n ngáº«u nhiÃªn nhÃ¢n
vá»›i nÃ³. Ma tráº­n nÃ y thÆ°á»ng lÃ  ma tráº­n <em>bÃ©o</em> (sá»‘ hÃ ng Ã­t hÆ¡n sá»‘ cá»™t, tiáº¿ng Anh - fat matrices) Ä‘á»ƒ Ä‘áº£m báº£o sá»‘ chiá»u thu Ä‘Æ°á»£c nhá» hÆ¡n sá»‘ chiá»u ban Ä‘áº§u. Viá»‡c
lÃ m nÃ y máº·c dÃ¹ lÃ m máº¥t Ä‘i thÃ´ng tin, trong nhiá»u trÆ°á»ng há»£p váº«n mang láº¡i hiá»‡u
quáº£ vÃ¬ Ä‘Ã£ giáº£m Ä‘Æ°á»£c lÆ°á»£ng tÃ­nh toÃ¡n á»Ÿ pháº§n sau. ÄÃ´i khi <em>ma tráº­n chiáº¿u</em> khÃ´ng
pháº£i lÃ  ngáº«u nhiÃªn mÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c <em>há»c</em> dá»±a trÃªn toÃ n bá»™ <em>raw input</em>, ta sáº½ cÃ³
bÃ i toÃ¡n tÃ¬m ma tráº­n chiáº¿u Ä‘á»ƒ lÆ°á»£ng thÃ´ng tin máº¥t Ä‘i lÃ  Ã­t nháº¥t. Trong nhiá»u
trÆ°á»ng há»£p, dá»¯ liá»‡u <em>output</em> cá»§a <em>training set</em> cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra
Feature Extractor. VÃ­ dá»¥: trong bÃ i toÃ¡n classification, ta khÃ´ng quan tÃ¢m
nhiá»u Ä‘áº¿n viá»‡c máº¥t thÃ´ng tin hay khÃ´ng, ta chá»‰ quan tÃ¢m Ä‘áº¿n viá»‡c nhá»¯ng thÃ´ng
tin cÃ²n láº¡i cÃ³ Ä‘áº·c trÆ°ng cho tá»«ng class hay khÃ´ng. VÃ­ dá»¥, dá»¯ liá»‡u thÃ´ lÃ  cÃ¡c
hÃ¬nh vuÃ´ng vÃ  hÃ¬nh tam giÃ¡c cÃ³ mÃ u Ä‘á» vÃ  xanh. Trong bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a
giÃ¡c, cÃ¡c output lÃ  <em>tam giÃ¡c</em> vÃ  <em>vuÃ´ng</em>,  thÃ¬ ta khÃ´ng quan tÃ¢m tá»›i mÃ u sáº¯c
mÃ  chá»‰ quan tÃ¢m tá»›i sá»‘ cáº¡nh cá»§a Ä‘a giÃ¡c. NgÆ°á»£c láº¡i, trong bÃ i toÃ¡n phÃ¢n loáº¡i
mÃ u, cÃ¡c class lÃ  <em>xanh</em> vÃ  <em>Ä‘á»</em>, ta khÃ´ng quan tÃ¢m tá»›i sá»‘ cáº¡nh mÃ  chá»‰ quan
tÃ¢m Ä‘áº¿n mÃ u sáº¯c thÃ´i.</p>
  </li>
  <li>
    <p><strong>(optional) <em>Prior knowledge about data</em></strong>: ÄÃ´i khi nhá»¯ng giáº£ thiáº¿t khÃ¡c vá» dá»¯ liá»‡u cÅ©ng mang láº¡i lá»£i Ã­ch. VÃ­ dá»¥, trong bÃ i toÃ¡n classification, náº¿u ta biáº¿t dá»¯ liá»‡u lÃ  (gáº§n nhÆ°) <a href="/2017/01/21/perceptron/#bai-toan-perceptron"> <em>linearly separable</em></a> thÃ¬ ta sáº½ Ä‘i tÃ¬m má»™t ma tráº­n chiáº¿u sao cho á»Ÿ trong khÃ´ng gian má»›i, dá»¯ liá»‡u váº«n Ä‘áº£m báº£o tÃ­nh <em>linearly separable</em>, viá»‡c nÃ y thuáº­n tiá»‡n hÆ¡n cho pháº§n classification vÃ¬ cÃ¡c thuáº­t toÃ¡n linear, nhÃ¬n chung, Ä‘Æ¡n giáº£n hÆ¡n.</p>
  </li>
</ul>

<p>Sau khi <em>há»c</em> Ä‘Æ°á»£c feature extractor thÃ¬ ta cÅ©ng sáº½ thu Ä‘Æ°á»£c <em>extracted features</em> cho <em>raw input data</em>. Nhá»¯ng <em>extracted features</em> nÃ y Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c thuáº­t toÃ¡n Classification, Clustering, Regression,â€¦ á»Ÿ phÃ­a sau.</p>

<p><a name="main-algorithms"></a></p>

<h4 id="main-algorithms">Main Algorithms</h4>
<p>Khi cÃ³ Ä‘Æ°á»£c <em>extracted features</em> rá»“i, chÃºng ta sá»­ dá»¥ng nhá»¯ng thÃ´ng tin nÃ y cÃ¹ng
vá»›i (optional) <em>training output</em> vÃ  (optional) <em>prior knowledge</em> Ä‘á»ƒ táº¡o ra cÃ¡c
mÃ´ hÃ¬nh phÃ¹ há»£p, Ä‘iá»u mÃ  chÃºng ta Ä‘Ã£ lÃ m á»Ÿ nhá»¯ng bÃ i trÆ°á»›c.</p>

<p><strong>ChÃº Ã½:</strong> Trong má»™t sá»‘ thuáº­t toÃ¡n cao cáº¥p hÆ¡n, viá»‡c <em>huáº¥n luyá»‡n</em> feature extractor vÃ  main algorithm Ä‘Æ°á»£c thá»±c hiá»‡n cÃ¹ng lÃºc vá»›i nhau chá»© khÃ´ng pháº£i tá»«ng bÆ°á»›c nhÆ° trÃªn.</p>

<p><strong>Má»™t Ä‘iá»ƒm ráº¥t quan trá»ng: khi xÃ¢y dá»±ng bá»™ <em>feature extractor</em> vÃ  <em>main
algorithms</em>, chÃºng ta khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng báº¥t ká»³ thÃ´ng tin nÃ o trong táº­p <em>test
data</em>. Ta pháº£i giáº£ sá»­ ráº±ng nhá»¯ng thÃ´ng tin trong <em>test data</em> chÆ°a Ä‘Æ°á»£c nhÃ¬n tháº¥y
bao giá». Náº¿u sá»­ dá»¥ng thÃªm thÃ´ng tin vá» <em>test data</em> thÃ¬ rÃµ rÃ ng ta Ä‘Ã£ <em>Äƒn gian</em>!
TÃ´i tá»«ng Ä‘Ã¡nh giÃ¡ cÃ¡c bÃ i bÃ¡o khoa há»c quá»‘c táº¿, ráº¥t nhiá»u tÃ¡c giáº£ xÃ¢y dá»±ng mÃ´
hÃ¬nh dÃ¹ng cáº£ dá»¯ liá»‡u <em>test data</em>, sau Ä‘Ã³ láº¡i dÃ¹ng chÃ­nh mÃ´ hÃ¬nh Ä‘Ã³ Ä‘á»ƒ kiá»ƒm tra
trÃªn <em>test data</em> Ä‘Ã³. Viá»‡c <em>Äƒn gian</em> nÃ y lÃ  lá»—i ráº¥t náº·ng vÃ  hiá»ƒn nhiÃªn nhá»¯ng bÃ i
bÃ¡o Ä‘Ã³ bá»‹ tá»« chá»‘i (reject).</strong></p>

<p><a name="testing-phase"></a></p>

<h3 id="testing-phase">TESTING PHASE</h3>
<p>BÆ°á»›c nÃ y Ä‘Æ¡n giáº£n hÆ¡n nhiá»u. Vá»›i <em>raw input</em> má»›i, ta sá»­ dá»¥ng feature extractor
Ä‘Ã£ táº¡o Ä‘Æ°á»£c á»Ÿ trÃªn (táº¥t nhiÃªn khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng <em>output</em> cá»§a nÃ³ vÃ¬ <em>output</em> lÃ 
cÃ¡i ta Ä‘ang Ä‘i tÃ¬m) Ä‘á»ƒ táº¡o ra feature vector tÆ°Æ¡ng á»©ng. Feature vector Ä‘Æ°á»£c Ä‘Æ°a
vÃ o <em>main algorithm</em> Ä‘Ã£ Ä‘Æ°á»£c há»c á»Ÿ training phase Ä‘á»ƒ dá»± Ä‘oÃ¡n <em>output</em>.</p>

<p><a name="-mot-so-vi-du-ve-feature-engineering"></a></p>

<h2 id="3-má»™t-sá»‘-vÃ­-dá»¥-vá»-feature-engineering">3. Má»™t sá»‘ vÃ­ dá»¥ vá» Feature Engineering</h2>
<p><a name="truc-tiep-lay-raw-data"></a></p>

<h3 id="trá»±c-tiáº¿p-láº¥y-raw-data">Trá»±c tiáº¿p láº¥y raw data</h3>
<p>Vá»›i bÃ i toÃ¡n phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay trong bá»™ cÆ¡ sá»Ÿ dá»¯ liá»‡u
<a href="/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist">MNIST</a>, má»—i bá»©c áº£nh cÃ³ sá»‘ chiá»u lÃ 
28 pixel x 28 pixel (táº¥t nhiÃªn viá»‡c <em>crop</em> vÃ  chá»‰nh sá»­a má»—i bá»©c áº£nh Ä‘Ã£ Ä‘Æ°á»£c thá»±c
hiá»‡n tá»« trÆ°á»›c rá»“i, Ä‘Ã³ Ä‘Ã£ lÃ  má»™t pháº§n cá»§a feature engineering rá»“i). Má»™t cÃ¡ch Ä‘Æ¡n
giáº£n thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng lÃ  <em>kÃ©o dÃ i</em> ma tráº­n 28x28 nÃ y Ä‘á»ƒ Ä‘Æ°á»£c 1 vector cÃ³ sá»‘
chiá»u 784. Trong cÃ¡ch nÃ y, cÃ¡c cá»™t (hoáº·c hÃ ng) cá»§a ma tráº­n áº£nh Ä‘Æ°á»£c Ä‘áº·t chá»“ng
lÃªn (hoáº·c cáº¡nh nhau) Ä‘á»ƒ Ä‘Æ°á»£c 1 vector dÃ i. Vector dÃ i nÃ y Ä‘Æ°á»£c trá»±c tiáº¿p sá»­ dá»¥ng
lÃ m feature Ä‘Æ°a vÃ o cÃ¡c bá»™ classifier/clustering/regression/â€¦ LÃºc nÃ y, giÃ¡ trá»‹
cá»§a má»—i pixel áº£nh Ä‘Æ°á»£c coi lÃ  má»™t feature.</p>

<p>RÃµ rÃ ng viá»‡c lÃ m Ä‘Æ¡n giáº£n nÃ y Ä‘Ã£ lÃ m máº¥t thÃ´ng tin vá» <em>khÃ´ng gian</em> (spatial information) giá»¯a cÃ¡c Ä‘iá»ƒm áº£nh, tuy nhiÃªn, trong nhiá»u trÆ°á»ng há»£p, nÃ³ váº«n mang láº¡i káº¿t quáº£ kháº£ quan. 
<a name="feature-selection"></a></p>

<h3 id="feature-selection">Feature selection</h3>
<p>Giáº£ sá»­ ráº±ng cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cÃ³ sá»‘ features khÃ¡c nhau (do kÃ­ch thÆ°á»›c dá»¯ liá»‡u
khÃ¡c nhau hay do má»™t sá»‘ feature mÃ  Ä‘iá»ƒm dá»¯ liá»‡u nÃ y cÃ³ nhÆ°ng Ä‘iá»ƒm dá»¯ liá»‡u kia
láº¡i khÃ´ng thu tháº­p Ä‘Æ°á»£c), vÃ  sá»‘ lÆ°á»£ng features lÃ  cá»±c lá»›n. ChÃºng ta cáº§n <em>chá»n</em>
ra má»™t sá»‘ lÆ°á»£ng nhá» hÆ¡n cÃ¡c feature phÃ¹ há»£p vá»›i bÃ i toÃ¡n. <em>Chá»n tháº¿ nÃ o</em> vÃ  <em>tháº¿
nÃ o lÃ  phÃ¹ há»£p</em> láº¡i lÃ  má»™t bÃ i toÃ¡n khÃ¡c, tÃ´i sáº½ khÃ´ng bÃ n thÃªm á»Ÿ Ä‘Ã¢y.</p>

<p><a name="dimensionality-reduction"></a></p>

<h3 id="dimensionality-reduction">Dimensionality reduction</h3>
<p>Má»™t phÆ°Æ¡ng phÃ¡p ná»¯a tÃ´i Ä‘Ã£ Ä‘á» cáº­p Ä‘Ã³ lÃ  lÃ m giáº£m sá»‘ chiá»u cá»§a dá»¯ liá»‡u Ä‘á»ƒ giáº£m bá»™
nhá»› vÃ  khá»‘i lÆ°á»£ng tÃ­nh toÃ¡n. Viá»‡c giáº£m sá»‘ chiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng
nhiá»u cÃ¡ch, trong Ä‘Ã³ <em>random projection</em> lÃ  cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t. Tá»©c chá»n má»™t <em>ma
tráº­n chiáº¿u</em> (projection matrix) ngáº«u nhiÃªn (ma tráº­n bÃ©o) rá»“i nhÃ¢n nÃ³ vá»›i tá»«ng
Ä‘iá»ƒm dá»¯ liá»‡u (giáº£ sá»­ dá»¯ liá»‡u á»Ÿ dáº¡ng vector cá»™t) Ä‘á»ƒ Ä‘Æ°á»£c cÃ¡c vector cÃ³ sá»‘ chiá»u
tháº¥p hÆ¡n. VÃ­ dá»¥, vector ban Ä‘áº§u cÃ³ sá»‘ chiá»u lÃ  784, chá»n <em>ma tráº­n chiáº¿u</em> cÃ³ kÃ­ch
thÆ°á»›c (100x784), khi Ä‘Ã³ náº¿u nhÃ¢n ma tráº­n chÃ©o nÃ y vá»›i vector ban Ä‘áº§u, ta sáº½ Ä‘Æ°á»£c
má»™t vector má»›i cÃ³ sá»‘ chiá»u lÃ  100, nhá» hÆ¡n sá»‘ chiá»u ban Ä‘áº§u ráº¥t nhiá»u. LÃºc nÃ y,
cÃ³ thá»ƒ ta khÃ´ng cÃ³ tÃªn gá»i cho má»—i feature ná»¯a vÃ¬ cÃ¡c feature á»Ÿ vector ban Ä‘áº§u
Ä‘Ã£ Ä‘Æ°á»£c trá»™n láº«n vá»›i nhau theo má»™t tá»‰ lá»‡ nÃ o Ä‘Ã³ rá»“i lÆ°u vÃ o vector má»›i nÃ y. Má»—i
thÃ nh pháº§n cá»§a vector má»›i nÃ y Ä‘Æ°á»£c coi lÃ  má»™t feature (khÃ´ng tÃªn).</p>

<p>Viá»‡c chá»n má»™t ma tráº­n chiáº¿u ngáº«u nhiÃªn Ä‘Ã´i khi mang láº¡i káº¿t quáº£ tá»‡ khÃ´ng mong
muá»‘n vÃ¬ thÃ´ng tin bá»‹ máº¥t Ä‘i quÃ¡ nhiá»u. Má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u Ä‘á»ƒ háº¡n
cháº¿ lÆ°á»£ng thÃ´ng tin máº¥t Ä‘i cÃ³ tÃªn lÃ  <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component
Analysis</a> sáº½ Ä‘Æ°á»£c
tÃ´i trÃ¬nh bÃ y sau Ä‘Ã¢y khoáº£ng 1-2 thÃ¡ng.</p>

<p><strong>ChÃº Ã½:</strong> Feature learning khÃ´ng nháº¥t thiáº¿t pháº£i lÃ m giáº£m sá»‘ chiá»u dá»¯ liá»‡u, Ä‘Ã´i
khi feature vector cÃ²n cÃ³ sá»‘ chiá»u lá»›n hÆ¡n raw data. Random projection cÅ©ng cÃ³
thá»ƒ lÃ m Ä‘Æ°á»£c viá»‡c nÃ y náº¿u ma tráº­n chiáº¿u lÃ  má»™t ma tráº­n <em>cao</em> (sá»‘ cá»™t Ã­t hÆ¡n sá»‘
hÃ ng).</p>

<p><a name="bag-of-words"></a></p>

<h3 id="bag-of-words">Bag-of-words</h3>
<p>Háº³n ráº¥t nhiá»u báº¡n Ä‘Ã£ tá»± Ä‘áº·t cÃ¢u há»i: Vá»›i má»™t vÄƒn báº£n thÃ¬ feature vector sáº½ cÃ³
dáº¡ng nhÆ° tháº¿ nÃ o? LÃ m sao Ä‘Æ°a cÃ¡c tá»«, cÃ¡c cÃ¢u, Ä‘oáº¡n vÄƒn á»Ÿ dáº¡ng <em>text</em> trong cÃ¡c
vÄƒn báº£n vá» má»™t vector mÃ  má»—i pháº§n tá»­ lÃ  má»™t sá»‘?</p>

<p>CÃ³ má»™t phÆ°Æ¡ng phÃ¡p ráº¥t phá»• biáº¿n giÃºp báº¡n tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y. PhÆ°Æ¡ng phÃ¡p Ä‘Ã³ cÃ³ tÃªn lÃ  <em>Bag of Words (BoW)</em> (<em>TÃºi Ä‘á»±ng Tá»«</em>).</p>

<p>Váº«n theo thÃ³i quen, tÃ´i báº¯t Ä‘áº§u báº±ng má»™t vÃ­ dá»¥. Giáº£ sá»­ chÃºng ta cÃ³ bÃ i toÃ¡n phÃ¢n loáº¡i tin rÃ¡c. Ta tháº¥y ráº±ng náº¿u má»™t tin cÃ³ chá»©a cÃ¡c tá»« <em>khuyáº¿n máº¡i, giáº£m giÃ¡, trÃºng thÆ°á»Ÿng, miá»…n phÃ­, quÃ  táº·ng, tri Ã¢n, â€¦</em> thÃ¬ nhiá»u kháº£ nÄƒng Ä‘Ã³ lÃ  má»™t tin nháº¯n rÃ¡c. Váº­y phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nháº¥t lÃ  <em>Ä‘áº¿m</em> xem trong tin Ä‘Ã³ cÃ³ bao nhiÃªu tá»« thuá»™c vÃ o cÃ¡c tá»« trÃªn, náº¿u nhiá»u hÆ¡n 1 ngÆ°á»¡ng nÃ o Ä‘Ã³ thÃ¬ ta quyáº¿t Ä‘á»‹nh Ä‘Ã³ lÃ  tin rÃ¡c. (Táº¥t nhiÃªn bÃ i toÃ¡n thá»±c táº¿ phá»©c táº¡p hÆ¡n nhiá»u khi cÃ¡c tá»« cÃ³ thá»ƒ Ä‘Æ°á»£c viáº¿t dÆ°á»›i dáº¡ng khÃ´ng dáº¥u, hoáº·c bá»‹ cá»‘ tÃ¬nh viáº¿t sai chÃ­nh táº£, hoáº·c dÃ¹ng ngÃ´n ngá»¯ teen). Vá»›i cÃ¡c loáº¡i vÄƒn báº£n khÃ¡c nhau thÃ¬ lÆ°á»£ng tá»« liÃªn quan tá»›i tá»«ng chá»§ Ä‘á» cÅ©ng khÃ¡c nhau. Tá»« Ä‘Ã³ cÃ³ thá»ƒ dá»±a vÃ o sá»‘ lÆ°á»£ng cÃ¡c tá»« trong tá»«ng loáº¡i Ä‘á»ƒ lÃ m cÃ¡c vector Ä‘áº·c trÆ°ng cho tá»«ng vÄƒn báº£n.</p>

<p>TÃ´i xin láº¥y vÃ­ dá»¥ cá»¥ thá»ƒ hÆ¡n vá» cÃ¡ch táº¡o ra vector Ä‘áº·c trÆ°ng cho má»—i vÄƒn báº£n dá»±a trÃªn BoW vÃ  xin Ä‘Æ°á»£c láº¥y tiáº¿ng Anh lÃ m vÃ­ dá»¥ (nguá»“n <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words wiki</a>. Tiáº¿ng Viá»‡t khÃ³ hÆ¡n vÃ¬ má»™t tá»« cÃ³ thá»ƒ cÃ³ nhiá»u Ã¢m tiáº¿t, tiáº¿ng Anh thÃ¬ thÆ°á»ng cá»© gáº·p dáº¥u cÃ¡ch lÃ  káº¿t thÃºc má»™t tá»«).</p>

<p>Giáº£ sá»­ chÃºng ta cÃ³ hai vÄƒn báº£n Ä‘Æ¡n giáº£n:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1) John likes to watch movies. Mary likes movies too.
</code></pre></div></div>

<p>vÃ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(2) John also likes to watch football games.
</code></pre></div></div>
<p>Dá»±a trÃªn hai vÄƒn báº£n nÃ y, ta cÃ³ danh sÃ¡ch cÃ¡c tá»« Ä‘Æ°á»£c sá»­ dá»¥ng, Ä‘Æ°á»£c gá»i lÃ  <em>tá»« Ä‘iá»ƒn</em> vá»›i 10 <em>tá»«</em> nhÆ° sau:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>["John", "likes", "to", "watch", "movies", "also", "football", "games", "Mary", "too"]
</code></pre></div></div>
<p>Vá»›i má»—i vÄƒn báº£n, ta sáº½ táº¡o ra má»™t vector Ä‘áº·c trÆ°ng cÃ³ sá»‘ chiá»u báº±ng 10, má»—i pháº§n tá»­ Ä‘áº¡i diá»‡n cho sá»‘ tá»« tÆ°Æ¡ng á»©ng xuáº¥t hiá»‡n trong vÄƒn báº£n Ä‘Ã³. Vá»›i hai vÄƒn báº£n trÃªn, ta sáº½ cÃ³ hai vector Ä‘áº·c trÆ°ng lÃ :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1]
(2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]
</code></pre></div></div>
<p>VÄƒn báº£n (1) cÃ³ 1 tá»« â€œJohnâ€, 2 tá»« â€œlikesâ€, 0 tá»« â€œalsoâ€, 0 tá»« â€œfootballâ€, â€¦ nÃªn ta thu Ä‘Æ°á»£c vector tÆ°Æ¡ng á»©ng nhÆ° trÃªn.</p>

<p>CÃ³ má»™t vÃ i Ä‘iá»u cáº§n lÆ°u Ã½ trong BoW:</p>

<ul>
  <li>
    <p>Vá»›i nhá»¯ng á»©ng dá»¥ng thá»±c táº¿, <em>tá»« Ä‘iá»n</em> cÃ³ nhiá»u hÆ¡n 10 tá»« ráº¥t nhiá»u, cÃ³ thá»ƒ Ä‘áº¿n má»™t trÄƒm nghÃ¬n hoáº·c cáº£ triá»‡u, nhÆ° váº­y vector Ä‘áº·c trÆ°ng thu Ä‘Æ°á»£c sáº½ ráº¥t <em>dÃ i</em>. Má»™t vÄƒn báº£n chá»‰ cÃ³ 1 cÃ¢u, vÃ  1 tiá»ƒu thuyáº¿t nghÃ¬n trang Ä‘á»u Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng cÃ¡c vector cÃ³ sá»‘ chiá»u báº±ng 100 nghÃ¬n hoáº·c 1 triá»‡u.</p>
  </li>
  <li>
    <p>CÃ³ ráº¥t nhiá»u tá»« trong tá»« Ä‘iá»ƒn khÃ´ng xuáº¥t hiá»‡n trong má»™t vÄƒn báº£n. NhÆ° váº­y cÃ¡c vector Ä‘áº·c trÆ°ng thu Ä‘Æ°á»£c thÆ°á»ng cÃ³ ráº¥t nhiá»u pháº§n tá»­ báº±ng 0. CÃ¡c vector cÃ³ nhiá»u pháº§n tá»­ báº±ng 0 Ä‘Æ°á»£c gá»i lÃ  <em>sparse vector</em> (sparse hiá»ƒu theo nghÄ©a lÃ  <em>thÆ°a thá»›t, ráº£i rÃ¡c</em>, tÃ´i xin phÃ©p chá»‰ sá»­ dá»¥ng khÃ¡i niá»‡m nÃ y báº±ng tiáº¿ng Anh). Äá»ƒ viá»‡c lÆ°u trá»¯ Ä‘Æ°á»£c hiá»‡u quáº£ hÆ¡n, ta khÃ´ng lÆ°u cáº£ vector Ä‘Ã³ mÃ  chá»‰ lÆ°u <em>vá»‹ trÃ­</em> cá»§a cÃ¡c pháº§n tá»­ khÃ¡c 0 vÃ  <em>giÃ¡ trá»‹</em> tÆ°Æ¡ng á»©ng. LÆ°u Ã½: náº¿u cÃ³ hÆ¡n 50% sá»‘ pháº§n tá»­ khÃ¡c 0, viá»‡c lÃ m nÃ y láº¡i pháº£n tÃ¡c dá»¥ng!</p>
  </li>
  <li>
    <p>Thi thoáº£ng cÃ³ nhá»¯ng tá»« hiáº¿m gáº·p khÃ´ng náº±m trong tá»« Ä‘iá»ƒn, váº­y ta sáº½ lÃ m gÃ¬? Má»™t cÃ¡ch thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng lÃ  <em>má»Ÿ rá»™ng</em> vector Ä‘áº·c trÆ°ng thÃªm 1 pháº§n tá»­, gá»i lÃ  pháº©n tá»­ <code class="language-plaintext highlighter-rouge">&lt;Unknown&gt;</code>. Má»i tá»« khÃ´ng cÃ³ trong tá»« Ä‘iá»n Ä‘á»u Ä‘Æ°á»£c coi lÃ  <code class="language-plaintext highlighter-rouge">&lt;Unknown&gt;</code>.</p>
  </li>
  <li>
    <p>NghÄ© ká»¹ má»™t chÃºt, nhá»¯ng tá»« hiáº¿m Ä‘Ã´i khi láº¡i mang nhá»¯ng thÃ´ng tin quan trá»ng nháº¥t mÃ  chá»‰ loáº¡i vÄƒn báº£n Ä‘Ã³ cÃ³. ÄÃ¢y lÃ  má»™t nhÆ°á»£c Ä‘iá»ƒm cá»§a BoW. CÃ³ má»™t phÆ°Æ¡ng phÃ¡p cáº£i tiáº¿n khÃ¡c giÃºp kháº¯c phá»¥c nhÆ°á»£c Ä‘iá»ƒm nÃ y cÃ³ tÃªn lÃ  Term Frequency-Inverse Document Frequency (TF-IDF) dÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh táº§m quan trá»ng cá»§a má»™t tá»« trong má»™t vÄƒn báº£n dá»±a trÃªn toÃ n bá»™ vÄƒn báº£n trong cÆ¡ sá»Ÿ dá»¯ liá»‡u (corpus). Báº¡n Ä‘á»c muá»‘n tÃ¬m hiá»ƒu thÃªm cÃ³ thá»ƒ xem <a href="https://www.gitbook.com/book/lizrush/algorithms-for-webdevs-ebook/details">5 Algorithms Every Web Developer Can Use and Understand, section 5.</a></p>
  </li>
  <li>
    <p>NhÆ°á»£c Ä‘iá»ƒm lá»›n nháº¥t cá»§a BoW lÃ  nÃ³ khÃ´ng mang thÃ´ng tin vá» thá»© tá»± cá»§a cÃ¡c tá»«. CÅ©ng nhÆ° sá»± liÃªn káº¿t giá»¯a cÃ¡c cÃ¢u, cÃ¡c Ä‘oáº¡n vÄƒn trong vÄƒn báº£n. VÃ­ dá»¥, ba cÃ¢u sau Ä‘Ã¢y: â€œ<em>Em yÃªu anh khÃ´ng?</em>â€, â€œ<em>Em khÃ´ng yÃªu anh</em>â€, vÃ  â€œ<em>KhÃ´ng, (nhÆ°ng) anh yÃªu em</em>â€ khi Ä‘Æ°á»£c trÃ­ch chá»n Ä‘áº·c trÆ°ng báº±ng BoW sáº½ cho ra ba vector giá»‘ng há»‡t nhau, máº·c dÃ¹ Ã½ nghÄ©a khÃ¡c háº³n nhau.</p>
  </li>
</ul>

<p><strong>Bonus:</strong> hÃ¬nh dÆ°á»›i Ä‘Ã¢y lÃ  táº§n suáº¥t sá»­ dá»¥ng cÃ¡c tá»« (coi má»—i Ã¢m tiáº¿t lÃ  má»™t tá»«) trong Truyá»‡n Kiá»u (<a href="https://bitbucket.org/tiepvupsu/vietnamese/src/c6f3af6050f8ca911ed0fa209220ce3c99010075/TruyenKieu2.txt?at=master&amp;fileviewer=file-view-default">theo báº£n nÃ y</a>) náº¿u ta chá»‰ sá»­ dá»¥ng 30 tá»« cÃ³ táº§n suáº¥t cao nháº¥t. :</p>
<div class="imgcap">
<img src="\assets\FeatureEngineering\truyenkieu.png" align="center" width="400" />
<div class="thecap">HÃ¬nh 2: Bag of Words cho Truyá»‡n Kiá»u vá»›i 30 tá»« cÃ³ táº§n suáº¥t cao nháº¥t.</div>
</div>

<p><a name="bag-of-words-trong-computer-vision"></a></p>

<h3 id="bag-of-words-trong-computer-vision">Bag-of-Words trong Computer Vision</h3>
<p>Bags of Words cÅ©ng Ä‘Æ°á»£c Ã¡p dá»¥ng trong Computer Vision vá»›i cÃ¡ch Ä‘á»‹nh nghÄ©a <em>words</em> vÃ  tá»« Ä‘iá»ƒn khÃ¡c.</p>

<p>XÃ©t cÃ¡c vÃ­ dá»¥ sau:</p>

<p><strong>VÃ­ dá»¥ 1:</strong></p>

<p>CÃ³ hai class áº£nh, má»™t class lÃ  áº£nh cÃ¡c khu rá»«ng, má»™t class lÃ  áº£nh cÃ¡c sa máº¡c. PhÃ¢n loáº¡i má»™t bá»©c áº£nh lÃ  rá»«ng hay sa máº¡c (giáº£ sá»­ ta biáº¿t ráº±ng nÃ³ thuá»™c má»™t trong hai loáº¡i nÃ y) má»™t cÃ¡ch trá»±c quan nháº¥t lÃ  dá»±a vÃ o mÃ u sáº¯c. MÃ u xanh nhiá»u thÃ¬ lÃ  rá»«ng, mÃ u Ä‘á» vÃ  vÃ ng nhiá»u thÃ¬ lÃ  sa máº¡c. Váº­y chÃºng ta cÃ³ thá»ƒ cÃ³ má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n Ä‘á»ƒ trÃ­ch chá»n Ä‘áº·c trÆ°ng nhÆ° sau:</p>

<ul>
  <li>
    <p>Vá»›i má»™t bá»©c áº£nh, chuáº©n bá»‹ má»™t vector \(\mathbf{x}\) cÃ³ sá»‘ chiá»u báº±ng 3, Ä‘áº¡i diá»‡n cho 3 mÃ u xanh (\(x_1\)), Ä‘á» (\(x_2\)), vÃ  vÃ ng (\(x_3\)).</p>
  </li>
  <li>
    <p>Vá»›i má»—i Ä‘iá»ƒm áº£nh trong bá»©c áº£nh Ä‘Ã³, xem nÃ³ gáº§n vá»›i mÃ u xanh, Ä‘á» hay vÃ ng nháº¥t dá»±a trÃªn giÃ¡ trá»‹ cá»§a pixel Ä‘Ã³. Náº¿u nÃ³ gáº§n Ä‘iá»ƒm xanh nháº¥t, tÄƒng \(x_1\) lÃªn 1; gáº§n Ä‘á» nháº¥t, tÄƒng \(x_2\) lÃªn 1; gáº§n vÃ ng nháº¥t, tÄƒng \(x_3\) lÃªn 1.</p>
  </li>
  <li>
    <p>Sau khi xem xÃ©t táº¥t cáº£ cÃ¡c Ä‘iá»ƒm áº£nh, dÃ¹ cho bá»©c áº£nh cÃ³ kÃ­ch thÆ°á»›c tháº¿ nÃ o, ta váº«n thu Ä‘Æ°á»£c má»™t vector cÃ³ Ä‘á»™ dÃ i báº±ng 3, má»—i pháº§n tá»­ thá»ƒ hiá»‡n viá»‡c cÃ³ bao nhiÃªu pixel trong bá»©c áº£nh cÃ³ mÃ u tÆ°Æ¡ng á»©ng. Vector cuá»‘i nÃ y cÃ²n Ä‘Æ°á»£c gá»i lÃ  vector histogram cá»§a bá»©c áº£nh tÆ°Æ¡ng á»©ng vá»›i ba mÃ u xanh, Ä‘á», vÃ ng. Dá»±a vÃ o vector nÃ y, ta cÃ³ thá»ƒ quyáº¿t Ä‘á»‹nh bá»©c áº£nh Ä‘Ã³ lÃ  áº£nh rá»«ng hay sa máº¡c.</p>
  </li>
</ul>

<p><strong>VÃ­ dá»¥ 2:</strong></p>

<p>TrÃªn thá»±c táº¿, cÃ¡c bÃ i toÃ¡n xá»­ lÃ½ áº£nh khÃ´ng Ä‘Æ¡n giáº£n nhÆ° vÃ­ dá»¥ 1 trÃªn Ä‘Ã¢y. Máº¯t ngÆ°á»i thá»±c ra nháº¡y vá»›i cÃ¡c Ä‘Æ°á»ng nÃ©t, hÃ¬nh dÃ¡ng hÆ¡n lÃ  mÃ u sáº¯c. Má»™t cÃ¡i (áº£nh) cÃ¢y dÃ¹ khÃ´ng cÃ³ mÃ u váº«n lÃ  má»™t cÃ¡i (áº£nh) cÃ¢y! VÃ¬ váº­y, xem xÃ©t giÃ¡ trá»‹ tá»«ng Ä‘iá»ƒm áº£nh má»™t khÃ´ng mang láº¡i káº¿t quáº£ kháº£ quan vÃ¬ lÆ°á»£ng thÃ´ng tin bá»‹ máº¥t quÃ¡ nhiá»u.</p>

<p>CÃ³ má»™t cÃ¡ch kháº¯c phá»¥c lÃ  thay vÃ¬ xem xÃ©t má»™t Ä‘iá»ƒm áº£nh, ta xem xÃ©t má»™t <em>cá»­a sá»•</em> nhá» trong áº£nh (trong Computer Vision, cá»­a sá»• nÃ y Ä‘Æ°á»£c gá»i lÃ  patch) lÃ  má»™t hÃ¬nh chá»¯ nháº­t chá»©a nhiá»u Ä‘iá»ƒm áº£nh gáº§n nhau. Cá»­a sá»• nÃ y Ä‘á»§ lá»›n Ä‘á»ƒ cÃ³ thá»ƒ chá»©a Ä‘Æ°á»£c cÃ¡c bá»™ pháº­n cÃ³ thá»ƒ mÃ´ táº£ Ä‘Æ°á»£c váº­t thá»ƒ trong áº£nh.</p>

<p>VÃ­ dá»¥ vá»›i máº·t ngÆ°á»i, cÃ¡c patch nÃªn Ä‘á»§ lá»›n Ä‘á»ƒ chá»©a Ä‘Æ°á»£c cÃ¡c pháº§n cá»§a khuÃ´n máº·t nhÆ° máº¯t, mÅ©i, miá»‡ng nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y.</p>

<div class="imgcap">
<img src="\assets\FeatureEngineering\bow_face.png" align="center" width="800" />
<div class="thecap">HÃ¬nh 3: Bag of Words cho áº£nh chá»©a máº·t ngÆ°á»i. (Nguá»“n <a href="http://www.robots.ox.ac.uk/~az/icvss08_az_bow.pdf"> Bag of visual words model: recognizing object categories</a>)</div>
</div>

<p>TÆ°Æ¡ng tá»± tháº¿, vá»›i áº£nh lÃ  Ã´ tÃ´, cÃ¡c patch thu Ä‘Æ°á»£c cÃ³ thá»ƒ lÃ  bÃ¡nh xe, khung xe, cá»­a xe, â€¦ nhÆ° hÃ ng trÃªn trong hÃ¬nh dÆ°á»›i Ä‘Ã¢y.</p>

<div class="imgcap">
<img src="\assets\FeatureEngineering\bow_car.png" align="center" width="800" />
<div class="thecap">HÃ¬nh 4: Bag of Words cho áº£nh Ã´ tÃ´. (Nguá»“n: tÃ´i cá»‘ gáº¯ng tÃ¬m nguá»“n cho hÃ¬nh nÃ y nhÆ°ng táº¥t cáº£ cÃ¡c tÃ i liá»‡u tÃ´i tÃ¬m Ä‘Æ°á»£c Ä‘á»u ghi "Source: B. Leibe", tÃ´i cÅ©ng xin Ä‘Æ°á»£c trÃ­ch nguá»“n tÆ°Æ¡ng tá»±)</div>
</div>

<p>CÃ³ má»™t cÃ¢u há»i Ä‘áº·t ra lÃ , trong xá»­ lÃ½ vÄƒn báº£n, hai tá»« Ä‘Æ°á»£c coi lÃ  nhÆ° nhau náº¿u nÃ³ Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi cÃ¡c kÃ½ tá»± giá»‘ng nhau. Váº­y trong xá»­ lÃ½ áº£nh, hai patches Ä‘Æ°á»£c coi lÃ  nhÆ° nhau khi nÃ o? Khi má»i pixel trong hai patches cÃ³ giÃ¡ trá»‹ báº±ng nhau sao?</p>

<p>CÃ¢u tráº£ lá»i lÃ  khÃ´ng. XÃ¡c suáº¥t Ä‘á»ƒ hai patches giá»‘ng há»‡t nhau tá»«ng pixel lÃ  ráº¥t tháº¥p vÃ¬ cÃ³ thá»ƒ má»™t pháº§n cá»§a váº­t thá»ƒ trong má»™t patch bá»‹ lá»‡ch Ä‘i vÃ i pixel so vá»›i pháº§n Ä‘Ã³ trong patch kia; hoáº·c pháº§n váº­t thá»ƒ trong patch bá»‹ mÃ©o, hoáº·c cÃ³ Ä‘á»™ sÃ¡ng khÃ¡c nhau, máº·c dÃ¹ ta váº«n nhÃ¬n tháº¥y hai patches Ä‘Ã³ <em>ráº¥t giá»‘ng nhau</em>. Váº­y thÃ¬ hai patch Ä‘Æ°á»£c coi lÃ  nhÆ° nhau khi nÃ o? VÃ  <em>tá»« Ä‘iá»ƒn</em> á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° tháº¿ nÃ o?</p>

<p>CÃ¢u tráº£ lá»i ngáº¯n: hai patches lÃ  gáº§n giá»‘ng nhau náº¿u khoáº£ng cÃ¡ch Euclid giá»¯a hai vector táº¡o bá»Ÿi hai patches Ä‘Ã³ gáº§n nhau. Tá»« Ä‘iá»ƒn (codebook) sáº½ cÃ³ sá»‘ pháº§n tá»­ do ta tá»± chá»n. Sá»‘ pháº§n tá»­ cÃ ng cao thÃ¬ Ä‘á»™ sai lá»‡ch cÃ ng Ã­t, nhÆ°ng sáº½ náº·ng vá» tÃ­nh toÃ¡n hÆ¡n.</p>

<p>CÃ¢u tráº£ lá»i dÃ i: chÃºng ta cÃ³ thá»ƒ Ã¡p dá»¥ng <a href="/2017/01/01/kmeans/">K-means clustering</a>. Vá»›i ráº¥t nhiá»u patches thu Ä‘Æ°á»£c, giáº£ sá»­ ta muá»‘n xÃ¢y dá»±ng má»™t <em>codebook</em> vá»›i chá»‰ khoáº£ng 1000 <em>words</em>. Váº­y thÃ¬ ta cho \(k = 1000\) rá»“i thá»±c hiá»‡n K-means clustering trÃªn toÃ n bá»™ sá»‘ patches thu Ä‘Æ°á»£c (tá»« táº­p training). Sau khi thá»±c hiá»‡n K-means clustering, ta thu Ä‘Æ°á»£c 1000 clusters vÃ  1000 centers tÆ°Æ¡ng á»©ng. Má»—i centers nÃ y Ä‘Æ°á»£c coi lÃ  má»™t <em>words</em>, vÃ  táº¥t cáº£ nhá»¯ng Ä‘iá»ƒm rÆ¡i vÃ o cÃ¹ng má»™t cluster Ä‘Æ°á»£c coi lÃ  cÃ¹ng má»™t bag. Vá»›i áº£nh trong táº­p test data, ta cÅ©ng láº¥y cÃ¡c patches rá»“i xem chÃºng rÆ¡i vÃ o nhá»¯ng bags nÃ o. Tá»« Ä‘Ã³ suy ra vector Ä‘áº·c trÆ°ng cho má»—i bá»©c áº£nh. ChÃº Ã½ ráº±ng vá»›i \(k = 1000\), má»—i bá»©c áº£nh sáº½ Ä‘Æ°á»£c <em>mÃ´ táº£</em> bá»Ÿi má»™t vector cÃ³ sá»‘ chiá»u 1000, tá»©c lÃ  má»—i Ä‘iá»ƒm dá»¯ liá»‡u bÃ¢y giá» Ä‘Ã£ cÃ³ sá»‘ chiá»u báº±ng nhau, máº·c dÃ¹ áº£nh thÃ´ Ä‘áº§u vÃ o cÃ³ thá»ƒ cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau.
<a name="feature-scaling-and-normalization"></a></p>

<h3 id="feature-scaling-and-normalization">Feature Scaling and Normalization</h3>
<p>(Tham kháº£o <a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature Scaling wiki</a>).</p>

<p>CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã´i khi Ä‘Æ°á»£c Ä‘o Ä‘áº¡c vá»›i nhá»¯ng Ä‘Æ¡n vá»‹ khÃ¡c nhau, m vÃ  feet cháº³ng háº¡n. Hoáº·c cÃ³ hai thÃ nh pháº§n (cá»§a vector dá»¯ liá»‡u) chÃªnh lá»‡ch nhau quÃ¡ lá»›n, má»™t thÃ nh pháº§n cÃ³ khoáº£ng giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1000, thÃ nh pháº§n kia chá»‰ cÃ³ khoáº£ng giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 1 cháº³ng háº¡n. LÃºc nÃ y, chÃºng ta cáº§n chuáº©n hÃ³a dá»¯ liá»‡u trÆ°á»›c khi thá»±c hiá»‡n cÃ¡c bÆ°á»›c tiáº¿p theo.</p>

<p><strong>ChÃº Ã½:</strong> viá»‡c chuáº©n hÃ³a nÃ y chá»‰ Ä‘Æ°á»£c thá»±c hiá»‡n khi vector dá»¯ liá»‡u Ä‘Ã£ cÃ³ cÃ¹ng chiá»u.</p>

<p>Má»™t vÃ i phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a thÆ°á»ng dÃ¹ng:
<a name="rescaling"></a></p>

<h4 id="rescaling">Rescaling</h4>
<p>PhÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nháº¥t lÃ  Ä‘Æ°a táº¥t cáº£ cÃ¡c thÃ nh pháº§n vá» cÃ¹ng má»™t khoáº£ng, \([0, 1]\) hoáº·c \([-1, 1]\) cháº³ng háº¡n, tÃ¹y thuá»™c vÃ o á»©ng dá»¥ng. Náº¿u muá»‘n Ä‘Æ°a má»™t thÃ nh pháº§n (feature) vá» khoáº£ng \([0, 1]\), cÃ´ng thá»©c sáº½ lÃ : 
\[
xâ€™ = \frac{x - \min(x)}{\max(x) - \min(x)}
\]
trong Ä‘Ã³ \(x\) lÃ  giÃ¡ trá»‹ ban Ä‘áº§u, \(xâ€™\) lÃ  giÃ¡ trá»‹ sau khi chuáº©n hÃ³a. \(\min(x), \max(x)\) Ä‘Æ°á»£c tÃ­nh trÃªn toÃ n bá»™ dá»¯ liá»‡u training data á»Ÿ cÃ¹ng má»™t thÃ nh pháº§n. Viá»‡c nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn tá»«ng thÃ nh pháº§n cá»§a vector dá»¯ liá»‡u \(\mathbf{x}\).</p>

<p><a name="standardization"></a></p>

<h4 id="standardization">Standardization</h4>
<p>Má»™t phÆ°Æ¡ng phÃ¡p ná»¯a cÅ©ng hay Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  giáº£ sá»­ má»—i thÃ nh pháº§n Ä‘á»u cÃ³ phÃ¢n phá»‘i chuáº©n vá»›i ká»³ vá»ng lÃ  0 vÃ  phÆ°Æ¡ng sai lÃ  1. Khi Ä‘Ã³, cÃ´ng thá»©c chuáº©n hÃ³a sáº½ lÃ : 
\[
xâ€™ = \frac{x - \bar{x}}{\sigma}
\]
vá»›i \(\bar{x}, \sigma\) láº§n lÆ°á»£t lÃ  ká»³ vá»ng vÃ  phÆ°Æ¡ng sai (standard deviation) cá»§a thÃ nh pháº§n Ä‘Ã³ trÃªn toÃ n bá»™ training data. 
<a name="scaling-to-unit-length"></a></p>

<h4 id="scaling-to-unit-length">Scaling to unit length</h4>
<p>Má»™t lá»±a chá»n khÃ¡c ná»¯a cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i lÃ  chuáº©n hÃ³a cÃ¡c thÃ nh pháº§n cá»§a má»—i vector dá»¯ liá»‡u sao cho toÃ n bá»™ vector cÃ³ Ä‘á»™ lá»›n (Euclid, tá»©c <a href="/math/#norm2">norm 2</a>) báº±ng 1. Viá»‡c nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng:
\[
\mathbf{x}â€™ = \frac{\mathbf{x}}{||\mathbf{x}||_2}
\]</p>

<p><a name="-thao-luan"></a></p>

<h2 id="4-tháº£o-luáº­n">4. Tháº£o luáº­n</h2>
<p>Xem ra tháº¿ giá»›i Machine Learning ráº¥t rá»™ng lá»›n vÃ  cÃ³ ráº¥t nhiá»u thá»© chÃºng ta cáº§n lÃ m. VÃ 
váº«n cÃ³ khÃ¡ nhiá»u thá»© tÃ´i cÃ³ thá»ƒ viáº¿t Ä‘Æ°á»£c. Tuy nhiÃªn, blog nÃ y sáº½ khÃ´ng táº­p trung nhiá»u vÃ o Feature Learning, máº·c dÃ¹ sáº½ cÃ³ má»™t vÃ i bÃ i nÃ³i vá» Dimensionality Reduction. TÃ´i sáº½ sá»­ dá»¥ng cÃ¡c bá»™ dá»¯ liá»‡u cÃ³ sáºµn, vÃ  Ä‘Ã£ qua bÆ°á»›c Feature Learning.</p>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-tÃ i-liá»‡u-tham-kháº£o">5. TÃ i liá»‡u tham kháº£o</h2>
<ol>
  <li><a href="https://en.wikipedia.org/wiki/Feature_engineering">Feature Enginieering - wiki</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature Scaling wiki</a></li>
  <li>Csurka, Gabriella, et al. â€œ<a href="https://people.eecs.berkeley.edu/~efros/courses/AP06/Papers/csurka-eccv-04.pdf">Visual categorization with bags of keypoints.</a>â€ Workshop on statistical learning in computer vision, ECCV. Vol. 1. No. 1-22. 2004.</li>
  <li><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words model - wiki</a></li>
  <li><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words">Bag of Words Meets Bags of Popcorn</a></li>
</ol>

:ET