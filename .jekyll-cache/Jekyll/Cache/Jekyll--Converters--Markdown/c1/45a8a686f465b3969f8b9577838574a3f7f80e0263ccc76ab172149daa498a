I"¹Ó<p><strong>Trong trang nÃ y:</strong></p>

<!-- MarkdownTOC -->

<ul>
  <li>
    <ol>
      <li>Naive Bayes Classifier</li>
    </ol>
  </li>
  <li>
    <ol>
      <li>CÃ¡c phÃ¢n phá»‘i thÆ°á»ng dÃ¹ng cho \(p(x_i | c)\)
        <ul>
          <li>2.1 Gaussian Naive Bayes</li>
          <li>2.2. Multinomial Naive Bayes</li>
          <li>2.3. Bernoulli Naive Bayes</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <ol>
      <li>VÃ­ dá»¥
        <ul>
          <li>3.1. Báº¯c hay Nam</li>
          <li>3.2. Báº¯c hay Nam vá»›i sklearn</li>
          <li>3.3. Naive Bayes Classifier cho bÃ i toÃ¡n Spam Filtering</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <ol>
      <li>TÃ³m táº¯t</li>
    </ol>
  </li>
  <li>
    <ol>
      <li>TÃ i liá»‡u tham kháº£o</li>
    </ol>
  </li>
</ul>

<!-- /MarkdownTOC -->

<p><em>Báº¡n Ä‘Æ°á»£c khuyáº¿n khÃ­ch Ä‘á»c <a href="/2017/07/17/mlemap/">BÃ i 31: Maximum Likelihood vÃ  Maximum A Posteriori estimation</a> trÆ°á»›c khi Ä‘á»c bÃ i nÃ y</em>
<a name="-naive-bayes-classifier"></a></p>

<h2 id="1-naive-bayes-classifier">1. Naive Bayes Classifier</h2>

<p>XÃ©t bÃ i toÃ¡n classification vá»›i \(C\) classes \(1, 2, \dots, C\). Giáº£ sá»­ cÃ³ má»™t Ä‘iá»ƒm dá»¯ liá»‡u \(\mathbf{x} \in \mathbb{R}^d\). HÃ£y tÃ­nh xÃ¡c suáº¥t Ä‘á»ƒ Ä‘iá»ƒm dá»¯ liá»‡u nÃ y rÆ¡i vÃ o class \(c\). NÃ³i cÃ¡ch khÃ¡c, hÃ£y tÃ­nh:</p>

<p>\[
p(y = c |\mathbf{x}) ~~~ (1)
\]
hoáº·c viáº¿t gá»n thÃ nh \(p(c|\mathbf{x})\).</p>

<p>Tá»©c tÃ­nh xÃ¡c suáº¥t Ä‘á»ƒ Ä‘áº§u ra lÃ  class \(c\) biáº¿t ráº±ng Ä‘áº§u vÃ o lÃ  vector \(\mathbf{x}\).</p>

<p>Biá»ƒu thá»©c nÃ y, náº¿u tÃ­nh Ä‘Æ°á»£c, sáº½ giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c xÃ¡c suáº¥t Ä‘á»ƒ Ä‘iá»ƒm dá»¯ liá»‡u rÆ¡i vÃ o má»—i class. Tá»« Ä‘Ã³ cÃ³ thá»ƒ giÃºp xÃ¡c Ä‘á»‹nh class cá»§a Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã³ báº±ng cÃ¡ch chá»n ra class cÃ³ xÃ¡c suáº¥t cao nháº¥t:</p>

<p>\[
c = \arg\max_{c \in \{1, \dots, C\}} p(c | \mathbf{x}) ~~~~ (2)
\]</p>

<p>Biá»ƒu thá»©c \((2)\) thÆ°á»ng khÃ³ Ä‘Æ°á»£c tÃ­nh trá»±c tiáº¿p. Thay vÃ o Ä‘Ã³, quy táº¯c Bayes thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng:</p>

<p>\[
\begin{eqnarray}
  c &amp; = &amp; \arg\max_c p(c | \mathbf{x}) &amp; (3) \<br />
      &amp; = &amp; \arg\max_c \frac{p(\mathbf{x} | c) p(c)}{p(\mathbf{x})} ~~~&amp; 4)\<br />
      &amp; = &amp; \arg\max_c p(\mathbf{x} | c) p(c) &amp; (5)\<br />
\end{eqnarray}
\]</p>

<p>Tá»« \((3)\) sang \((4)\) lÃ  vÃ¬ quy táº¯c Bayes. Tá»« \((4)\) sang \((5)\) lÃ  vÃ¬ máº«u sá»‘ \(p(\mathbf{x})\) khÃ´ng phá»¥ thuá»™c vÃ o \(c\).</p>

<p>Tiáº¿p tá»¥c xÃ©t biá»ƒu thá»©c \((5)\), \(p(c)\) cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu lÃ  xÃ¡c suáº¥t Ä‘á»ƒ má»™t Ä‘iá»ƒm rÆ¡i vÃ o class \(c\). GiÃ¡ trá»‹ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh báº±ng <a href="/2017/07/17/mlemap/#-maximum-likelihood-estimation">MLE</a>, tá»©c tá»‰ lá»‡ sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u trong táº­p training rÆ¡i vÃ o class nÃ y chia cho tá»•ng sá»‘ lÆ°á»£ng dá»¯ liá»‡u trong táº­p training; hoáº·c cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng <a href="/2017/07/17/mlemap/#-maximum-a-posteriori">MAP estimation</a>. TrÆ°á»ng há»£p thá»© nháº¥t thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u hÆ¡n.</p>

<p>ThÃ nh pháº§n cÃ²n láº¡i \(p(\mathbf{x} | c)\), tá»©c phÃ¢n phá»‘i cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u trong class \(c\), thÆ°á»ng ráº¥t khÃ³ tÃ­nh toÃ¡n vÃ¬ \(\mathbf{x}\) lÃ  má»™t biáº¿n ngáº«u nhiÃªn nhiá»u chiá»u, cáº§n ráº¥t ráº¥t nhiá»u dá»¯ liá»‡u training Ä‘á»ƒ cÃ³ thá»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c phÃ¢n phá»‘i Ä‘Ã³. Äá»ƒ giÃºp cho viá»‡c tÃ­nh toÃ¡n Ä‘Æ°á»£c Ä‘Æ¡n giáº£n, ngÆ°á»i ta thÆ°á»ng giáº£ sá»­ má»™t cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t ráº±ng cÃ¡c thÃ nh pháº§n cá»§a biáº¿n ngáº«u nhiÃªn \(\mathbf{x}\) lÃ  <a href="/2017/07/09/prob/#-independence">Ä‘á»™c láº­p vá»›i nhau</a>, náº¿u biáº¿t \(c\) (given \(c\)). Tá»©c lÃ :</p>

<p>\[
p(\mathbf{x} | c) = p(x_1, x_2, \dots, x_d | c) =  \prod_{i = 1}^d p(x_i | c) ~~~~~ (6)
\]</p>

<p>Giáº£ thiáº¿t cÃ¡c chiá»u cá»§a dá»¯ liá»‡u Ä‘á»™c láº­p vá»›i nhau, náº¿u biáº¿t \(c\), lÃ  quÃ¡ cháº·t vÃ  Ã­t khi tÃ¬m Ä‘Æ°á»£c dá»¯ liá»‡u mÃ  cÃ¡c thÃ nh pháº§n hoÃ n toÃ n Ä‘á»™c láº­p vá»›i nhau. Tuy nhiÃªn, giáº£ thiáº¿t <em>ngÃ¢y ngÃ´</em> nÃ y láº¡i mang láº¡i nhá»¯ng káº¿t quáº£ tá»‘t báº¥t ngá». Giáº£ thiáº¿t vá» sá»± Ä‘á»™c láº­p cá»§a cÃ¡c chiá»u dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c gá»i lÃ  <em>Naive Bayes</em> (xin khÃ´ng dá»‹ch). CÃ¡ch xÃ¡c Ä‘á»‹nh class cá»§a dá»¯ liá»‡u dá»±a trÃªn giáº£ thiáº¿t nÃ y cÃ³ tÃªn lÃ  <em>Naive Bayes Classifier (NBC)</em>.</p>

<p>NBC, nhá» vÃ o tÃ­nh Ä‘Æ¡n giáº£n má»™t cÃ¡ch <em>ngÃ¢y thÆ¡</em>, cÃ³ tá»‘c Ä‘á»™ training vÃ  test ráº¥t nhanh. Viá»‡c nÃ y giÃºp nÃ³ mang láº¡i hiá»‡u quáº£ cao trong cÃ¡c bÃ i toÃ¡n large-scale.</p>

<p>á» bÆ°á»›c <strong>training</strong>, cÃ¡c phÃ¢n phá»‘i \(p(c)\) vÃ  \(p(x_i | c), i = 1, \dots, d\) sáº½ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh dá»±a vÃ o training data. Viá»‡c xÃ¡c Ä‘á»‹nh cÃ¡c giÃ¡ trá»‹ nÃ y cÃ³ thá»ƒ dá»±a vÃ o <a href="/2017/07/17/mlemap/">Maximum Likelihood Estimation hoáº·c Maximum A Posteriori</a>.</p>

<p>á» bÆ°á»›c <strong>test</strong>, vá»›i má»™t Ä‘iá»ƒm dá»¯ liá»‡u má»›i \(\mathbf{x}\), class cá»§a nÃ³ sáº½ Ä‘Æ°á»£c xÃ¡c Ä‘inh bá»Ÿi:</p>

<p>\[
c = \arg\max_{c \in \{1, \dots, C\}} p(c) \prod_{i=1}^d p(x_i | c) ~~~~~ (7)
\]</p>

<p>Khi \(d\) lá»›n vÃ  cÃ¡c xÃ¡c suáº¥t nhá», biá»ƒu thá»©c á»Ÿ váº¿ pháº£i cá»§a \((7)\) sáº½ lÃ  má»™t sá»‘ ráº¥t nhá», khi tÃ­nh toÃ¡n cÃ³ thá»ƒ gáº·p sai sá»‘. Äá»ƒ giáº£i quyáº¿t viá»‡c nÃ y, \((7)\) thÆ°á»ng Ä‘Æ°á»£c viáº¿t láº¡i dÆ°á»›i dáº¡ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng báº±ng cÃ¡ch láº¥y \(\log\) cá»§a váº¿ pháº£i: 
\[
c = \arg\max_{c \in \{1, \dots, C\}} = \log(p(c)) + \sum_{i=1}^d \log(p(x_i | c)) ~~~~ (7.1)
\]</p>

<p>Viá»‡c nÃ y khÃ´ng áº£nh hÆ°á»Ÿng tá»›i káº¿t quáº£ vÃ¬ \(\log\) lÃ  má»™t hÃ m Ä‘á»“ng biáº¿n trÃªn táº­p cÃ¡c sá»‘ dÆ°Æ¡ng.</p>

<!-- LÃ½ thuyáº¿t vá» Naive Bayes Classifier cÃ³ thá»ƒ dá»«ng láº¡i á»Ÿ Ä‘Ã¢y (_tháº­t lÃ  naive_). ChÃºng ta sáº½ hiá»ƒu rÃµ hÆ¡n phÆ°Æ¡ng phÃ¡p nÃ y thÃ´ng qua cÃ¡c vÃ­ dá»¥.  -->
<p>Máº·c dÃ¹ giáº£ thiáº¿t mÃ  Naive Bayes Classifiers sá»­ dá»¥ng lÃ  quÃ¡ phi thá»±c táº¿, chÃºng váº«n hoáº¡t Ä‘á»™ng khÃ¡ hiá»‡u quáº£ trong nhiá»u bÃ i toÃ¡n thá»±c táº¿, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i vÄƒn báº£n, vÃ­ dá»¥ nhÆ° lá»c tin nháº¯n rÃ¡c hay lá»c email spam. Trong pháº§n sau cá»§a bÃ i viáº¿t, chÃºng ta cÃ¹ng xÃ¢y dá»±ng má»™t bá»™ lá»c email spam tiáº¿ng Anh Ä‘Æ¡n giáº£n.</p>

<p>Cáº£ viá»‡c training vÃ  test cá»§a NBC lÃ  cá»±c ká»³ nhanh khi so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p classification phá»©c táº¡p khÃ¡c. Viá»‡c giáº£ sá»­ cÃ¡c thÃ nh pháº§n trong dá»¯ liá»‡u lÃ  Ä‘á»™c láº­p vá»›i nhau, náº¿u biáº¿t class, khiáº¿n cho viá»‡c tÃ­nh toÃ¡n má»—i phÃ¢n phá»‘i \(p(\mathbf{x}_i|c)\) trá»Ÿ nÃªn cá»±c ká»³ nhanh.</p>

<p>Má»—i giÃ¡ trá»‹ \(p(c), c = 1, 2, \dots, C\) cÃ³ thá»ƒ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh nhÆ° lÃ  táº§n suáº¥t xuáº¥t hiá»‡n cá»§a class \(c\) trong training data.</p>

<p>Viá»‡c tÃ­nh toÃ¡n \(p(\mathbf{x_i} | c) \) phá»¥ thuá»™c vÃ o loáº¡i dá»¯ liá»‡u. <a href="http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes">CÃ³ ba loáº¡i Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n</a> lÃ : Gaussian Naive Bayes, Multinomial Naive Bayes, vÃ  Bernoulli Naive .</p>

<p><a name="-cac-phan-phoi-thuong-dung-cho-\\pxi-\|-c\\"></a></p>

<h2 id="2-cÃ¡c-phÃ¢n-phá»‘i-thÆ°á»ng-dÃ¹ng-cho-px_i--c">2. CÃ¡c phÃ¢n phá»‘i thÆ°á»ng dÃ¹ng cho \(p(x_i | c)\)</h2>

<p><em>Má»¥c nÃ y chá»§ yáº¿u Ä‘Æ°á»£c dá»‹ch tá»« <a href="http://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes">tÃ i liá»‡u cá»§a thÆ° viá»‡n sklearn</a>.</em>
<a name="-gaussian-naive-bayes"></a></p>

<h3 id="21-gaussian-naive-bayes">2.1 Gaussian Naive Bayes</h3>

<p>MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng chá»§ yáº¿u trong loáº¡i dá»¯ liá»‡u mÃ  cÃ¡c thÃ nh pháº§n lÃ  cÃ¡c biáº¿n liÃªn tá»¥c.</p>

<p>Vá»›i má»—i chiá»u dá»¯ liá»‡u \(i\) vÃ  má»™t class \(c\), \(x_i\) tuÃ¢n theo má»™t phÃ¢n phá»‘i chuáº©n cÃ³ ká»³ vá»ng \(\mu_{ci}\) vÃ  phÆ°Æ¡ng sai \(\sigma_{ci}^2\):</p>

<p>\[
p(x_i|c) = p(x_i | \mu_{ci}, \sigma_{ci}^2) =  \frac{1}{\sqrt{2\pi \sigma_{ci}^2}} \exp\left(- \frac{(x_i - \mu_{ci})^2}{2 \sigma_{ci}^2}\right) ~~~~ (8)
\]</p>

<p>Trong Ä‘Ã³, bá»™ tham sá»‘ \(\theta = \{\mu_{ci}, \sigma_{ci}^2\}\) Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh báº±ng Maximum Likelihood:</p>

<p>\[
(\mu_{ci}, \sigma_{ci}^2) = \arg\max_{\mu_{ci}, \sigma_{ci}^2} \prod_{n = 1}^N p(x_i^{(n)} | \mu_{ci}, \sigma_{ci}^2) ~~~~ (9)
\]</p>

<p><em>ÄÃ¢y lÃ  cÃ¡ch tÃ­nh cá»§a thÆ° viá»‡n sklearn. ChÃºng ta cÅ©ng cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c tham sá»‘ báº±ng MAP náº¿u biáº¿t trÆ°á»›c priors cá»§a \(\mu_{ci}\) vÃ  \(\sigma^2_{ci}\)</em></p>

<p><a name="-multinomial-naive-bayes"></a></p>

<h3 id="22-multinomial-naive-bayes">2.2. Multinomial Naive Bayes</h3>
<p>MÃ´ hÃ¬nh nÃ y chá»§ yáº¿u Ä‘Æ°á»£c sá»­ dá»¥ng trong phÃ¢n loáº¡i vÄƒn báº£n mÃ  feature vectors Ä‘Æ°á»£c tÃ­nh báº±ng <a href="https://machinelearningcoban.com/general/2017/02/06/featureengineering/#bag-of-words">Bags of Words</a>. LÃºc nÃ y, má»—i vÄƒn báº£n Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi má»™t vector cÃ³ Ä‘á»™ dÃ i \(d\) chÃ­nh lÃ  sá»‘ tá»« trong tá»« Ä‘iá»ƒn. GiÃ¡ trá»‹ cá»§a thÃ nh pháº§n thá»© \(i\) trong má»—i vector chÃ­nh lÃ  sá»‘ láº§n tá»« thá»© \(i\) xuáº¥t hiá»‡n trong vÄƒn báº£n Ä‘Ã³.</p>

<p>Khi Ä‘Ã³, \(p(x_i |c) \) tá»‰ lá»‡ vá»›i táº§n suáº¥t tá»« thá»© \(i\) (hay feature thá»© \(i\) cho trÆ°á»ng há»£p tá»•ng quÃ¡t) xuáº¥t hiá»‡n trong cÃ¡c vÄƒn báº£n cá»§a class \(c\). GiÃ¡ trá»‹ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh báº±ng cÃ¡ch: 
\[
\lambda_{ci} = p(x_i | c) = \frac{N_{ci}}{N_c} ~~~~ (10)
\]
Trong Ä‘Ã³:</p>

<ul>
  <li>
    <p>\(N_{ci}\) lÃ  tá»•ng sá»‘ láº§n tá»« thá»© \(i\) xuáº¥t hiá»‡n trong cÃ¡c vÄƒn báº£n cá»§a class \(c\), nÃ³ Ä‘Æ°á»£c tÃ­nh lÃ  tá»•ng cá»§a táº¥t cáº£ cÃ¡c thÃ nh pháº§n thá»© \(i\) cá»§a cÃ¡c feature vectors á»©ng vá»›i class \(c\).</p>
  </li>
  <li>
    <p>\(N_c\) lÃ  tá»•ng sá»‘ tá»« (ká»ƒ cáº£ láº·p) xuáº¥t hiá»‡n trong class \(c\). NÃ³i cÃ¡ch khÃ¡c, nÃ³ báº±ng tá»•ng Ä‘á»™ dÃ i cá»§a toÃ n bá»™ cÃ¡c vÄƒn báº£n thuá»™c vÃ o class \(c\). CÃ³ thá»ƒ suy ra ráº±ng \(N_c = \sum_{i = 1}^d N_{ci}\), tá»« Ä‘Ã³ \(\sum_{i=1}^d \lambda_{ci} = 1\).</p>
  </li>
</ul>

<p>CÃ¡ch tÃ­nh nÃ y cÃ³ má»™t háº¡n cháº¿ lÃ  náº¿u cÃ³ má»™t tá»« má»›i chÆ°a bao giá» xuáº¥t hiá»‡n trong class \(c\) thÃ¬ biá»ƒu thá»©c \((10)\) sáº½ báº±ng 0, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n váº¿ pháº£i cá»§a \((7)\) báº±ng 0 báº¥t ká»ƒ cÃ¡c giÃ¡ trá»‹ cÃ²n láº¡i cÃ³ lá»›n tháº¿ nÃ o. Viá»‡c nÃ y sáº½ dáº«n Ä‘áº¿n káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c (xem thÃªm vÃ­ dá»¥ á»Ÿ má»¥c sau).</p>

<p>Äá»ƒ giáº£i quyáº¿t viá»‡c nÃ y, má»™t ká»¹ thuáº­t Ä‘Æ°á»£c gá»i lÃ  <em>Laplace smoothing</em> Ä‘Æ°á»£c Ã¡p dá»¥ng:</p>

<p>\[
\hat{\lambda}_{ci} = \frac{N_{ci} + \alpha}{N_{c} + d\alpha} ~~~~~~ (11)
\]</p>

<p>Vá»›i \(\alpha\) lÃ  má»™t sá»‘ dÆ°Æ¡ng, thÆ°á»ng báº±ng 1, Ä‘á»ƒ trÃ¡nh trÆ°á»ng há»£p tá»­ sá»‘ báº±ng 0. Máº«u sá»‘ Ä‘Æ°á»£c cá»™ng vá»›i \(d\alpha\) Ä‘á»ƒ Ä‘áº£m báº£o tá»•ng xÃ¡c suáº¥t \(\sum_{i=1}^d \hat{\lambda}_{ci} = 1\).</p>

<p>NhÆ° váº­y, má»—i class \(c\) sáº½ Ä‘Æ°á»£c mÃ´ táº£ bá»Ÿi bá»™ cÃ¡c sá»‘ dÆ°Æ¡ng cÃ³ tá»•ng báº±ng 1: \(\hat{\lambda}_c = \{\hat{\lambda}_{c1}, \dots, \hat{\lambda}_{cd}\}\).</p>

<p><a name="-bernoulli-naive-bayes"></a></p>

<h3 id="23-bernoulli-naive-bayes">2.3. Bernoulli Naive Bayes</h3>

<p>MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c loáº¡i dá»¯ liá»‡u mÃ  má»—i thÃ nh pháº§n lÃ  má»™t giÃ¡ trá»‹ binary - báº³ng 0 hoáº·c 1. VÃ­ dá»¥: cÅ©ng vá»›i loáº¡i vÄƒn báº£n nhÆ°ng thay vÃ¬ Ä‘áº¿m tá»•ng sá»‘ láº§n xuáº¥t hiá»‡n cá»§a 1 tá»« trong vÄƒn báº£n, ta chá»‰ cáº§n quan tÃ¢m tá»« Ä‘Ã³ cÃ³ xuáº¥t hiá»‡n hay khÃ´ng.</p>

<p>Khi Ä‘Ã³, \(p(x_i | c) \) Ä‘Æ°á»£c tÃ­nh báº±ng: 
\[
p(x_i | c) = p(i | c)^{x_i} (1 - p(i | c) ^{1 - x_i}
\]
vá»›i \(p(i | c)\) cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu lÃ  xÃ¡c suáº¥t tá»« thá»© \(i\) xuáº¥t hiá»‡n trong cÃ¡c vÄƒn báº£n cá»§a class \(c\).</p>

<p><a name="-vi-du"></a></p>

<h2 id="3-vÃ­-dá»¥">3. VÃ­ dá»¥</h2>

<p><a name="-bac-hay-nam"></a></p>

<h3 id="31-báº¯c-hay-nam">3.1. Báº¯c hay Nam</h3>
<p>Giáº£ sá»­ trong táº­p training cÃ³ cÃ¡c vÄƒn báº£n \(\text{d1, d2, d3, d4}\) nhÆ° trong báº£ng dÆ°á»›i Ä‘Ã¢y. Má»—i vÄƒn báº£n nÃ y thuá»™c vÃ o 1 trong 2 classes: \(\text{B}\) (<em>Báº¯c</em>) hoáº·c \(\text{N}\) (<em>Nam</em>). HÃ£y xÃ¡c Ä‘á»‹nh class cá»§a vÄƒn báº£n \(\text{d5}\).</p>

<table>
  <thead>
    <tr>
      <th>Â </th>
      <th style="text-align: center">Document</th>
      <th>Content</th>
      <th style="text-align: center">Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Training</strong></td>
      <td style="text-align: center">\(\text{d1}\)</td>
      <td>\(\text{hanoi pho chaolong hanoi}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>Â </td>
      <td style="text-align: center">\(\text{d2}\)</td>
      <td>\(\text{hanoi buncha pho omai}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>Â </td>
      <td style="text-align: center">\(\text{d3}\)</td>
      <td>\(\text{pho banhgio omai}\)</td>
      <td style="text-align: center">\(\text{B}\)</td>
    </tr>
    <tr>
      <td>Â </td>
      <td style="text-align: center">\(\text{d4}\)</td>
      <td>\(\text{saigon hutiu banhbo pho}\)</td>
      <td style="text-align: center">\(\text{N}\)</td>
    </tr>
    <tr>
      <td><strong>Test</strong></td>
      <td style="text-align: center">\(\text{d5}\)</td>
      <td>\(\text{hanoi hanoi buncha hutiu}\)</td>
      <td style="text-align: center">?</td>
    </tr>
  </tbody>
</table>

<p><br />
Ta cÃ³ thá»ƒ dá»± Ä‘oÃ¡n ráº±ng \(\text{d5}\) thuá»™c class <em>Báº¯c</em>.</p>

<p>BÃ i toÃ¡n nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i quyáº¿t bá»Ÿi hai mÃ´ hÃ¬nh: Multinomial Naive Bayes vÃ  Bernoulli Naive Bayes. TÃ´i sáº½ lÃ m vÃ­ dá»¥ minh hoáº¡ vá»›i mÃ´ hÃ¬nh thá»© nháº¥t vÃ  thá»±c hiá»‡n code cho cáº£ hai mÃ´ hÃ¬nh. Viá»‡c mÃ´ hÃ¬nh nÃ o tá»‘t hÆ¡n phá»¥ thuá»™c vÃ o má»—i bÃ i toÃ¡n. ChÃºng ta cÃ³ thá»ƒ thá»­ cáº£ hai Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh tá»‘t hÆ¡n.</p>

<p>Nháº­n tháº¥y ráº±ng á»Ÿ Ä‘Ã¢y cÃ³ 2 class \(\text{B}\) vÃ  \(\text{N}\), ta cáº§n Ä‘i tÃ¬m \(p(\text{B})\) vÃ  \(p(\text{N})\). Ã  dá»±a trÃªn táº§n sá»‘ xuáº¥t hiá»‡n cá»§a má»—i class trong táº­p training. Ta sáº½ cÃ³:</p>

<p>\[
p(\text{B}) = \frac{3}{4}, ~~~~~ p(\text{N}) = \frac{1}{4} ~~~~~~ (8)
\]</p>

<p>Táº­p há»£p toÃ n bá»™ cÃ¡c tá»« trong vÄƒn báº£n, hay cÃ²n gá»i lÃ  tá»« Ä‘iá»ƒn, lÃ : \(V = \{\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\}\). Tá»•ng cá»™ng sá»‘ pháº§n tá»­ trong tá»« Ä‘iá»ƒn lÃ  \(|V| = 9\).</p>

<p>HÃ¬nh dÆ°á»›i Ä‘Ã¢y minh hoáº¡ quÃ¡ trÃ¬nh Training vÃ  Test cho bÃ i toÃ¡n nÃ y khi sá»­ dá»¥ng Multinomial Naive Bayes, trong Ä‘Ã³ cÃ³ sá»­ dá»¥ng Laplace smoothing vá»›i \(\alpha = 1\).</p>

<hr />

<div class="imgcap">
<img src="/assets/32_nbc/nbc.png" align="center" width="100%" />
</div>

<div class="thecap" style="text-align: center">HÃ¬nh 1: Minh hoáº¡ Multinomial Naive Bayes.</div>
<hr />

<p>ChÃº Ã½, hai giÃ¡ trá»‹ tÃ¬m Ä‘Æ°á»£c \(1.5\times 10^{-4}\) vÃ  \(1.75\times 10^{-5}\) khÃ´ng pháº£i lÃ  hai xÃ¡c suáº¥t cáº§n tÃ¬m mÃ  chá»‰ lÃ  hai Ä‘áº¡i lÆ°á»£ng <strong>tá»‰ lá»‡ thuáº­n</strong> vá»›i hai xÃ¡c suáº¥t Ä‘Ã³. Äá»ƒ tÃ­nh cá»¥ thá»ƒ, ta cÃ³ thá»ƒ lÃ m nhÆ° sau:</p>

<p>\[
p(\text{B} | \text{d5}) = \frac{1.5\times 10^{-4}}{1.5\times 10^{-4} + 1.75\times 10^{-5}} \approx 0.8955, ~~~~ p(\text{N} | \text{d5}) = 1 - p(\text{B} | \text{d5}) \approx 0.1045
\]</p>

<p>Báº¡n Ä‘á»c cÃ³ thá»ƒ tá»± tÃ­nh vá»›i vÃ­ dá»¥ khÃ¡c: \(\text{d6 = pho hutiu banhbo}\). Náº¿u báº¡n vÃ  tÃ´i tÃ­nh ra káº¿t quáº£ giá»‘ng nhau, chÃºng ta sáº½ thu Ä‘Æ°á»£c:
\[
p(\text{B} | \text{d6}) \approx 0.29, ~~~~ p(\text{N} | \text{d6}) \approx 0.71
\]</p>

<p>vÃ  suy ra \(\text{d6}\) thuá»™c vÃ o class <em>Nam</em>.
<a name="-bac-hay-nam-voi-sklearn"></a></p>

<h3 id="32-báº¯c-hay-nam-vá»›i-sklearn">3.2. Báº¯c hay Nam vá»›i sklearn</h3>

<p>Äá»ƒ kiá»ƒm tra láº¡i cÃ¡c phÃ©p tÃ­nh toÃ¡n phÃ­a trÃªn, chÃºng ta cÃ¹ng giáº£i quyáº¿t bÃ i toÃ¡n nÃ y vá»›i <a href="http://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB">sklearn</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 

<span class="c1"># train data
</span><span class="n">d1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">d3</span><span class="p">,</span> <span class="n">d4</span><span class="p">])</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">])</span> 

<span class="c1"># test data
</span><span class="n">d5</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">d6</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1">## call MultinomialNB
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="c1"># training 
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">'Predicting class of d5:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Probability of d6 in each class:'</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">d6</span><span class="p">))</span>
</code></pre></div></div>

<p>Káº¿t quáº£:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predicting class of d5: B
Probability of d6 in each class: [[ 0.29175335  0.70824665]]
</code></pre></div></div>

<p>Náº¿u sá»­ dá»¥ng mÃ´ hÃ¬nh Bernoulli Naive Bayes, chÃºng ta cáº§n thay Ä‘á»•i má»™t chÃºt vá» feature vectors. LÃºc nÃ y, cÃ¡c giÃ¡ trá»‹ khÃ¡c khÃ´ng sáº½ Ä‘á»u Ä‘Æ°á»£c Ä‘Æ°a vá» 1 vÃ¬ ta chá»‰ quan tÃ¢m Ä‘áº¿n viá»‡c tá»« Ä‘Ã³ cÃ³ xuáº¥t hiá»‡n trong vÄƒn báº£n khÃ´ng.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 

<span class="c1"># train data
</span><span class="n">d1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">d4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">d3</span><span class="p">,</span> <span class="n">d4</span><span class="p">])</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">])</span> <span class="c1"># 0 - B, 1 - N 
</span>
<span class="c1"># test data
</span><span class="n">d5</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">d6</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1">## call MultinomialNB
</span><span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="c1"># training 
</span><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">'Predicting class of d5:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Probability of d6 in each class:'</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">d6</span><span class="p">))</span>
</code></pre></div></div>

<p>Káº¿t quáº£:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Predicting class of d5: B
Probability of d6 in each class: [[ 0.16948581  0.83051419]]
</code></pre></div></div>

<p>Ta tháº¥y ráº±ng, vá»›i bÃ i toÃ¡n nhá» nÃ y, cáº£ hai mÃ´ hÃ¬nh Ä‘á»u cho káº¿t quáº£ giá»‘ng nhau (xÃ¡c suáº¥t tÃ¬m Ä‘Æ°á»£c khÃ¡c nhau nhÆ°ng khÃ´ng áº£nh hÆ°á»Ÿng tá»›i quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng).</p>

<p><a name="-naive-bayes-classifier-cho-bai-toan-spam-filtering"></a></p>

<h3 id="33-naive-bayes-classifier-cho-bÃ i-toÃ¡n-spam-filtering">3.3. Naive Bayes Classifier cho bÃ i toÃ¡n Spam Filtering</h3>

<p>Dá»¯ liá»‡u trong vÃ­ dá»¥ nÃ y Ä‘Æ°á»£c láº¥y trong <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">Exercise 6: Naive Bayes - Machine Learning - Andrew Ng</a>.</p>

<p>Trong vÃ­ dá»¥ nÃ y, dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½, vÃ  lÃ  má»™t táº­p con cá»§a cÆ¡ sá»Ÿ dá»¯ liá»‡u <a href="http://csmining.org/index.php/ling-spam-datasets.html">Ling-Spam Dataset</a>.</p>

<p><strong>MÃ´ táº£ dá»¯ liá»‡u:</strong></p>

<p>Táº­p dá»¯ liá»‡u nÃ y bao gá»“m tá»•ng cá»™ng 960 emails tiáº¿ng Anh, Ä‘Æ°á»£c tÃ¡ch thÃ nh táº­p training vÃ  test theo tá»‰ lá»‡ 700:260, 50% trong má»—i táº­p lÃ  cÃ¡c spam emails.</p>

<p>Dá»¯ liá»‡u trong cÆ¡ sá»Ÿ dá»¯ liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ khÃ¡ Ä‘áº¹p. CÃ¡c quy táº¯c xá»­ lÃ½ nhÆ° sau:</p>

<ol>
  <li>
    <p><strong>Loáº¡i bá» <em>stop words</em></strong>: Nhá»¯ng tá»« xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn nhÆ° â€˜andâ€™, â€˜theâ€™, â€˜ofâ€™, â€¦ Ä‘Æ°á»£c loáº¡i bá».</p>
  </li>
  <li>
    <p><strong>Lemmatization</strong>: Nhá»¯ng tá»« cÃ³ cÃ¹ng â€˜gá»‘câ€™ Ä‘Æ°á»£c Ä‘Æ°a vá» cÃ¹ng loáº¡i. VÃ­ dá»¥, â€˜includeâ€™, â€˜includesâ€™, â€˜includedâ€™ Ä‘á»u Ä‘Æ°á»£c Ä‘Æ°a chung vá» â€˜includeâ€™. Táº¥t cáº£ cÃ¡c tá»« cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ°a vá» dáº¡ng kÃ½ tá»± thÆ°á»ng (khÃ´ng pháº£i HOA).</p>
  </li>
  <li>
    <p><strong>Loáº¡i bá» <em>non-words</em></strong>: Sá»‘, dáº¥u cÃ¢u, kÃ½ tá»± â€˜tabsâ€™, kÃ½ tá»± â€˜xuá»‘ng dÃ²ngâ€™ Ä‘Ã£ Ä‘Æ°á»£c loáº¡i bá».</p>
  </li>
</ol>

<p>DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ cá»§a 1 email khÃ´ng pháº£i spam, <strong>trÆ°á»›c khi Ä‘Æ°á»£c xá»­ lÃ½</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Subject: Re: 5.1344 Native speaker intuitions
  
The discussion on native speaker intuitions has been extremely interesting, 
but I worry that my brief intervention may have muddied the waters. I take 
it that there are a number of separable issues. The first is the extent to
which a native speaker is likely to judge a lexical string as grammatical 
or ungrammatical per se. The second is concerned with the relationships 
between syntax and interpretation (although even here the distinction may 
not be entirely clear cut). 
</code></pre></div></div>

<p>vÃ  <strong>sau khi Ä‘Æ°á»£c xá»­ lÃ½</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re native speaker intuition discussion native speaker intuition extremely 
interest worry brief intervention muddy waters number separable issue first 
extent native speaker likely judge lexical string grammatical ungrammatical 
per se second concern relationship between syntax interpretation although 
even here distinction entirely clear cut 
</code></pre></div></div>

<p>VÃ  Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ vá» <strong>spam email sau khi Ä‘Æ°á»£c xá»­ lÃ½</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>financial freedom follow financial freedom work ethic extraordinary desire 
earn least per month work home special skills experience required train 
personal support need ensure success legitimate homebased income 
opportunity put back control finance life ve try opportunity past 
fail live promise 
</code></pre></div></div>

<p>ChÃºng ta tháº¥y ráº±ng trong Ä‘oáº¡n nÃ y cÃ³ cÃ¡c tá»« nhÆ°: <em>financial, extraordinary, earn, opportunity, â€¦</em> lÃ  nhá»¯ng tá»« thÆ°á»ng tháº¥y trong cÃ¡c email spam.</p>

<p>Trong vÃ­ dá»¥ nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng Multinomial Naive Bayes.</p>

<p>Äá»ƒ cho bÃ i toÃ¡n Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÆ¡n, tÃ´i tiáº¿p tá»¥c sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½, cÃ³ thá»ƒ Ä‘Æ°á»£c download á»Ÿ Ä‘Ã¢y: <a href="http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/exercises/ex6materials/ex6DataPrepared.zip">ex6DataPrepared.zip</a>. Trong folder sau khi giáº£i nÃ©n, chÃºng ta sáº½ tháº¥y cÃ¡c files:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test-features.txt
test-labels.txt
train-features-50.txt
train-features-100.txt
train-features-400.txt
train-features.txt
train-labels-50.txt
train-labels-100.txt
train-labels-400.txt
train-labels.txt
</code></pre></div></div>

<p>tÆ°Æ¡ng á»©ng vá»›i cÃ¡c file chá»©a dá»¯ liá»‡u cá»§a táº­p training vÃ  táº­p test. File <code class="language-plaintext highlighter-rouge">train-features-50.txt</code> chá»©a dá»¯ liá»‡u cá»§a táº­p training thu gá»n vá»›i chá»‰ cÃ³ tá»•ng cá»™ng 50 training emails.</p>

<p>Má»—i file <code class="language-plaintext highlighter-rouge">*labels*.txt</code> chá»©a nhiá»u dÃ²ng, má»—i dÃ²ng lÃ  má»™t kÃ½ tá»± 0 hoáº·c 1 thá»ƒ hiá»‡n email lÃ  <em>non-spam</em> hoáº·c <em>spam</em>.</p>

<p>Má»—i file <code class="language-plaintext highlighter-rouge">*features*.txt</code> chá»©a nhiá»u dÃ²ng, má»—i dÃ²ng cÃ³ 3 sá»‘, vÃ­ dá»¥:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 564 1
1 19 2
</code></pre></div></div>

<p>trong Ä‘Ã³ sá»‘ Ä‘áº§u tiÃªn lÃ  chá»‰ sá»‘ cá»§a email, báº¯t Ä‘áº§u tá»« 1; sá»‘ thá»© hai lÃ  thá»© tá»± cá»§a tá»« trong tá»« Ä‘iá»ƒn (tá»•ng cá»™ng 2500 tá»«); sá»‘ thá»© ba lÃ  sá»‘ lÆ°á»£ng cá»§a tá»« Ä‘Ã³ trong email Ä‘ang xÃ©t. DÃ²ng Ä‘áº§u tiÃªn nÃ³i ráº±ng trong email thá»© nháº¥t, tá»« thá»© 564 trong tá»« Ä‘iá»ƒn xuáº¥t hiá»‡n 1 láº§n. CÃ¡ch lÆ°u dá»¯ liá»‡u nhÆ° tháº¿ nÃ y giÃºp tiáº¿t kiá»‡m bá»™ nhá»› vÃ¬ 1 email thÆ°á»ng khÃ´ng chá»©a háº¿t táº¥t cáº£ cÃ¡c tá»« trong tá»« Ä‘iá»ƒn mÃ  chá»‰ chá»©a má»™t lÆ°á»£ng nhá», ta chá»‰ cáº§n lÆ°u cÃ¡c giÃ¡ trá»‹ khÃ¡c khÃ´ng.</p>

<p>Náº¿u ta biá»ƒu diá»…n feature vector cá»§a má»—i email lÃ  má»™t vector hÃ ng cÃ³ Ä‘á»™ dÃ i báº±ng Ä‘á»™ dÃ i tá»« Ä‘iá»ƒn (2500) thÃ¬ dÃ²ng thá»© nháº¥t nÃ³i ráº±ng thÃ nh pháº§n thá»© 564 cá»§a vector nÃ y báº±ng 1. TÆ°Æ¡ng tá»±, thÃ nh pháº§n thá»© 19 cá»§a vector nÃ y báº±ng 1. Náº¿u khÃ´ng xuáº¥t hiá»‡n, cÃ¡c thÃ nh pháº§n khÃ¡c Ä‘Æ°á»£c máº·c Ä‘á»‹nh báº±ng 0.</p>

<p>Dá»±a trÃªn cÃ¡c thÃ´ng tin nÃ y, chÃºng ta cÃ³ thá»ƒ tiáº¿n hÃ nh láº­p trÃ¬nh vá»›i thÆ° viá»‡n sklearn.</p>

<p><strong>Khai bÃ¡o thÆ° viá»‡n vÃ  Ä‘Æ°á»ng dáº«n tá»›i files:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## packages 
</span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span> <span class="c1"># for sparse matrix
</span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span><span class="p">,</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span> <span class="c1"># for evaluating results
</span>
<span class="c1"># data path and file name 
</span><span class="n">path</span> <span class="o">=</span> <span class="s">'ex6DataPrepared/'</span>
<span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>
</code></pre></div></div>

<p>HÃ m sá»‘ Ä‘á»c dá»¯ liá»‡u tá»« file <code class="language-plaintext highlighter-rouge">data_fn</code> vá»›i labels tÆ°Æ¡ng á»©ng <code class="language-plaintext highlighter-rouge">label_fn</code>. ChÃº Ã½ ráº±ng <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">sá»‘ lÆ°á»£ng tá»« trong tá»« Ä‘iá»ƒn lÃ  2500</a>.</p>

<p>Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u trong má»™t ma tráº­n mÃ  má»—i hÃ ng thá»ƒ hiá»‡n má»™t email. Ma tráº­n nÃ y lÃ  má»™t ma tráº­n sparse nÃªn chÃºng ta sáº½ sá»­ dá»¥ng hÃ m <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html"><code class="language-plaintext highlighter-rouge">scipy.sparse.coo_matrix</code></a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nwords</span> <span class="o">=</span> <span class="mi">2500</span> 

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">data_fn</span><span class="p">,</span> <span class="n">label_fn</span><span class="p">):</span>
    <span class="c1">## read label_fn
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">label_fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">content</span><span class="p">]</span>

    <span class="c1">## read data_fn
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">data_fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="c1"># remove '\n' at the end of each line
</span>    <span class="n">content</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">content</span><span class="p">]</span> 

    <span class="n">dat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">content</span><span class="p">),</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">content</span><span class="p">):</span> 
        <span class="n">a</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
        <span class="n">dat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">])])</span>
    
    <span class="c1"># remember to -1 at coordinate since we're in Python
</span>    <span class="c1"># check this: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html
</span>    <span class="c1"># for more information about coo_matrix function 
</span>    <span class="n">data</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">((</span><span class="n">dat</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="n">dat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dat</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>\
             <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">nwords</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</code></pre></div></div>

<p>Äá»c training data vÃ  test data, sá»­ dá»¥ng class <code class="language-plaintext highlighter-rouge">MultinomialNB</code> trong sklearn Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh vÃ  dá»± Ä‘oÃ¡n Ä‘áº§u ra cho test data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 700, accuracy = 98.08%
</code></pre></div></div>

<p>Váº­y lÃ  cÃ³ tá»›i 98.08% cÃ¡c email Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng. ChÃºng ta tiáº¿p tá»¥c thá»­ vá»›i cÃ¡c bá»™ dá»¯ liá»‡u training nhá» hÆ¡n:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features-100.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels-100.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>

<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 100, accuracy = 97.69%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data_fn</span> <span class="o">=</span> <span class="s">'train-features-50.txt'</span>
<span class="n">train_label_fn</span> <span class="o">=</span> <span class="s">'train-labels-50.txt'</span>
<span class="n">test_data_fn</span> <span class="o">=</span> <span class="s">'test-features.txt'</span>
<span class="n">test_label_fn</span> <span class="o">=</span> <span class="s">'test-labels.txt'</span>

<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">train_data_fn</span><span class="p">,</span> <span class="n">train_label_fn</span><span class="p">)</span>
<span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>  <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">test_data_fn</span><span class="p">,</span> <span class="n">test_label_fn</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 50, accuracy = 97.31%
</code></pre></div></div>

<p>Ta tháº¥y ráº±ng tháº­m chÃ­ khi táº­p training lÃ  ráº¥t nhá», 50 emails tá»•ng cá»™ng, káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c Ä‘Ã£ ráº¥t áº¥n tÆ°á»£ng.</p>

<p>Náº¿u báº¡n muá»‘n tiáº¿p tá»¥c thá»­ mÃ´ hÃ¬nh <code class="language-plaintext highlighter-rouge">BernoulliNB</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">(</span><span class="n">binarize</span> <span class="o">=</span> <span class="p">.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training size = %d, accuracy = %.2f%%'</span> <span class="o">%</span> \
      <span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size = 50, accuracy = 69.62%
</code></pre></div></div>

<p>Ta tháº¥y ráº±ng trong bÃ i toÃ¡n nÃ y, <code class="language-plaintext highlighter-rouge">MultinomialNB</code> hoáº¡t Ä‘á»™ng hiá»‡u quáº£ hÆ¡n.</p>

<p><a name="-tom-tat"></a></p>

<h2 id="4-tÃ³m-táº¯t">4. TÃ³m táº¯t</h2>

<ul>
  <li>
    <p>Naive Bayes Classifiers (NBC) thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n Text Classification.</p>
  </li>
  <li>
    <p>NBC cÃ³ thá»i gian training vÃ  test ráº¥t nhanh. Äiá»u nÃ y cÃ³ Ä‘Æ°á»£c lÃ  do giáº£ sá»­ vá» tÃ­nh Ä‘á»™c láº­p giá»¯a cÃ¡c thÃ nh pháº§n, náº¿u biáº¿t class.</p>
  </li>
  <li>
    <p>Náº¿u giáº£ sá»­ vá» tÃ­nh Ä‘á»™c láº­p Ä‘Æ°á»£c thoáº£ mÃ£n (dá»±a vÃ o báº£n cháº¥t cá»§a dá»¯ liá»‡u), NBC Ä‘Æ°á»£c cho lÃ  cho káº¿t quáº£ tá»‘t hÆ¡n so vá»›i SVM vÃ  logistic regression khi cÃ³ Ã­t dá»¯ liá»‡u training.</p>
  </li>
  <li>
    <p>NBC cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng vá»›i cÃ¡c feature vector mÃ  má»™t pháº§n lÃ  liÃªn tá»¥c (sá»­ dá»¥ng Gaussian Naive Bayes), pháº§n cÃ²n láº¡i á»Ÿ dáº¡ng rá»i ráº¡c (sá»­ dá»¥ng Multinomial hoáº·c Bernoulli).</p>
  </li>
  <li>
    <p>Khi sá»­ dá»¥ng Multinomial Naive Bayes, Laplace smoothing thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ trÃ¡nh trÆ°á»ng há»£p 1 thÃ nh pháº§n trong test data chÆ°a xuáº¥t hiá»‡n á»Ÿ training data.</p>
  </li>
  <li>
    <p><a href="https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/32_nbc/python/Spam%20filtering.ipynb">Source code</a>.</p>
  </li>
</ul>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-tÃ i-liá»‡u-tham-kháº£o">5. TÃ i liá»‡u tham kháº£o</h2>

<p>[1] <a href="https://web.stanford.edu/class/cs124/lec/naivebayes.pdf">Text Classification and Naive Bayes - Stanford</a></p>

<p>[2] <a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex6/ex6.html">Exercise 6: Naive Bayes - Machine Learning - Andrew Ng</a></p>

<p>[3] <a href="http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes"><code class="language-plaintext highlighter-rouge">sklearn.naive_bayes</code></a></p>

<p>[4] <a href="https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/">6 Easy Steps to Learn Naive Bayes Algorithm (with code in Python)</a></p>
:ET