I"ª<!-- <div class="imgcap">
<div >
<a href = "/2017/01/08/knn/">
    <img src ="https://upload.wikimedia.org/wikipedia/commons/5/52/Map1NN.png" align = "center" width="800"></a>
</div>
<div class="thecap"> Báº£n Ä‘á»“ cá»§a 1NN (Nguá»“n: <a href = "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">Wikipedia</a>) <br></div>
</div> -->

<p>Náº¿u nhÆ° con ngÆ°á»i cÃ³ kiá»ƒu há»c â€œnÆ°á»›c Ä‘áº¿n chÃ¢n má»›i nháº£yâ€, thÃ¬ trong Machine Learning cÅ©ng cÃ³ má»™t thuáº­t toÃ¡n nhÆ° váº­y.</p>

<p><strong>Trong trang nÃ y:</strong>
<!-- MarkdownTOC --></p>

<ul>
  <li><a href="#-gioi-thieu">1. Giá»›i thiá»‡u</a>
    <ul>
      <li><a href="#mot-cau-chuyen-vui">Má»™t cÃ¢u chuyá»‡n vui</a></li>
      <li><a href="#k-nearest-neighbor">K-nearest neighbor</a></li>
      <li><a href="#khoang-cach-trong-khong-gian-vector">Khoáº£ng cÃ¡ch trong khÃ´ng gian vector</a></li>
    </ul>
  </li>
  <li><a href="#-phan-tich-toan-hoc">2. PhÃ¢n tÃ­ch toÃ¡n há»c</a></li>
  <li><a href="#-vi-du-tren-python">3. VÃ­ dá»¥ trÃªn Python</a>
    <ul>
      <li><a href="#bo-co-so-du-lieu-iris-iris-flower-dataset">Bá»™ cÆ¡ sá»Ÿ dá»¯ liá»‡u Iris (Iris flower dataset).</a></li>
      <li><a href="#thi-nghiem">ThÃ­ nghiá»‡m</a>
        <ul>
          <li><a href="#tach-training-va-test-sets">TÃ¡ch training vÃ  test sets</a></li>
          <li><a href="#phuong-phap-danh-gia-evaluation-method">PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ (evaluation method)</a></li>
          <li><a href="#danh-trong-so-cho-cac-diem-lan-can">ÄÃ¡nh trá»ng sá»‘ cho cÃ¡c Ä‘iá»ƒm lÃ¢n cáº­n</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#-thao-luan">4. Tháº£o luáº­n</a>
    <ul>
      <li><a href="#knn-cho-regression">KNN cho Regression</a></li>
      <li><a href="#chuan-hoa-du-lieu">Chuáº©n hÃ³a dá»¯ liá»‡u</a></li>
      <li><a href="#su-dung-cac-phep-do-khoang-cach-khac-nhau">Sá»­ dá»¥ng cÃ¡c phÃ©p Ä‘o khoáº£ng cÃ¡ch khÃ¡c nhau</a></li>
      <li><a href="#uu-diem-cua-knn">Æ¯u Ä‘iá»ƒm cá»§a KNN</a></li>
      <li><a href="#nhuoc-diem-cua-knn">NhÆ°á»£c Ä‘iá»ƒm cá»§a KNN</a></li>
      <li><a href="#tang-toc-cho-knn">TÄƒng tá»‘c cho KNN</a></li>
      <li><a href="#try-this-yourself">Try this yourself</a></li>
      <li><a href="#source-code">Source code</a></li>
    </ul>
  </li>
  <li><a href="#-tai-lieu-tham-khao">5. TÃ i liá»‡u tham kháº£o</a></li>
</ul>

<!-- /MarkdownTOC -->

<p><a name="-gioi-thieu"></a></p>

<h2 id="1-giá»›i-thiá»‡u">1. Giá»›i thiá»‡u</h2>

<p><a name="mot-cau-chuyen-vui"></a></p>

<h3 id="má»™t-cÃ¢u-chuyá»‡n-vui">Má»™t cÃ¢u chuyá»‡n vui</h3>

<p>CÃ³ má»™t anh báº¡n chuáº©n bá»‹ Ä‘áº¿n ngÃ y thi cuá»‘i ká»³. VÃ¬ mÃ´n nÃ y Ä‘Æ°á»£c má»Ÿ tÃ i liá»‡u khi thi nÃªn anh ta khÃ´ng chá»‹u Ã´n táº­p Ä‘á»ƒ hiá»ƒu Ã½ nghÄ©a cá»§a tá»«ng bÃ i há»c vÃ  má»‘i liÃªn há»‡ giá»¯a cÃ¡c bÃ i. Thay vÃ o Ä‘Ã³, anh thu tháº­p táº¥t cáº£ cÃ¡c tÃ i liá»‡u trÃªn lá»›p, bao gá»“m ghi chÃ©p bÃ i giáº£ng (lecture notes), cÃ¡c slides vÃ  bÃ i táº­p vá» nhÃ  + lá»i giáº£i. Äá»ƒ cho cháº¯c, anh ta ra thÆ° viá»‡n vÃ  cÃ¡c quÃ¡n Photocopy quanh trÆ°á»ng mua háº¿t táº¥t cáº£ cÃ¡c loáº¡i tÃ i liá»‡u liÃªn quan (<em>khÃ¡ khen cho cáº­u nÃ y chá»‹u khÃ³ tÃ¬m kiáº¿m tÃ i liá»‡u</em>). Cuá»‘i cÃ¹ng, anh báº¡n cá»§a chÃºng ta thu tháº­p Ä‘Æ°á»£c má»™t chá»“ng cao tÃ i liá»‡u Ä‘á»ƒ mang vÃ o phÃ²ng thi. 
<!-- Tháº­t khÃ´ng may, cáº­u áº¥y khÃ´ng biáº¿t ráº±ng trong Ä‘á»‘ng tÃ i liá»‡u mua tá»« quÃ¡n Photocopy Ä‘Ã³ cÃ³ nhiá»u bÃ i cho Ä‘Ã¡p Ã¡n sai.  --></p>

<p>VÃ o ngÃ y thi, anh tá»± tin mang chá»“ng tÃ i liá»‡u vÃ o phÃ²ng thi. Aha, Ä‘á» nÃ y Ã­t nháº¥t mÃ¬nh pháº£i Ä‘Æ°á»£c 8 Ä‘iá»ƒm. CÃ¢u 1 giá»‘ng há»‡t bÃ i giáº£ng trÃªn lá»›p. CÃ¢u 2 giá»‘ng há»‡t Ä‘á» thi nÄƒm ngoÃ¡i mÃ  lá»i giáº£i cÃ³ trong táº­p tÃ i liá»‡u mua á»Ÿ quÃ¡n Photocopy. CÃ¢u 3 gáº§n giá»‘ng vá»›i bÃ i táº­p vá» nhÃ . CÃ¢u 4 tráº¯c nghiá»‡m tháº­m chÃ­ cáº­u nhá»› chÃ­nh xÃ¡c ba tÃ i liá»‡u cÃ³ ghi Ä‘Ã¡p Ã¡n. CÃ¢u cuá»‘i cÃ¹ng, 1 cÃ¢u khÃ³ nhÆ°ng anh Ä‘Ã£ tá»«ng nhÃ¬n tháº¥y, chá»‰ lÃ  khÃ´ng nhá»› á»Ÿ Ä‘Ã¢u thÃ´i.</p>

<p>Káº¿t quáº£ cuá»‘i cÃ¹ng, cáº­u ta Ä‘Æ°á»£c 4 Ä‘iá»ƒm, vá»«a Ä‘á»§ Ä‘iá»ƒm qua mÃ´n. Cáº­u lÃ m chÃ­nh xÃ¡c cÃ¢u 1 vÃ¬ tÃ¬m Ä‘Æ°á»£c ngay trong táº­p ghi chÃº bÃ i giáº£ng. CÃ¢u 2 cÅ©ng tÃ¬m Ä‘Æ°á»£c Ä‘Ã¡p Ã¡n nhÆ°ng lá»i giáº£i cá»§a quÃ¡n Photocopy sai! CÃ¢u ba tháº¥y gáº§n giá»‘ng bÃ i vá» nhÃ , chá»‰ khÃ¡c má»—i má»™t sá»‘ thÃ´i, cáº­u cho káº¿t quáº£ giá»‘ng nhÆ° tháº¿ luÃ´n, váº­y mÃ  khÃ´ng Ä‘Æ°á»£c Ä‘iá»ƒm nÃ o. CÃ¢u 4 thÃ¬ tÃ¬m Ä‘Æ°á»£c cáº£ 3 tÃ i liá»‡u nhÆ°ng cÃ³ hai trong Ä‘Ã³ cho Ä‘Ã¡p Ã¡n A, cÃ¡i cÃ²n láº¡i cho B. Cáº­u chá»n A vÃ  Ä‘Æ°á»£c Ä‘iá»ƒm. CÃ¢u 5 thÃ¬ khÃ´ng lÃ m Ä‘Æ°á»£c dÃ¹ cÃ²n tá»›i 20 phÃºt, vÃ¬ tÃ¬m mÃ£i cháº³ng tháº¥y Ä‘Ã¡p Ã¡n Ä‘Ã¢u - nhiá»u tÃ i liá»‡u quÃ¡ cÅ©ng má»‡t!!</p>

<p>KhÃ´ng pháº£i ngáº«u nhiÃªn mÃ  tÃ´i dÃ nh ra ba Ä‘oáº¡n vÄƒn Ä‘á»ƒ ká»ƒ vá» chuyá»‡n há»c hÃ nh cá»§a anh chÃ ng kia. HÃ´m nay tÃ´i xin trÃ¬nh bÃ y vá» má»™t phÆ°Æ¡ng phÃ¡p trong Machine Learning, Ä‘Æ°á»£c gá»i lÃ  K-nearest neighbor (hay KNN), má»™t thuáº­t toÃ¡n Ä‘Æ°á»£c xáº¿p vÃ o loáº¡i lazy (machine) learning (mÃ¡y lÆ°á»i há»c). Thuáº­t toÃ¡n nÃ y khÃ¡ giá»‘ng vá»›i cÃ¡ch há»c/thi cá»§a anh báº¡n kÃ©m may máº¯n kia.</p>

<p><a name="k-nearest-neighbor"></a></p>

<h3 id="k-nearest-neighbor">K-nearest neighbor</h3>

<p>K-nearest neighbor lÃ  má»™t trong nhá»¯ng thuáº­t toÃ¡n supervised-learning Ä‘Æ¡n giáº£n nháº¥t (mÃ  hiá»‡u quáº£ trong má»™t vÃ i trÆ°á»ng há»£p) trong Machine Learning. Khi training, thuáº­t toÃ¡n nÃ y <em>khÃ´ng há»c</em> má»™t Ä‘iá»u gÃ¬ tá»« dá»¯ liá»‡u training (Ä‘Ã¢y cÅ©ng lÃ  lÃ½ do thuáº­t toÃ¡n nÃ y Ä‘Æ°á»£c xáº¿p vÃ o loáº¡i <a href="https://en.wikipedia.org/wiki/Lazy_learning">lazy learning</a>), má»i tÃ­nh toÃ¡n Ä‘Æ°á»£c thá»±c hiá»‡n khi nÃ³ cáº§n dá»± Ä‘oÃ¡n káº¿t quáº£ cá»§a dá»¯ liá»‡u má»›i. K-nearest neighbor cÃ³ thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c vÃ o cáº£ hai loáº¡i cá»§a bÃ i toÃ¡n Supervised learning lÃ  <a href="/2016/12/27/categories/#classification-phan-loai">Classification</a> vÃ  <a href="/2016/12/27/categories/#regression-hoi-quy">Regression</a>. KNN cÃ²n Ä‘Æ°á»£c gá»i lÃ  má»™t thuáº­t toÃ¡n <a href="https://en.wikipedia.org/wiki/Instance-based_learning">Instance-based hay Memory-based learning</a>.</p>

<p>CÃ³ má»™t vÃ i khÃ¡i niá»‡m tÆ°Æ¡ng á»©ng ngÆ°á»i-mÃ¡y nhÆ° sau:</p>

<table>
  <thead>
    <tr>
      <th>NgÃ´n ngá»¯ ngÆ°á»i</th>
      <th>NgÃ´n ngá»¯ MÃ¡y Há»c</th>
      <th>in Machine Learning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CÃ¢u há»i</td>
      <td>Äiá»ƒm dá»¯ liá»‡u</td>
      <td>Data point</td>
    </tr>
    <tr>
      <td>ÄÃ¡p Ã¡n</td>
      <td>Äáº§u ra, nhÃ£n</td>
      <td>Output, Label</td>
    </tr>
    <tr>
      <td>Ã”n thi</td>
      <td>Huáº¥n luyá»‡n</td>
      <td>Training</td>
    </tr>
    <tr>
      <td>Táº­p tÃ i liá»‡u mang vÃ o phÃ²ng thi</td>
      <td>Táº­p dá»¯ liá»‡u táº­p huáº¥n</td>
      <td>Training set</td>
    </tr>
    <tr>
      <td>Äá» thi</td>
      <td>Táº­p dá»¯ liá»ƒu kiá»ƒm thá»­</td>
      <td>Test set</td>
    </tr>
    <tr>
      <td>CÃ¢u há»i trong dá» thi</td>
      <td>Dá»¯ liá»‡u kiá»ƒm thá»­</td>
      <td>Test data point</td>
    </tr>
    <tr>
      <td>CÃ¢u há»i cÃ³ Ä‘Ã¡p Ã¡n sai</td>
      <td>Nhiá»…u</td>
      <td>Noise, Outlier</td>
    </tr>
    <tr>
      <td>CÃ¢u há»i gáº§n giá»‘ng</td>
      <td>Äiá»ƒm dá»¯ liá»‡u gáº§n nháº¥t</td>
      <td>Nearest Neighbor</td>
    </tr>
  </tbody>
</table>

<p><br />
Vá»›i KNN, trong bÃ i toÃ¡n Classification, label cá»§a má»™t Ä‘iá»ƒm dá»¯ liá»‡u má»›i (hay káº¿t quáº£ cá»§a cÃ¢u há»i trong bÃ i thi) Ä‘Æ°á»£c suy ra trá»±c tiáº¿p tá»« K Ä‘iá»ƒm dá»¯ liá»‡u gáº§n nháº¥t trong training set. Label cá»§a má»™t test data cÃ³ thá»ƒ Ä‘Æ°á»£c quyáº¿t Ä‘á»‹nh báº±ng major voting (báº§u chá»n theo sá»‘ phiáº¿u) giá»¯a cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t, hoáº·c nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c suy ra báº±ng cÃ¡ch Ä‘Ã¡nh trá»ng sá»‘ khÃ¡c nhau cho má»—i trong cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t Ä‘Ã³ rá»“i suy ra label. Chi tiáº¿t sáº½ Ä‘Æ°á»£c nÃªu trong pháº§n tiáº¿p theo.</p>

<p>Trong bÃ i toÃ¡n Regresssion, Ä‘áº§u ra cá»§a má»™t Ä‘iá»ƒm dá»¯ liá»‡u sáº½ báº±ng chÃ­nh Ä‘áº§u ra cá»§a Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã£ biáº¿t gáº§n nháº¥t (trong trÆ°á»ng há»£p K=1), hoáº·c lÃ  trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a Ä‘áº§u ra cá»§a nhá»¯ng Ä‘iá»ƒm gáº§n nháº¥t, hoáº·c báº±ng má»™t má»‘i quan há»‡ dá»±a trÃªn khoáº£ng cÃ¡ch tá»›i cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t Ä‘Ã³.</p>

<p>Má»™t cÃ¡ch ngáº¯n gá»n, KNN lÃ  thuáº­t toÃ¡n Ä‘i tÃ¬m Ä‘áº§u ra cá»§a má»™t Ä‘iá»ƒm dá»¯ liá»‡u má»›i báº±ng cÃ¡ch <em>chá»‰</em> dá»±a trÃªn thÃ´ng tin cá»§a K Ä‘iá»ƒm dá»¯ liá»‡u trong training set gáº§n nÃ³ nháº¥t (K-lÃ¢n cáº­n), <em>khÃ´ng quan tÃ¢m Ä‘áº¿n viá»‡c cÃ³ má»™t vÃ i Ä‘iá»ƒm dá»¯ liá»‡u trong nhá»¯ng Ä‘iá»ƒm gáº§n nháº¥t nÃ y lÃ  nhiá»…u</em>. HÃ¬nh dÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ­ dá»¥ vá» KNN trong classification vá»›i K = 1.</p>

<div class="imgcap">
<img src="https://upload.wikimedia.org/wikipedia/commons/5/52/Map1NN.png" align="center" />
<div class="thecap"> Báº£n Ä‘á»“ cá»§a 1NN (Nguá»“n: <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">Wikipedia</a>) <br /></div>
</div>

<p>VÃ­ dá»¥ trÃªn Ä‘Ã¢y lÃ  bÃ i toÃ¡n Classification vá»›i 3 classes: Äá», Lam, Lá»¥c. Má»—i Ä‘iá»ƒm dá»¯ liá»‡u má»›i (test data point) sáº½ Ä‘Æ°á»£c gÃ¡n label theo mÃ u cá»§a Ä‘iá»ƒm mÃ  nÃ³ thuá»™c vá». Trong hÃ¬nh nÃ y, cÃ³ má»™t vÃ i vÃ¹ng nhá» xem láº«n vÃ o cÃ¡c vÃ¹ng lá»›n hÆ¡n khÃ¡c mÃ u. VÃ­ dá»¥ cÃ³ má»™t Ä‘iá»ƒm mÃ u Lá»¥c á»Ÿ gáº§n gÃ³c 11 giá» náº±m giá»¯a hai vÃ¹ng lá»›n vá»›i nhiá»u dá»¯ liá»‡u mÃ u Äá» vÃ  Lam. Äiá»ƒm nÃ y ráº¥t cÃ³ thá»ƒ lÃ  nhiá»…u. Dáº«n Ä‘áº¿n náº¿u dá»¯ liá»‡u test rÆ¡i vÃ o vÃ¹ng nÃ y sáº½ cÃ³ nhiá»u kháº£ nÄƒng cho káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c.</p>

<p><a name="khoang-cach-trong-khong-gian-vector"></a></p>

<h3 id="khoáº£ng-cÃ¡ch-trong-khÃ´ng-gian-vector">Khoáº£ng cÃ¡ch trong khÃ´ng gian vector</h3>

<p>Trong khÃ´ng gian má»™t chiá»u, khoáº£ng cÃ¡ch giá»¯a hai Ä‘iá»ƒm lÃ  trá»‹ tuyá»‡t Ä‘á»‘i giá»¯a hiá»‡u giÃ¡ trá»‹ cá»§a hai Ä‘iá»ƒm Ä‘Ã³. Trong khÃ´ng gian nhiá»u chiá»u, khoáº£ng cÃ¡ch giá»¯a hai Ä‘iá»ƒm cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a báº±ng nhiá»u hÃ m sá»‘ khÃ¡c nhau, trong Ä‘Ã³ Ä‘á»™ dÃ i Ä‘Æ°á»ng tháº±ng ná»•i hai Ä‘iá»ƒm chá»‰ lÃ  má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t trong Ä‘Ã³. Nhiá»u thÃ´ng tin bá»• Ã­ch (cho Machine Learning) cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y táº¡i <a href="/math/#-norms-chuan">Norms (chuáº©n) cá»§a vector</a> trong tab <a href="/math/">Math</a>.</p>

<p><a name="-phan-tich-toan-hoc"></a></p>

<h2 id="2-phÃ¢n-tÃ­ch-toÃ¡n-há»c">2. PhÃ¢n tÃ­ch toÃ¡n há»c</h2>
<p>Thuáº­t toÃ¡n KNN ráº¥t dá»… hiá»ƒu nÃªn sáº½ pháº§n â€œPhÃ¢n tÃ­ch toÃ¡n há»câ€ nÃ y sáº½ chá»‰ cÃ³ 3 cÃ¢u. TÃ´i trá»±c tiáº¿p Ä‘i vÃ o cÃ¡c vÃ­ dá»¥. CÃ³ má»™t Ä‘iá»u Ä‘Ã¡ng lÆ°u Ã½ lÃ  KNN pháº£i <em>nhá»›</em> táº¥t cáº£ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u training, viá»‡c nÃ y khÃ´ng Ä‘Æ°á»£c lá»£i vá» cáº£ bá»™ nhá»› vÃ  thá»i gian tÃ­nh toÃ¡n - giá»‘ng nhÆ° khi cáº­u báº¡n cá»§a chÃºng ta khÃ´ng tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i cho cÃ¢u há»i cuá»‘i cÃ¹ng.</p>

<p><a name="-vi-du-tren-python"></a></p>

<h2 id="3-vÃ­-dá»¥-trÃªn-python">3. VÃ­ dá»¥ trÃªn Python</h2>

<p><a name="bo-co-so-du-lieu-iris-iris-flower-dataset"></a></p>

<h3 id="bá»™-cÆ¡-sá»Ÿ-dá»¯-liá»‡u-iris-iris-flower-dataset">Bá»™ cÆ¡ sá»Ÿ dá»¯ liá»‡u Iris (Iris flower dataset).</h3>

<p><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris flower dataset</a> lÃ  má»™t bá»™ dá»¯ liá»‡u nhá» (nhá» hÆ¡n ráº¥t nhiá»u so vá»›i <a href="/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist">MNIST</a>. Bá»™ dá»¯ liá»‡u nÃ y bao gá»“m thÃ´ng tin cá»§a ba loáº¡i hoa Iris (má»™t loÃ i hoa lan) khÃ¡c nhau: Iris setosa, Iris virginica vÃ  Iris versicolor. Má»—i loáº¡i cÃ³ 50 bÃ´ng hoa Ä‘Æ°á»£c Ä‘o vá»›i dá»¯ liá»‡u lÃ  4 thÃ´ng tin: chiá»u dÃ i, chiá»u rá»™ng Ä‘Ã i hoa (sepal), vÃ  chiá»u dÃ i, chiá»u rá»™ng cÃ¡nh hoa (petal). DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» hÃ¬nh áº£nh cá»§a ba loáº¡i hoa. (ChÃº Ã½, Ä‘Ã¢y khÃ´ng pháº£i lÃ  bá»™ cÆ¡ sá»Ÿ dá»¯ liá»‡u áº£nh nhÆ° MNIST, má»—i Ä‘iá»ƒm dá»¯ liá»‡u trong táº­p nÃ y chá»‰ lÃ  má»™t vector 4 chiá»u).</p>

<div class="imgcap">
<img src="/assets/knn/iris.png" align="center" width="800" />
<div class="thecap"> VÃ­ dá»¥ vá» Iris flower dataset (Nguá»“n: <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Wikipedia</a>) <br /></div>
</div>

<p>Bá»™ dá»¯ liá»‡u nhá» nÃ y thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u thuáº­t toÃ¡n Machine Learning trong cÃ¡c lá»›p há»c. TÃ´i sáº½ giáº£i thÃ­ch lÃ½ do khÃ´ng chá»n MNIST vÃ o pháº§n sau.</p>

<p><a name="thi-nghiem"></a></p>

<h3 id="thÃ­-nghiá»‡m">ThÃ­ nghiá»‡m</h3>

<p>Trong pháº§n nÃ y, chÃºng ta sáº½ tÃ¡ch 150 dá»¯ liá»‡u trong Iris flower dataset ra thÃ nh 2 pháº§n, gá»i lÃ  <em>training set</em> vÃ  <em>test set</em>. Thuáº­t toÃ¡n KNN sáº½ dá»±a vÃ o trÃ´ng tin á»Ÿ <em>training set</em> Ä‘á»ƒ dá»± Ä‘oÃ¡n xem má»—i dá»¯ liá»‡u trong <em>test set</em> tÆ°Æ¡ng á»©ng vá»›i loáº¡i hoa nÃ o. Dá»¯ liá»‡u Ä‘Æ°á»£c dá»± Ä‘oÃ¡n nÃ y sáº½ Ä‘Æ°á»£c Ä‘á»‘i chiáº¿u vá»›i loáº¡i hoa tháº­t cá»§a má»—i dá»¯ liá»‡u trong <em>test set</em> Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a KNN.</p>

<p><strong>TrÆ°á»›c tiÃªn, chÃºng ta cáº§n khai bÃ¡o vÃ i thÆ° viá»‡n</strong>.</p>

<p>Iris flower dataset cÃ³ sáºµn trong thÆ° viá»‡n <a href="http://scikit-learn.org/">scikit-learn</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">datasets</span>
</code></pre></div></div>

<p><strong>Tiáº¿p theo, chÃºng ta load dá»¯ liá»‡u vÃ  hiá»‡n thá»‹ vÃ i dá»¯ liá»‡u máº«u</strong>. CÃ¡c class Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  0, 1, vÃ  2.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">iris_X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>
<span class="n">iris_y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="k">print</span> <span class="s">'Number of classes: %d'</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">iris_y</span><span class="p">))</span>
<span class="k">print</span> <span class="s">'Number of data points: %d'</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">iris_y</span><span class="p">)</span>


<span class="n">X0</span> <span class="o">=</span> <span class="n">iris_X</span><span class="p">[</span><span class="n">iris_y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,:]</span>
<span class="k">print</span> <span class="s">'</span><span class="se">\n</span><span class="s">Samples from class 0:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">X0</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:]</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">iris_X</span><span class="p">[</span><span class="n">iris_y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,:]</span>
<span class="k">print</span> <span class="s">'</span><span class="se">\n</span><span class="s">Samples from class 1:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">X1</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:]</span>

<span class="n">X2</span> <span class="o">=</span> <span class="n">iris_X</span><span class="p">[</span><span class="n">iris_y</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,:]</span>
<span class="k">print</span> <span class="s">'</span><span class="se">\n</span><span class="s">Samples from class 2:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">X2</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:]</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of classes: 3
Number of data points: 150

Samples from class 0:
[[ 5.1  3.5  1.4  0.2]
 [ 4.9  3.   1.4  0.2]
 [ 4.7  3.2  1.3  0.2]
 [ 4.6  3.1  1.5  0.2]
 [ 5.   3.6  1.4  0.2]]

Samples from class 1:
[[ 7.   3.2  4.7  1.4]
 [ 6.4  3.2  4.5  1.5]
 [ 6.9  3.1  4.9  1.5]
 [ 5.5  2.3  4.   1.3]
 [ 6.5  2.8  4.6  1.5]]

Samples from class 2:
[[ 6.3  3.3  6.   2.5]
 [ 5.8  2.7  5.1  1.9]
 [ 7.1  3.   5.9  2.1]
 [ 6.3  2.9  5.6  1.8]
 [ 6.5  3.   5.8  2.2]]
</code></pre></div></div>

<p>Náº¿u nhÃ¬n vÃ o vÃ i dá»¯ liá»‡u máº«u, chÃºng ta tháº¥y ráº±ng hai cá»™t cuá»‘i mang khÃ¡ nhiá»u thÃ´ng tin giÃºp chÃºng ta cÃ³ thá»ƒ  phÃ¢n biá»‡t Ä‘Æ°á»£c chÃºng. ChÃºng ta dá»± Ä‘oÃ¡n ráº±ng káº¿t quáº£ classification cho cÆ¡ sá»Ÿ dá»¯ liá»‡u nÃ y sáº½ tÆ°Æ¡ng Ä‘á»‘i cao.</p>

<p><a name="tach-training-va-test-sets"></a></p>

<h4 id="tÃ¡ch-training-vÃ -test-sets">TÃ¡ch training vÃ  test sets</h4>
<p>Giáº£ sá»­ chÃºng ta muá»‘n dÃ¹ng 50 Ä‘iá»ƒm dá»¯ liá»‡u cho test set, 100 Ä‘iá»ƒm cÃ²n láº¡i cho training set. Scikit-learn cÃ³ má»™t hÃ m sá»‘ cho phÃ©p chÃºng ta ngáº«u nhiÃªn lá»±a chá»n cÃ¡c Ä‘iá»ƒm nÃ y, nhÆ° sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
     <span class="n">iris_X</span><span class="p">,</span> <span class="n">iris_y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="k">print</span> <span class="s">"Training size: %d"</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span> <span class="s">"Test size    : %d"</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training size: 100
Test size    : 50
</code></pre></div></div>

<p>Sau Ä‘Ã¢y, tÃ´i trÆ°á»›c háº¿t xÃ©t trÆ°á»ng há»£p Ä‘Æ¡n giáº£n K = 1, tá»©c lÃ  vá»›i má»—i Ä‘iá»ƒm test data, ta chá»‰ xÃ©t 1 Ä‘iá»ƒm training data gáº§n nháº¥t vÃ  láº¥y label cá»§a Ä‘iá»ƒm Ä‘Ã³ Ä‘á»ƒ dá»± Ä‘oÃ¡n cho Ä‘iá»ƒm test nÃ y.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span> <span class="s">"Print results for 20 test data points:"</span>
<span class="k">print</span> <span class="s">"Predicted labels: "</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">40</span><span class="p">]</span>
<span class="k">print</span> <span class="s">"Ground truth    : "</span><span class="p">,</span> <span class="n">y_test</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">40</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Print results for first 20 test data points:
Predicted labels:  [2 1 2 2 1 2 2 0 2 0 2 0 1 0 0 2 2 0 2 0]
Ground truth    :  [2 1 2 2 1 2 2 0 2 0 1 0 1 0 0 2 1 0 2 0]
</code></pre></div></div>

<p><a name="ground-truth"></a>
Káº¿t quáº£ cho tháº¥y label dá»± Ä‘oÃ¡n gáº§n giá»‘ng vá»›i label tháº­t cá»§a test data, chá»‰ cÃ³ 2 Ä‘iá»ƒm trong sá»‘ 20 Ä‘iá»ƒm Ä‘Æ°á»£c hiá»ƒn thá»‹ cÃ³ káº¿t quáº£ sai lá»‡ch. á» Ä‘Ã¢y chÃºng ta lÃ m quen vá»›i khÃ¡i niá»‡m má»›i: <em>ground truth</em>. Má»™t cÃ¡ch Ä‘Æ¡n giáº£n, <em>ground truth</em> chÃ­nh lÃ  nhÃ£n/label/Ä‘áº§u ra <em>thá»±c sá»±</em> cá»§a cÃ¡c Ä‘iá»ƒm trong test data. KhÃ¡i niá»‡m nÃ y Ä‘Æ°á»£c dÃ¹ng nhiá»u trong Machine Learning, hy vá»ng láº§n tá»›i cÃ¡c báº¡n gáº·p thÃ¬ sáº½ nhá»› ngay nÃ³ lÃ  gÃ¬.</p>

<p><a name="phuong-phap-danh-gia-evaluation-method"></a></p>

<h4 id="phÆ°Æ¡ng-phÃ¡p-Ä‘Ã¡nh-giÃ¡-evaluation-method">PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ (evaluation method)</h4>
<p>Äá»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n KNN classifier nÃ y, chÃºng ta xem xem cÃ³ bao nhiÃªu Ä‘iá»ƒm trong test data Ä‘Æ°á»£c dá»± Ä‘oÃ¡n Ä‘Ãºng. Láº¥y sá»‘ lÆ°á»£ng nÃ y chia cho tá»•ng sá»‘ lÆ°á»£ng trong táº­p test data sáº½ ra Ä‘á»™ chÃ­nh xÃ¡c. Scikit-learn cung cáº¥p hÃ m sá»‘ <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"><code class="language-plaintext highlighter-rouge">accuracy_score</code></a> Ä‘á»ƒ thá»±c hiá»‡n cÃ´ng viá»‡c nÃ y.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="k">print</span> <span class="s">"Accuracy of 1NN: %.2f %%"</span> <span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of 1NN: 94.00 %
</code></pre></div></div>

<p>1NN Ä‘Ã£ cho chÃºng ta káº¿t quáº£ lÃ  94%, khÃ´ng tá»‡! ChÃº Ã½ ráº±ng Ä‘Ã¢y lÃ  má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u dá»… vÃ¬ chá»‰ vá»›i dá»¯ liá»‡u á»Ÿ hai cá»™t cuá»‘i cÃ¹ng, chÃºng ta Ä‘Ã£ cÃ³ thá»ƒ suy ra quy luáº­t. Trong vÃ­ dá»¥ nÃ y, tÃ´i sá»­ dá»¥ng <code class="language-plaintext highlighter-rouge">p = 2</code> nghÄ©a lÃ  khoáº£ng cÃ¡ch á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c tÃ­nh lÃ  khoáº£ng cÃ¡ch theo <a href="/math/#norm2">norm 2</a>. CÃ¡c báº¡n cÅ©ng cÃ³ thá»ƒ thá»­ báº±ng cÃ¡ch thay <code class="language-plaintext highlighter-rouge">p = 1</code> cho <a href="/math/#norm0">norm 1</a>, hoáº·c cÃ¡c gÃ­a trá»‹ <code class="language-plaintext highlighter-rouge">p</code> khÃ¡c cho norm khÃ¡c. (Xem thÃªm <a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">sklearn.neighbors.KNeighborsClassifier</a>)</p>

<p>Nháº­n tháº¥y ráº±ng chá»‰ xÃ©t 1 Ä‘iá»ƒm gáº§n nháº¥t cÃ³ thá»ƒ dáº«n Ä‘áº¿n káº¿t quáº£ sai náº¿u Ä‘iá»ƒm Ä‘Ã³ lÃ  nhiá»…u. Má»™t cÃ¡ch cÃ³ thá»ƒ lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c lÃ  tÄƒng sá»‘ lÆ°á»£ng Ä‘iá»ƒm lÃ¢n cáº­n lÃªn, vÃ­ dá»¥ 10 Ä‘iá»ƒm, vÃ  xem xem trong 10 Ä‘iá»ƒm gáº§n nháº¥t, class nÃ o chiáº¿m Ä‘a sá»‘ thÃ¬ dá»± Ä‘oÃ¡n káº¿t quáº£ lÃ  class Ä‘Ã³. Ká»¹ thuáº­t dá»±a vÃ o Ä‘a sá»‘ nÃ y Ä‘Æ°á»£c gá»i lÃ  major voting.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span> <span class="s">"Accuracy of 10NN with major voting: %.2f %%"</span> <span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of 10NN with major voting: 98.00 %
</code></pre></div></div>

<p>Káº¿t quáº£ Ä‘Ã£ tÄƒng lÃªn 98%, ráº¥t tá»‘t!</p>

<p><a name="danh-trong-so-cho-cac-diem-lan-can"></a></p>

<h4 id="Ä‘Ã¡nh-trá»ng-sá»‘-cho-cÃ¡c-Ä‘iá»ƒm-lÃ¢n-cáº­n">ÄÃ¡nh trá»ng sá»‘ cho cÃ¡c Ä‘iá»ƒm lÃ¢n cáº­n</h4>

<p>LÃ  má»™t káº» tham lam, tÃ´i chÆ°a muá»‘n dá»«ng káº¿t quáº£ á»Ÿ Ä‘Ã¢y vÃ¬ tháº¥y ráº±ng mÃ¬nh váº«n cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘Æ°á»£c. Trong ká»¹ thuáº­t major voting bÃªn trÃªn, má»—i trong 10 Ä‘iá»ƒm gáº§n nháº¥t Ä‘Æ°á»£c coi lÃ  cÃ³ vai trÃ² nhÆ° nhau vÃ  giÃ¡ trá»‹ <em>lÃ¡ phiáº¿u</em> cá»§a má»—i Ä‘iá»ƒm nÃ y lÃ  nhÆ° nhau. TÃ´i cho ráº±ng nhÆ° tháº¿ lÃ  khÃ´ng cÃ´ng báº±ng, vÃ¬ rÃµ rÃ ng ráº±ng nhá»¯ng Ä‘iá»ƒm gáº§n hÆ¡n nÃªn cÃ³ trá»ng sá»‘ cao hÆ¡n (<em>cÃ ng thÃ¢n cáº­n thÃ¬ cÃ ng tin tÆ°á»Ÿng</em>). Váº­y nÃªn tÃ´i sáº½ Ä‘Ã¡nh trá»ng sá»‘ khÃ¡c nhau cho má»—i trong 10 Ä‘iá»ƒm gáº§n nháº¥t nÃ y. CÃ¡ch Ä‘Ã¡nh trá»ng sá»‘ pháº£i thoáº£i mÃ£n Ä‘iá»u kiá»‡n lÃ  má»™t Ä‘iá»ƒm cÃ ng gáº§n Ä‘iá»ƒm test data thÃ¬ pháº£i Ä‘Æ°á»£c Ä‘Ã¡nh trá»ng sá»‘ cÃ ng cao (tin tÆ°á»Ÿng hÆ¡n). CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  láº¥y nghá»‹ch Ä‘áº£o cá»§a khoáº£ng cÃ¡ch nÃ y. (Trong trÆ°á»ng há»£p test data trÃ¹ng vá»›i 1 Ä‘iá»ƒm dá»¯ liá»‡u trong training data, tá»©c khoáº£ng cÃ¡ch báº±ng 0, ta láº¥y luÃ´n label cá»§a Ä‘iá»ƒm training data).</p>

<p>Scikit-learn giÃºp chÃºng ta Ä‘Æ¡n giáº£n hÃ³a viá»‡c nÃ y báº±ng cÃ¡ch gÃ¡n gÃ­a trá»‹ <code class="language-plaintext highlighter-rouge">weights = 'distance'</code>. (GiÃ¡ trá»‹ máº·c Ä‘á»‹nh cá»§a <code class="language-plaintext highlighter-rouge">weights</code> lÃ  <code class="language-plaintext highlighter-rouge">'uniform'</code>, tÆ°Æ¡ng á»©ng vá»›i viá»‡c coi táº¥t cáº£ cÃ¡c Ä‘iá»ƒm lÃ¢n cáº­n cÃ³ giÃ¡ trá»‹ nhÆ° nhau nhÆ° á»Ÿ trÃªn).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s">'distance'</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span> <span class="s">"Accuracy of 10NN (1/distance weights): %.2f %%"</span> <span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of 10NN (1/distance weights): 100.00 %
</code></pre></div></div>

<p>Aha, 100%.</p>

<p><strong>ChÃº Ã½:</strong> NgoÃ i 2 phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh trá»ng sá»‘ <code class="language-plaintext highlighter-rouge">weights = 'uniform'</code> vÃ  <code class="language-plaintext highlighter-rouge">weights = 'distance'</code> á»Ÿ trÃªn, scikit-learn cÃ²n cung cáº¥p cho chÃºng ta má»™t cÃ¡ch Ä‘á»ƒ Ä‘Ã¡nh trá»ng sá»‘ má»™t cÃ¡ch tÃ¹y chá»n. VÃ­ dá»¥, má»™t cÃ¡ch Ä‘Ã¡nh trá»ng sá»‘ phá»• biáº¿n khÃ¡c trong Machine Learning lÃ :</p>

<p>\[
w_i = \exp \left( \frac{-||\mathbf{x} - \mathbf{x}_i||_2^2}{\sigma^2} \right)
\]
<!-- \\[
w_i = \exp{- \|\|\mathbf{x} - \mathbf{x}_i\|\|_2^2}{\sigma^2}}
\\] --></p>

<p>trong Ä‘Ã³ \(\mathbf{x}\) lÃ  test data, \(\mathbf{x}_i\) lÃ  má»™t Ä‘iá»ƒm trong K-lÃ¢n cáº­n cá»§a \(\mathbf{x}\), \(w_i\) lÃ  trá»ng sá»‘ cá»§a Ä‘iá»ƒm Ä‘Ã³ (á»©ng vá»›i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘ang xÃ©t \(\mathbf{x}\)), \(\sigma\) lÃ  má»™t sá»‘ dÆ°Æ¡ng. Nháº­n tháº¥y ráº±ng hÃ m sá»‘ nÃ y cÅ©ng thá»a mÃ£n Ä‘iá»u kiá»‡n: Ä‘iá»ƒm cÃ ng gáº§n \(\mathbf{x}\) thÃ¬ trá»ng sá»‘ cÃ ng cao (cao nháº¥t báº±ng 1). Vá»›i hÃ m sá»‘ nÃ y, chÃºng ta cÃ³ thá»ƒ láº­p trÃ¬nh nhÆ° sau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">myweight</span><span class="p">(</span><span class="n">distances</span><span class="p">):</span>
    <span class="n">sigma2</span> <span class="o">=</span> <span class="p">.</span><span class="mi">5</span> <span class="c1"># we can change this number
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">distances</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">sigma2</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">myweight</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span> <span class="s">"Accuracy of 10NN (customized weights): %.2f %%"</span> <span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of 10NN (customized weights): 98.00 %
</code></pre></div></div>

<p>Trong trÆ°á»ng há»£p nÃ y, káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i ká»¹ thuáº­t major voting. Äá»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hÆ¡n káº¿t quáº£ cá»§a KNN vá»›i K khÃ¡c nhau, cÃ¡ch Ä‘á»‹nh nghÄ©a khoáº£ng cÃ¡ch khÃ¡c nhau vÃ  cÃ¡ch Ä‘Ã¡nh trá»ng sá»‘ khÃ¡c nhau, chÃºng ta cáº§n thá»±c hiá»‡n quÃ¡ trÃ¬nh trÃªn vá»›i nhiá»u cÃ¡ch chia dá»¯ liá»‡u <em>training</em> vÃ  <em>test</em> khÃ¡c nhau rá»“i láº¥y káº¿t quáº£ trung bÃ¬nh, vÃ¬ ráº¥t cÃ³ thá»ƒ dá»¯ liá»‡u phÃ¢n chia trong 1 trÆ°á»ng há»£p cá»¥ thá»ƒ lÃ  ráº¥t tá»‘t hoáº·c ráº¥t xáº¥u (bias). ÄÃ¢y cÅ©ng lÃ  cÃ¡ch thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng khi Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a má»™t thuáº­t toÃ¡n cá»¥ thá»ƒ nÃ o Ä‘Ã³.</p>

<p><a name="-thao-luan"></a></p>

<h2 id="4-tháº£o-luáº­n">4. Tháº£o luáº­n</h2>

<p><a name="knn-cho-regression"></a></p>

<h3 id="knn-cho-regression">KNN cho Regression</h3>
<p>Vá»›i bÃ i toÃ¡n Regression, chÃºng ta cÅ©ng hoÃ n toÃ n cÃ³ thá»ƒ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»±: Æ°á»›c lÆ°á»£ng Ä‘áº§u ra dá»±a trÃªn Ä‘áº§u ra vÃ  khoáº£ng cÃ¡ch cá»§a cÃ¡c Ä‘iá»ƒm trong K-lÃ¢n cáº­n. Viá»‡c Æ°á»›c lÆ°á»£ng nhÆ° tháº¿ nÃ o cÃ¡c báº¡n cÃ³ thá»ƒ tá»± Ä‘á»‹nh nghÄ©a tÃ¹y vÃ o tá»«ng bÃ i toÃ¡n.</p>

<div class="imgcap">
<!-- <img src ="/assets/knn/knnR.png" align = "center"> -->
<img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_regression_001.png" align="center" />
<div class="thecap"> KNN cho bÃ i toÃ¡n Regression  (Nguá»“n: <a href="http://scikit-learn.org/stable/auto_examples/neighbors/plot_regression.html#sphx-glr-auto-examples-neighbors-plot-regression-py">Nearest Neighbors regression</a>) <br /></div>
</div>

<p><a name="chuan-hoa-du-lieu"></a></p>

<h3 id="chuáº©n-hÃ³a-dá»¯-liá»‡u">Chuáº©n hÃ³a dá»¯ liá»‡u</h3>
<p>Khi cÃ³ má»™t thuá»™c tÃ­nh trong dá»¯ liá»‡u (hay pháº§n tá»­ trong vector) lá»›n hÆ¡n cÃ¡c thuá»™c tÃ­nh khÃ¡c ráº¥t nhiá»u (vÃ­ dá»¥ thay vÃ¬ Ä‘o báº±ng cm thÃ¬ má»™t káº¿t quáº£ láº¡i tÃ­nh báº±ng mm), khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm sáº½ phá»¥ thuá»™c vÃ o thuá»™c tÃ­nh nÃ y ráº¥t nhiá»u. Äá»ƒ cÃ³ Ä‘Æ°á»£c káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n, má»™t ká»¹ thuáº­t thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng lÃ  <em>Data Normalization</em> (chuáº©n hÃ³a dá»¯ liá»‡u) Ä‘á»ƒ Ä‘Æ°a cÃ¡c thuá»™c tÃ­nh cÃ³ Ä‘Æ¡n vá»‹ Ä‘o khÃ¡c nhau vá» cÃ¹ng má»™t khoáº£ng giÃ¡ trá»‹, thÆ°á»ng lÃ  tá»« 0 Ä‘áº¿n 1, trÆ°á»›c khi thá»±c hiá»‡n KNN. CÃ³ nhiá»u ká»¹ thuáº­t chuáº©n hÃ³a khÃ¡c nhau, cÃ¡c báº¡n sáº½ Ä‘Æ°á»£c tháº¥y khi tiáº¿p tá»¥c theo dÃµi Blog nÃ y. CÃ¡c ká»¹ thuáº­t chuáº©n hÃ³a Ä‘Æ°á»£c Ã¡p dá»¥ng vá»›i khÃ´ng chá»‰ KNN mÃ  cÃ²n vá»›i háº§u háº¿t cÃ¡c thuáº­t toÃ¡n khÃ¡c.</p>

<p><a name="su-dung-cac-phep-do-khoang-cach-khac-nhau"></a></p>

<h3 id="sá»­-dá»¥ng-cÃ¡c-phÃ©p-Ä‘o-khoáº£ng-cÃ¡ch-khÃ¡c-nhau">Sá»­ dá»¥ng cÃ¡c phÃ©p Ä‘o khoáº£ng cÃ¡ch khÃ¡c nhau</h3>
<p>NgoÃ i norm 1 vÃ  norm 2 tÃ´i giá»›i thiá»‡u trong bÃ i nÃ y, cÃ²n ráº¥t nhiá»u cÃ¡c khoáº£ng cÃ¡ch khÃ¡c nhau cÃ³ thá»ƒ Ä‘Æ°á»£c dÃ¹ng. Má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n lÃ  Ä‘áº¿m sá»‘ lÆ°á»£ng thuá»™c tÃ­nh khÃ¡c nhau giá»¯a hai Ä‘iá»ƒm dá»¯ liá»‡u. Sá»‘ nÃ y cÃ ng nhá» thÃ¬ hai Ä‘iá»ƒm cÃ ng gáº§n nhau. ÄÃ¢y chÃ­nh lÃ  <a href="/math/#norm0">giáº£ chuáº©n 0</a> mÃ  tÃ´i Ä‘Ã£ giá»›i thiá»‡u trong Tab <a href="/math/">Math</a>.</p>

<p><a name="uu-diem-cua-knn"></a></p>

<h3 id="Æ°u-Ä‘iá»ƒm-cá»§a-knn">Æ¯u Ä‘iá»ƒm cá»§a KNN</h3>

<ol>
  <li>Äá»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a quÃ¡ trÃ¬nh training lÃ  báº±ng 0.</li>
  <li>Viá»‡c dá»± Ä‘oÃ¡n káº¿t quáº£ cá»§a dá»¯ liá»‡u má»›i ráº¥t Ä‘Æ¡n giáº£n.</li>
  <li>KhÃ´ng cáº§n giáº£ sá»­ gÃ¬ vá» phÃ¢n phá»‘i cá»§a cÃ¡c class.</li>
</ol>

<p><a name="nhuoc-diem-cua-knn"></a></p>

<h3 id="nhÆ°á»£c-Ä‘iá»ƒm-cá»§a-knn">NhÆ°á»£c Ä‘iá»ƒm cá»§a KNN</h3>

<ol>
  <li>KNN ráº¥t nháº¡y cáº£m vá»›i nhiá»…u khi K nhá».</li>
  <li>NhÆ° Ä‘Ã£ nÃ³i, KNN lÃ  má»™t thuáº­t toÃ¡n mÃ  má»i tÃ­nh toÃ¡n Ä‘á»u náº±m á»Ÿ khÃ¢u test. Trong Ä‘Ã³ viá»‡c tÃ­nh khoáº£ng cÃ¡ch tá»›i <em>tá»«ng</em> Ä‘iá»ƒm dá»¯ liá»‡u trong training set sáº½ tá»‘n ráº¥t nhiá»u thá»i gian, Ä‘áº·c biá»‡t lÃ  vá»›i cÃ¡c cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ³ sá»‘ chiá»u lá»›n vÃ  cÃ³ nhiá»u Ä‘iá»ƒm dá»¯ liá»‡u. Vá»›i K cÃ ng lá»›n thÃ¬ Ä‘á»™ phá»©c táº¡p cÅ©ng sáº½ tÄƒng lÃªn. NgoÃ i ra, viá»‡c lÆ°u toÃ n bá»™ dá»¯ liá»‡u trong bá»™ nhá»› cÅ©ng áº£nh hÆ°á»Ÿng tá»›i hiá»‡u nÄƒng cá»§a KNN.</li>
</ol>

<p><a name="tang-toc-cho-knn"></a></p>

<h3 id="tÄƒng-tá»‘c-cho-knn">TÄƒng tá»‘c cho KNN</h3>
<p>NgoÃ i viá»‡c tÃ­nh toÃ¡n khoáº£ng cÃ¡ch tá»« má»™t Ä‘iá»ƒm test data Ä‘áº¿n táº¥t cáº£ cÃ¡c Ä‘iá»ƒm trong traing set (Brute Force), cÃ³ má»™t sá»‘ thuáº­t toÃ¡n khÃ¡c giÃºp tÄƒng tá»‘c viá»‡c tÃ¬m kiáº¿m nÃ y. Báº¡n Ä‘á»c cÃ³ tháº» tÃ¬m kiáº¿m thÃªm vá»›i hai tá»« khÃ³a: <a href="http://pointclouds.org/documentation/tutorials/kdtree_search.php">K-D Tree</a> vÃ  <a href="https://en.wikipedia.org/wiki/Ball_tree">Ball Tree</a>. TÃ´i xin dÃ nh pháº§n nÃ y cho Ä‘á»™c giáº£ tá»± tÃ¬m hiá»ƒu, vÃ  sáº½ quay láº¡i náº¿u cÃ³ dá»‹p. ChÃºng ta váº«n cÃ²n nhá»¯ng thuáº­t toÃ¡n quan trá»ng hÆ¡n khÃ¡c cáº§n nhiá»u sá»± quan tÃ¢m hÆ¡n.</p>

<p><a name="try-this-yourself"></a></p>

<h3 id="try-this-yourself">Try this yourself</h3>

<p>TÃ´i cÃ³ viáº¿t má»™t Ä‘oáº¡n code ngáº¯n Ä‘á»ƒ thá»±c hiá»‡n viá»‡c Classification cho cÆ¡ sá»Ÿ dá»¯ liá»‡u <a href="/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist">MNIST</a>. CÃ¡c báº¡n hÃ£y download toÃ n bá»™ bá»™ dá»¯ liá»‡u nÃ y vá» vÃ¬ sau nÃ y chÃºng ta cÃ²n dÃ¹ng nhiá»u, cháº¡y thá»­, comment káº¿t quáº£ vÃ  nháº­n xÃ©t cá»§a cÃ¡c báº¡n vÃ o pháº§n comment bÃªn dÆ°á»›i. Äá»ƒ tráº£ lá»i cho cÃ¢u há»i vÃ¬ sao tÃ´i khÃ´ng chá»n cÆ¡ sá»Ÿ dá»¯ liá»‡u nÃ y lÃ m vÃ­ dá»¥, báº¡n Ä‘á»c cÃ³ thá»ƒ tá»± tÃ¬m ra Ä‘Ã¡p Ã¡n khi cháº¡y xong Ä‘oáº¡n code nÃ y.</p>

<p>Enjoy!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># %reset
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">from</span> <span class="nn">mnist</span> <span class="kn">import</span> <span class="n">MNIST</span> <span class="c1"># require `pip install python-mnist`
# https://pypi.python.org/pypi/python-mnist/
</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># you need to download the MNIST dataset first
# at: http://yann.lecun.com/exdb/mnist/
</span><span class="n">mndata</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s">'../MNIST/'</span><span class="p">)</span> <span class="c1"># path to your MNIST folder 
</span><span class="n">mndata</span><span class="p">.</span><span class="n">load_testing</span><span class="p">()</span>
<span class="n">mndata</span><span class="p">.</span><span class="n">load_training</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">mndata</span><span class="p">.</span><span class="n">test_images</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">mndata</span><span class="p">.</span><span class="n">train_images</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mndata</span><span class="p">.</span><span class="n">test_labels</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mndata</span><span class="p">.</span><span class="n">train_labels</span><span class="p">)</span>


<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span> <span class="s">"Accuracy of 1NN for MNIST: %.2f %%"</span> <span class="o">%</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="k">print</span> <span class="s">"Running time: %.2f (s)"</span> <span class="o">%</span> <span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>
</code></pre></div></div>

<p><a name="source-code"></a></p>

<h3 id="source-code">Source code</h3>
<p>iPython Notebook cho bÃ i nÃ y cÃ³ thá»ƒ <a href="https://github.com/tiepvupsu/tiepvupsu.github.io/tree/master/assets/knn/KNN.ipynb">download táº¡i Ä‘Ã¢y</a>.</p>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-tÃ i-liá»‡u-tham-kháº£o">5. TÃ i liá»‡u tham kháº£o</h2>

<ol>
  <li>
    <p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors">sklearn.neighbors.NearestNeighbors</a></p>
  </li>
  <li>
    <p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">sklearn.model_selection.train_test_split</a></p>
  </li>
  <li>
    <p><a href="http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/">Tutorial To Implement k-Nearest Neighbors in Python From Scratch</a></p>
  </li>
</ol>
:ET