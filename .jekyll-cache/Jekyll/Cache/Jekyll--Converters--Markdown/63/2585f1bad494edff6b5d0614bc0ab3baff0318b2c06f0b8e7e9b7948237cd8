I"ª<p><strong>Trong trang n√†y:</strong></p>

<!-- MarkdownTOC -->

<ul>
  <li><a href="#-gioi-thieu">1. Gi·ªõi thi·ªáu</a></li>
  <li><a href="#-id">2. ID3</a>
    <ul>
      <li><a href="#-y-tuong">2.1. √ù t∆∞·ªüng</a></li>
      <li><a href="#-ham-so-entropy">2.2. H√†m s·ªë entropy</a></li>
      <li><a href="#-thuat-toan-id">2.3. Thu·∫≠t to√°n ID3</a></li>
      <li><a href="#-vi-du">2.4. V√≠ d·ª•</a></li>
      <li><a href="#-dieu-kien-dung">2.5. ƒêi·ªÅu ki·ªán d·ª´ng</a></li>
      <li><a href="#-pruning">2.6. Pruning</a></li>
    </ul>
  </li>
  <li><a href="#-lap-trinh-python-cho-id">3. L·∫≠p tr√¨nh Python cho ID3</a></li>
  <li><a href="#-thao-luan">4. Th·∫£o lu·∫≠n</a></li>
  <li><a href="#-tai-lieu-tham-khao">5. T√†i li·ªáu tham kh·∫£o</a></li>
</ul>

<!-- /MarkdownTOC -->
<p><a name="-gioi-thieu"></a></p>

<h2 id="1-gi·ªõi-thi·ªáu">1. Gi·ªõi thi·ªáu</h2>
<p>S·∫Øp ƒë·∫øn k·ª≥ thi, m·ªôt c·∫≠u sinh vi√™n t·ª± ƒë·∫∑t ra quy t·∫Øc <em>h·ªçc</em> hay
<em>ch∆°i</em> c·ªßa m√¨nh nh∆∞ sau. N·∫øu c√≤n nhi·ªÅu h∆°n hai ng√†y t·ªõi ng√†y thi, c·∫≠u ra
s·∫Ω ƒëi ch∆°i.
N·∫øu c√≤n kh√¥ng qu√° hai ng√†y v√† ƒë√™m h√¥m ƒë√≥ c√≥ m·ªôt tr·∫≠n b√≥ng ƒë√°, c·∫≠u s·∫Ω sang nh√†
b·∫°n ch∆°i v√† c√πng xem b√≥ng ƒë√™m ƒë√≥. C·∫≠u s·∫Ω ch·ªâ h·ªçc trong c√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i. 
Vi·ªác ra quy·∫øt ƒë·ªãnh c·ªßa c·∫≠u sinh vi√™n n√†y c√≥ th·ªÉ ƒë∆∞·ª£c m√¥ t·∫£ tr√™n s∆° ƒë·ªì trong
H√¨nh 1. H√¨nh ellipse n·ªÅn v√†ng th·ªÉ hi·ªán quy·∫øt ƒë·ªãnh c·∫ßn ƒë∆∞·ª£c ƒë∆∞a
ra. Quy·∫øt ƒë·ªãnh n√†y ph·ª• thu·ªôc v√†o c√°c c√¢u tr·∫£ l·ªùi c·ªßa c√°c c√¢u h·ªèi trong c√°c √¥
h√¨nh ch·ªØ nh·∫≠t m√†u x√°m. D·ª±a tr√™n c√°c c√¢u tr·∫£ l·ªùi, quy·∫øt ƒë·ªãnh cu·ªëi c√πng ƒë∆∞·ª£c cho
trong c√°c h√¨nh tr√≤n m√†u l·ª•c (<em>ch∆°i</em>) v√† ƒë·ªè (<em>h·ªçc</em>).
S∆° ƒë·ªì trong H√¨nh 1 c√≤n ƒë∆∞·ª£c g·ªçi l√† m·ªôt <em>c√¢y quy·∫øt ƒë·ªãnh</em>.</p>

<hr />

<table width="100%" style="border: 0px solid white">
   <tr>
        <td width="40%" style="border: 0px solid white">
        <img style="display:block;" width="100%" src="/assets/34_id3/dt_ex1.png" />
         </td>
        <td width="40%" style="border: 0px solid white">
        H√¨nh 1: V√≠ d·ª• v·ªÅ vi·ªác ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n c√°c c√¢u h·ªèi. 
        </td>
    </tr>
</table>
<hr />

<p>Vi·ªác quan s√°t, suy nghƒ© v√† ra c√°c quy·∫øt ƒë·ªãnh c·ªßa con ng∆∞·ªùi th∆∞·ªùng ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu
t·ª´ c√°c c√¢u h·ªèi. Machine learning c≈©ng c√≥ m·ªôt m√¥ h√¨nh ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n c√°c
c√¢u h·ªèi. M√¥ h√¨nh n√†y c√≥ t√™n l√† <em>c√¢y quy·∫øt ƒë·ªãnh</em> (<em>decision tree</em>).</p>

<p>X√©t v√≠ d·ª• tr√™n H√¨nh 2a v·ªõi hai class m√†u l·ª•c v√† ƒë·ªè tr√™n kh√¥ng
gian hai chi·ªÅu. Nhi·ªám v·ª• l√† ƒëi t√¨m ranh gi·ªõi ƒë∆°n gi·∫£n gi√∫p ph√¢n chia hai class
n√†y. Hay n√≥i c√°ch kh√°c, ƒë√¢y l√† m·ªôt b√†i to√°n classification, ta c·∫ßn x√¢y d·ª±ng m·ªôt
b·ªô ph√¢n l·ªõp ƒë·ªÉ quy·∫øt ƒë·ªãnh vi·ªác m·ªôt ƒëi·ªÉm d·ªØ li·ªáu m·ªõi thu·ªôc v√†o class n√†o. Quan
s√°t h√¨nh ta th·∫•y r·∫±ng ranh gi·ªõi cho hai class trong b√†i to√°n n√†y kh√° ƒë∆°n
gi·∫£n‚Äìch√∫ng l√† c√°c ƒë∆∞·ªùng song song v·ªõi c√°c tr·ª•c to·∫° ƒë·ªô. N·∫øu m·ªôt ƒëi·ªÉm c√≥ th√†nh
ph·∫ßn th·ª© nh·∫•t, \(x_1\), nh·ªè h∆°n ng∆∞·ª°ng \(t_1\), ta quy·∫øt ƒë·ªãnh ngay ƒë∆∞·ª£c r·∫±ng n√≥
thu·ªôc class l·ª•c. Ngo√†i ra, n·∫øu th√†nh ph·∫ßn th·ª© hai, \(x_2\) l·ªõn h∆°n ng∆∞·ª°ng \(t_2\),
ta quy·∫øt ƒë·ªãnh n√≥ c≈©ng thu·ªôc v√†o class l·ª•c. X√©t ti·∫øp, n·∫øu th√†nh ph·∫ßn th·ª© nh·∫•t,
\(x_1\), l·ªõn h∆°n ng∆∞·ª°ng \(t_3\), ta quy·∫øt ƒë·ªãnh n√≥ thu·ªôc v√†o class l·ª•c. C√°c ƒëi·ªÉm
kh√¥ng tho·∫£ m√£n c√°c ƒëi·ªÅu ki·ªán tr√™n ƒë∆∞·ª£c x·∫øp v√†o class ƒë·ªè. Vi·ªác ra quy·∫øt ƒë·ªãnh m·ªôt
ƒëi·ªÉm thu·ªôc class n√†o ƒë∆∞·ª£c m√¥ t·∫£ tr√™n decision tree tr√™n H√¨nh 2b.</p>

<hr />

<div class="imgcap">
<img src="/assets/34_id3/dt_ex2.png" align="center" width="800" />
</div>

<p><br /></p>
<div class="thecap" style="text-align: center">H√¨nh 2: V√≠ d·ª• v·ªÅ b√†i to√°n ph√¢n l·ªõp s·ª≠ d·ª•ng decision tree.</div>
<hr />

<p>Trong decision tree, c√°c √¥ m√†u x√°m, l·ª•c, ƒë·ªè tr√™n H√¨nh 2 ƒë∆∞·ª£c g·ªçi l√† c√°c <em>node</em>.
C√°c <em>node</em> th·ªÉ hi·ªán ƒë·∫ßu ra (m√†u l·ª•c v√† ƒë·ªè) ƒë∆∞·ª£c g·ªçi l√† <em>node l√°</em> (<em>leaf node</em>
ho·∫∑c <em>terminal node</em>). C√°c <em>node</em> th·ªÉ hi·ªán c√¢u h·ªèi l√† c√°c <em>non-leaf node</em>.
<em>Non-leaf node</em> tr√™n c√πng (c√¢u h·ªèi ƒë·∫ßu ti√™n) ƒë∆∞·ª£c g·ªçi l√† <em>node g·ªëc</em> (<em>root
node</em>). C√°c <em>non-leaf node</em> th∆∞·ªùng c√≥ hai ho·∫∑c nhi·ªÅu <em>node con</em> (<em>child node</em>).
C√°c <em>child node</em> n√†y c√≥ th·ªÉ l√† m·ªôt <em>leaf node</em> ho·∫∑c m·ªôt <em>non-leaf node</em> kh√°c.
C√°c <em>child node</em> c√≥ c√πng <em>b·ªë m·∫π</em> ƒë∆∞·ª£c g·ªçi l√† <em>sibling node</em>. N·∫øu t·∫•t c·∫£ c√°c
<em>non-leaf node</em> ch·ªâ c√≥ hai <em>child node</em>, ta n√≥i r·∫±ng ƒë√≥ l√† m·ªôt <em>binary decision
tree</em> (<em>c√¢y quy·∫øt ƒë·ªãnh nh·ªã ph√¢n</em>). C√°c c√¢u h·ªèi trong binary decision tree ƒë·ªÅu c√≥
th·ªÉ ƒë∆∞a ƒë∆∞·ª£c v·ªÅ d·∫°ng c√¢u h·ªèi ƒë√∫ng hay sai. C√°c decision tree m√† m·ªôt <em>leaf
node</em> c√≥ nhi·ªÅu <em>child node</em> c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng m·ªôt binary decision
tree. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c v√¨ h·∫ßu h·∫øt c√°c c√¢u h·ªèi ƒë·ªÅu c√≥ th·ªÉ ƒë∆∞·ª£c ƒë∆∞a v·ªÅ
d·∫°ng c√¢u h·ªèi ƒë√∫ng sai.</p>

<p>V√≠ d·ª•, ta c√≥ th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c tu·ªïi c·ªßa m·ªôt ng∆∞·ªùi d·ª±a tr√™n nhi·ªÅu c√¢u h·ªèi ƒë√∫ng
sai d·∫°ng: tu·ªïi c·ªßa b·∫°n l·ªõn h∆°n \(x\) ƒë√∫ng kh√¥ng? (ƒê√¢y ch√≠nh l√† thu·∫≠t to√°n
<em>t√¨m ki·∫øm nh·ªã ph√¢n</em> ‚Äì <em>binary search</em>.)</p>

<p>Decision tree l√† m·ªôt m√¥ h√¨nh supervised learning, c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng v√†o c·∫£ hai
b√†i to√°n classification v√† regression. Vi·ªác x√¢y d·ª±ng m·ªôt decision tree tr√™n d·ªØ
li·ªáu hu·∫•n luy·ªán cho tr∆∞·ªõc l√† vi·ªác ƒëi x√°c ƒë·ªãnh c√°c <em>c√¢u h·ªèi</em> v√† <em>th·ª© t·ª± c·ªßa
ch√∫ng</em>. M·ªôt ƒëi·ªÉm ƒë√°ng l∆∞u √Ω c·ªßa decision tree l√† n√≥ c√≥ th·ªÉ l√†m vi·ªác v·ªõi c√°c ƒë·∫∑c
tr∆∞ng (trong c√°c t√†i li·ªáu v·ªÅ decision tree, c√°c ƒë·∫∑c tr∆∞ng th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√†
<em>thu·ªôc t√≠nh</em> ‚Äì <em>attribute</em>) d·∫°ng <em>categorical</em>, th∆∞·ªùng l√† r·ªùi r·∫°c v√† kh√¥ng c√≥ th·ª©
t·ª±. V√≠ d·ª•, <em>m∆∞a, n·∫Øng</em> hay <em>xanh, ƒë·ªè</em>, v.v. Decision tree c≈©ng l√†m vi·ªác v·ªõi d·ªØ
li·ªáu c√≥ vector ƒë·∫∑c tr∆∞ng bao g·ªìm c·∫£ thu·ªôc t√≠nh d·∫°ng categorical v√† li√™n t·ª•c
(<em>numeric</em>). M·ªôt ƒëi·ªÉm ƒë√°ng l∆∞u √Ω n·ªØa l√† decision tree √≠t y√™u c·∫ßu vi·ªác chu·∫©n ho√°
d·ªØ li·ªáu.</p>

<p>Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω l√†m quen v·ªõi m·ªôt thu·∫≠t to√°n x√¢y d·ª±ng decision
tree ra ƒë·ªùi t·ª´ r·∫•t s·ªõm v√† r·∫•t ph·ªï bi·∫øn: <a href="https://en.wikipedia.org/wiki/ID3_algorithm">Iterative Dichotomiser 3
(ID3)</a>.</p>

<p>Quay tr·ªü l·∫°i v·ªõi nhi·ªám v·ª• ch√≠nh c·ªßa vi·ªác x√¢y d·ª±ng m·ªôt decision tree: c√°c
<em>c√¢u h·ªèi</em> n√™n ƒë∆∞·ª£c x√¢y d·ª±ng nh∆∞ th·∫ø n√†o, v√† th·ª© t·ª± c·ªßa ch√∫ng ra sao. C√°c
c√¢u h·ªèi n√†y th∆∞·ªùng ƒë∆∞·ª£c √°p d·ª•ng l√™n t·ª´ng thu·ªôc t√≠nh, ho·∫∑c m·ªôt t·ªï h·ª£p tuy·∫øn t√≠nh
c·ªßa c√°c thu·ªôc t√≠nh. C√°ch th·ª© nh·∫•t, √°p d·ª•ng l√™n t·ª´ng thu·ªôc t√≠nh, ƒë∆∞·ª£c s·ª≠ d·ª•ng
nhi·ªÅu h∆°n v√¨ t√≠nh ƒë∆°n gi·∫£n c·ªßa n√≥. V·ªõi c√°c thu·ªôc t√≠nh d·∫°ng categorical, c√¢u h·ªèi
s·∫Ω l√† <em>N√≥ r∆°i v√†o category n√†o?</em> ho·∫∑c <em>N√≥ c√≥ r∆°i v√†o category n√†o ƒë√≥ kh√¥ng?</em>
v·ªõi tr∆∞·ªùng h·ª£p nh·ªã ph√¢n. V·ªõi c√°c thu·ªôc t√≠nh d·∫°ng li√™n t·ª•c, c√¢u h·ªèi c√≥ th·ªÉ l√†
<em>N√≥ n·∫±m v√†o kho·∫£ng gi√° tr·ªã n√†o?</em> ho·∫∑c <em>N√≥ c√≥ l·ªõn h∆°n m·ªôt ng∆∞·ª°ng n√†o ƒë√≥
kh√¥ng?</em>.</p>

<p>ID3 l√† m·ªôt thu·∫≠t to√°n decision tree ƒë∆∞·ª£c √°p d·ª•ng cho c√°c b√†i to√°n classification
m√† t·∫•t c·∫£ c√°c thu·ªôc t√≠nh ƒë·ªÅu ·ªü d·∫°ng categorical. Trong b√†i ti·∫øp theo, ch√∫ng ta
s·∫Ω l√†m quen v·ªõi m·ªôt thu·∫≠t to√°n kh√°c c√≥ t√™n l√† Classification and Regression Tree
(CART)‚Äìc√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng v√†o c·∫£ hai lo·∫°i classification v√† regression, nh∆∞
t√™n g·ªçi c·ªßa n√≥‚Äìl√†m vi·ªác v·ªõi c·∫£ thu·ªôc t√≠nh d·∫°ng categorical v√† li√™n t·ª•c.</p>

<p><a name="-id"></a></p>

<h2 id="2-id3">2. ID3</h2>
<p><a name="-y-tuong"></a></p>

<h3 id="21-√Ω-t∆∞·ªüng">2.1. √ù t∆∞·ªüng</h3>
<p>Trong ID3, ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh th·ª© t·ª± c·ªßa thu·ªôc t√≠nh c·∫ßn ƒë∆∞·ª£c xem x√©t t·∫°i m·ªói
b∆∞·ªõc. V·ªõi c√°c b√†i to√°n c√≥ nhi·ªÅu thu·ªôc t√≠nh v√† m·ªói thu·ªôc t√≠nh c√≥ nhi·ªÅu gi√° tr·ªã
kh√°c nhau, vi·ªác t√¨m ƒë∆∞·ª£c nghi·ªám t·ªëi ∆∞u th∆∞·ªùng l√† kh√¥ng kh·∫£ thi. Thay v√†o ƒë√≥, m·ªôt
ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† t·∫°i m·ªói b∆∞·ªõc, m·ªôt thu·ªôc t√≠nh
<em>t·ªët nh·∫•t</em> s·∫Ω ƒë∆∞·ª£c ch·ªçn ra d·ª±a tr√™n m·ªôt ti√™u chu·∫©n n√†o ƒë√≥ (ch√∫ng ta s·∫Ω
b√†n s·ªõm). V·ªõi m·ªói thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn, ta chia d·ªØ li·ªáu v√†o c√°c <em>child
node</em> t∆∞∆°ng ·ª©ng v·ªõi c√°c gi√° tr·ªã c·ªßa thu·ªôc t√≠nh ƒë√≥ r·ªìi ti·∫øp t·ª•c √°p d·ª•ng ph∆∞∆°ng
ph√°p n√†y cho m·ªói <em>child node</em>. Vi·ªác ch·ªçn ra thu·ªôc t√≠nh <em>t·ªët nh·∫•t</em>
·ªü m·ªói b∆∞·ªõc nh∆∞ th·∫ø n√†y ƒë∆∞·ª£c g·ªçi l√† c√°ch ch·ªçn <em>greedy</em> (<em>tham
lam</em>). C√°ch ch·ªçn n√†y c√≥ th·ªÉ kh√¥ng ph·∫£i l√† t·ªëi ∆∞u, nh∆∞ng tr·ª±c gi√°c cho ch√∫ng ta
th·∫•y r·∫±ng c√°ch l√†m n√†y s·∫Ω g·∫ßn v·ªõi c√°ch l√†m t·ªëi ∆∞u. Ngo√†i ra, c√°ch l√†m n√†y khi·∫øn
cho b√†i to√°n c·∫ßn gi·∫£i quy·∫øt tr·ªü n√™n ƒë∆°n gi·∫£n h∆°n.</p>

<p>Sau m·ªói <em>c√¢u h·ªèi</em>, d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n chia v√†o t·ª´ng <em>child node</em>
t∆∞∆°ng ·ª©ng v·ªõi c√°c c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi ƒë√≥. <em>C√¢u h·ªèi</em> ·ªü ƒë√¢y ch√≠nh l√†
m·ªôt thu·ªôc t√≠nh, c√¢u tr·∫£ l·ªùi ch√≠nh l√† gi√° tr·ªã c·ªßa thu·ªôc t√≠nh ƒë√≥. ƒê·ªÉ ƒë√°nh gi√°
<em>ch·∫•t l∆∞·ª£ng</em> c·ªßa m·ªôt c√°ch ph√¢n chia, ch√∫ng ta c·∫ßn ƒëi t√¨m m·ªôt ph√©p ƒëo.</p>

<p>Tr∆∞·ªõc h·∫øt, th·∫ø n√†o l√† m·ªôt ph√©p ph√¢n chia t·ªët? B·∫±ng tr·ª±c gi√°c, m·ªôt ph√©p ph√¢n chia
l√† t·ªët nh·∫•t n·∫øu d·ªØ li·ªáu trong m·ªói <em>child node</em> ho√†n to√†n thu·ªôc v√†o m·ªôt
class‚Äìkhi ƒë√≥ <em>child node</em> n√†y c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† m·ªôt <em>leaf node</em>, t·ª©c ta kh√¥ng
c·∫ßn ph√¢n chia th√™m n·ªØa. N·∫øu d·ªØ li·ªáu trong c√°c <em>child node</em> v·∫´n l·∫´n v√†o nhau theo
t·ªâ l·ªá l·ªõn, ta coi r·∫±ng ph√©p ph√¢n chia ƒë√≥ ch∆∞a th·ª±c s·ª± t·ªët. T·ª´ nh·∫≠n x√©t n√†y, ta
c·∫ßn c√≥ m·ªôt h√†m s·ªë ƒëo <em>ƒë·ªô tinh khi·∫øt</em> (<em>purity</em>), ho·∫∑c <em>ƒë·ªô v·∫©n ƒë·ª•c</em> (<em>impurity</em>)
c·ªßa m·ªôt ph√©p ph√¢n chia. H√†m s·ªë n√†y s·∫Ω cho gi√° tr·ªã th·∫•p nh·∫•t n·∫øu d·ªØ li·ªáu trong
m·ªói <em>child node</em> n·∫±m trong c√πng m·ªôt class (tinh khi·∫øt nh·∫•t), v√† cho gi√° tr·ªã cao
n·∫øu m·ªói <em>child node</em> c√≥ ch·ª©a d·ªØ li·ªáu thu·ªôc nhi·ªÅu class kh√°c nhau.</p>

<p>M·ªôt h√†m s·ªë c√≥ c√°c ƒë·∫∑c ƒëi·ªÉm n√†y v√† ƒë∆∞·ª£c d√πng nhi·ªÅu trong l√Ω thuy·∫øt th√¥ng tin l√†
h√†m <em>entropy</em>.</p>

<p><a name="-ham-so-entropy"></a></p>

<h3 id="22-h√†m-s·ªë-entropy">2.2. H√†m s·ªë entropy</h3>
<p>Cho m·ªôt ph√¢n ph·ªëi x√°c su·∫•t c·ªßa m·ªôt bi·∫øn r·ªùi r·∫°c \(x\) c√≥ th·ªÉ nh·∫≠n \(n\) gi√° tr·ªã
kh√°c nhau \(x_1, x_2, \dots, x_n\). Gi·∫£ s·ª≠ r·∫±ng x√°c su·∫•t ƒë·ªÉ \(x\) nh·∫≠n c√°c gi√° tr·ªã
n√†y l√† \(p_i = p(x = x_i)\) v·ªõi \(0 \leq p_i \leq 1, \sum_{i=1}^n p_i = 1\). K√Ω hi·ªáu
ph√¢n ph·ªëi n√†y l√† \(\mathbf{p} = (p_1, p_2, \dots, p_n)\). Entropy c·ªßa ph√¢n ph·ªëi n√†y ƒë∆∞·ª£c
ƒë·ªãnh nghƒ©a l√†
\[
    H(\mathbf{p}) = -\sum_{i=1}^n p_i \log(p_i)\quad\quad (1)
\]
trong ƒë√≥ \(\log\) l√† logarit t·ª± nhi√™n (<em>M·ªôt s·ªë t√†i li·ªáu d√πng logarit c∆° s·ªë
2, nh∆∞ng gi√° tr·ªã c·ªßa \(H(\mathbf{p})\) ch·ªâ kh√°c ƒëi b·∫±ng c√°ch nh√¢n v·ªõi m·ªôt h·∫±ng s·ªë.</em>) v√†
quy ∆∞·ªõc \(0 \log(0) = 0\).</p>

<p>X√©t m·ªôt v√≠ d·ª• v·ªõi \(n = 2\) ƒë∆∞·ª£c cho tr√™n H√¨nh 3. Trong tr∆∞·ªùng h·ª£p \(\mathbf{p}\)
l√† <em>tinh khi·∫øt</em> nh·∫•t, t·ª©c m·ªôt trong hai gi√° tr·ªã \(p_i\) b·∫±ng 1, gi√° tr·ªã kia
b·∫±ng 0, entropy c·ªßa ph√¢n ph·ªëi n√†y l√† \(H(\mathbf{p}) = 0\). Khi \(\mathbf{p}\) l√† <em>v·∫©n
ƒë·ª•c</em> nh·∫•t, t·ª©c c·∫£ hai gi√° tr·ªã \(p_i = 0.5\), h√†m entropy ƒë·∫°t gi√° tr·ªã cao nh·∫•t.</p>

<hr />

<table width="100%" style="border: 0px solid white">
   <tr>
        <td width="40%" style="border: 0px solid white">
        <img style="display:block;" width="100%" src="/assets/34_id3/entropy.png" />
         </td>
        <td width="40%" style="border: 0px solid white">
        H√¨nh 3: ƒê·ªì th·ªã c·ªßa h√†m entropy v·ªõi \(n = 2\).
        </td>
    </tr>
</table>
<hr />

<p>T·ªïng qu√°t l√™n v·ªõi \(n &gt; 2\), h√†m entropy ƒë·∫°t gi√° tr·ªã nh·ªè nh·∫•t n·∫øu c√≥ m·ªôt gi√° tr·ªã \(p_i = 1\), ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t n·∫øu t·∫•t c·∫£ c√°c \(p_i\) b·∫±ng nhau ((vi·ªác n√†y c√≥ th·ªÉ ƒë∆∞·ª£c ch·ª©ng minh b·∫±ng <a href="/2017/04/02/duality/#--phuong-phap-nhan-tu-lagrange">ph∆∞∆°ng ph√°p nh√¢n t·ª≠ Lagrange</a>).</p>

<p>Nh·ªØng t√≠nh ch·∫•t n√†y c·ªßa h√†m entropy khi·∫øn n√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong vi·ªác ƒëo
<em>ƒë·ªô v·∫©n ƒë·ª•c</em> c·ªßa m·ªôt ph√©p ph√¢n chia c·ªßa ID3. V√¨ l√Ω do n√†y, ID3 c√≤n ƒë∆∞·ª£c
g·ªçi l√† <em>entropy-based decision tree</em>.</p>

<p><a name="-thuat-toan-id"></a></p>

<h3 id="23-thu·∫≠t-to√°n-id3">2.3. Thu·∫≠t to√°n ID3</h3>
<p>Trong ID3, <em>t·ªïng c√≥ tr·ªçng s·ªë c·ªßa entropy t·∫°i c√°c leaf-node</em> sau khi x√¢y
d·ª±ng decision tree ƒë∆∞·ª£c coi l√† h√†m m·∫•t m√°t c·ªßa decision tree ƒë√≥. C√°c tr·ªçng s·ªë ·ªü
ƒë√¢y t·ªâ l·ªá v·ªõi s·ªë ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n v√†o m·ªói node. C√¥ng vi·ªác c·ªßa ID3 l√† t√¨m
c√°c c√°ch ph√¢n chia h·ª£p l√Ω (th·ª© t·ª± ch·ªçn thu·ªôc t√≠nh h·ª£p l√Ω) sao cho h√†m m·∫•t m√°t
cu·ªëi c√πng ƒë·∫°t gi√° tr·ªã c√†ng nh·ªè c√†ng t·ªët. Nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p, vi·ªác n√†y ƒë·∫°t ƒë∆∞·ª£c b·∫±ng
c√°ch ch·ªçn ra thu·ªôc t√≠nh sao cho n·∫øu d√πng thu·ªôc t√≠nh ƒë√≥ ƒë·ªÉ ph√¢n chia, entropy t·∫°i
m·ªói b∆∞·ªõc gi·∫£m ƒëi m·ªôt l∆∞·ª£ng l·ªõn nh·∫•t. B√†i to√°n x√¢y d·ª±ng m·ªôt decision tree b·∫±ng
ID3 c√≥ th·ªÉ chia th√†nh c√°c b√†i to√°n nh·ªè, trong m·ªói b√†i to√°n, ta ch·ªâ c·∫ßn ch·ªçn ra
thu·ªôc t√≠nh gi√∫p cho vi·ªác ph√¢n chia ƒë·∫°t k·∫øt qu·∫£ t·ªët nh·∫•t. M·ªói b√†i to√°n nh·ªè n√†y
t∆∞∆°ng ·ª©ng v·ªõi vi·ªác ph√¢n chia d·ªØ li·ªáu trong m·ªôt <em>non-leaf node</em>. Ch√∫ng ta
s·∫Ω x√¢y d·ª±ng ph∆∞∆°ng ph√°p t√≠nh to√°n d·ª±a tr√™n m·ªói node n√†y.</p>

<p>X√©t m·ªôt b√†i to√°n v·ªõi \(C\) class kh√°c nhau. Gi·∫£ s·ª≠ ta ƒëang l√†m vi·ªác v·ªõi m·ªôt
<em>non-leaf node</em> v·ªõi c√°c ƒëi·ªÉm d·ªØ li·ªáu t·∫°o th√†nh m·ªôt t·∫≠p \(\mathcal{S}\) v·ªõi s·ªë
ph·∫ßn t·ª≠ l√† \(|\mathcal{S}| = N\). Gi·∫£ s·ª≠ th√™m r·∫±ng trong s·ªë \(N\) ƒëi·ªÉm d·ªØ
li·ªáu n√†y, \(N_c, c= 1, 2, \dots, C\) ƒëi·ªÉm thu·ªôc v√†o class \(c\). X√°c su·∫•t ƒë·ªÉ
m·ªói ƒëi·ªÉm d·ªØ li·ªáu r∆°i v√†o m·ªôt class \(c\) ƒë∆∞·ª£c x·∫•p x·ªâ b·∫±ng \(\frac{N_c}{N}\)
(maximum likelihood estimation). Nh∆∞ v·∫≠y, entropy t·∫°i node n√†y ƒë∆∞·ª£c t√≠nh b·ªüi:
\[ H(\mathcal{S}) = -\sum_{c=1}^C \frac{N_c}{N} \log\left(\frac{N_c}{N}\right) \quad\quad
    (2)
\]
Ti·∫øp theo, gi·∫£ s·ª≠ thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn l√† \(x\). D·ª±a tr√™n \(x\), c√°c ƒëi·ªÉm d·ªØ li·ªáu
trong \(\mathcal{S}\) ƒë∆∞·ª£c ph√¢n ra th√†nh \(K\) child node \(\mathcal{S}_1, \mathcal{S}_2, \dots, \mathcal{S}_K\) v·ªõi s·ªë
ƒëi·ªÉm
trong m·ªói child node l·∫ßn l∆∞·ª£t l√† \(m_1, m_2, \dots, m_K\). Ta ƒë·ªãnh nghƒ©a</p>

<p>\[
    H(x, \mathcal{S}) = \sum_{k=1}^K \frac{m_k}{N} H(\mathcal{S}_k) \quad\quad (3)
\]</p>

<p>l√† t·ªïng c√≥ tr·ªçng s·ªë entroy c·ªßa m·ªói child node‚Äìƒë∆∞·ª£c t√≠nh t∆∞∆°ng t·ª±
nh∆∞ (2). Vi·ªác l·∫•y tr·ªçng s·ªë n√†y l√† quan tr·ªçng v√¨ c√°c
node th∆∞·ªùng c√≥ s·ªë l∆∞·ª£ng ƒëi·ªÉm kh√°c nhau.</p>

<p>Ti·∫øp theo, ta ƒë·ªãnh nghƒ©a <em>information gain</em> d·ª±a tr√™n thu·ªôc t√≠nh \(x\):</p>

<p>\[
    G(x, \mathcal{S}) = H(\mathcal{S}) - H(x, \mathcal{S})
\]</p>

<p>Trong ID3, t·∫°i m·ªói node, thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn ƒë∆∞·ª£c x√°c ƒë·ªãnh d·ª±a tr√™n:</p>

<p>\[
    x^* = \arg\max_{x} G(x, \mathcal{S}) = \arg\min_{x} H(x, \mathcal{S})
\]
t·ª©c thu·ªôc t√≠nh khi·∫øn cho <em>information gain</em> ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t.</p>

<p>C√¢u h·ªèi ti·∫øp theo l√† khi n√†o th√¨ d·ª´ng c√°ch ph√¢n chia? C√¢u tr·∫£
l·ªùi s·∫Ω ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p sau m·ª•c v√≠ d·ª• d∆∞·ªõi ƒë√¢y.</p>

<p><a name="-vi-du"></a></p>

<h3 id="24-v√≠-d·ª•">2.4. V√≠ d·ª•</h3>
<p>ƒê·ªÉ m·ªçi th·ª© ƒë∆∞·ª£c r√µ r√†ng h∆°n, ch√∫ng ta c√πng xem v√≠ d·ª• v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán
ƒë∆∞·ª£c cho trong B·∫£ng d∆∞·ªõi ƒë√¢y. B·∫£ng d·ªØ li·ªáu n√†y ƒë∆∞·ª£c l·∫•y
t·ª´ cu·ªën s√°ch <a href="ftp://ftp.ingv.it/pub/manuela.sbarra/Data%20Mining%20Practical%20Machine%20Learning%20Tools%20and%20Techniques%20-%20WEKA.pdf">Data Mining: Practical Machine Learning Tools and Techniques</a>, trang 11. ƒê√¢y l√† m·ªôt b·∫£ng d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠
d·ª•ng r·∫•t nhi·ªÅu trong c√°c b√†i gi·∫£ng v·ªÅ decision tree. B·∫£ng d·ªØ li·ªáu n√†y m√¥ t·∫£ m·ªëi
quan h·ªá gi·ªØa th·ªùi ti·∫øt trong 14 ng√†y (b·ªën c·ªôt ƒë·∫ßu, kh√¥ng t√≠nh c·ªôt id) v√† vi·ªác m·ªôt ƒë·ªôi b√≥ng c√≥ ch∆°i b√≥ng hay
kh√¥ng (c·ªôt cu·ªëi c√πng). N√≥i c√°ch kh√°c, ta ph·∫£i d·ª± ƒëo√°n gi√° tr·ªã ·ªü c·ªôt cu·ªëi c√πng n·∫øu bi·∫øt gi√° tr·ªã c·ªßa b·ªën c·ªôt c√≤n l·∫°i.</p>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>2</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>3</td>
      <td>overcast</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>4</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>5</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>6</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>7</td>
      <td>overcast</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>8</td>
      <td>sunny</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>9</td>
      <td>sunny</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>10</td>
      <td>rainy</td>
      <td>mild</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>11</td>
      <td>sunny</td>
      <td>mild</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>12</td>
      <td>overcast</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>13</td>
      <td>overcast</td>
      <td>hot</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>14</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
  </tbody>
</table>

<hr />

<p>C√≥ b·ªën thu·ªôc t√≠nh th·ªùi ti·∫øt:</p>

<ol>
  <li>
    <p><em>Outlook</em> nh·∫≠n m·ªôt trong ba gi√° tr·ªã: sunny, overcast, rainy.</p>
  </li>
  <li>
    <p><em>Temperature</em> nh·∫≠n m·ªôt trong ba gi√° tr·ªã: hot, cool, mild.</p>
  </li>
  <li>
    <p><em>Humidity</em> nh·∫≠n m·ªôt trong hai gi√° tr·ªã: high, normal.</p>
  </li>
  <li>
    <p><em>Wind</em> nh·∫≠n m·ªôt trong hai gi√° tr·ªã: weak, strong.</p>
  </li>
</ol>

<p>(T·ªïng c·ªông c√≥ \(3\times 3 \times 2 \times 2 = 36\) lo·∫°i th·ªùi ti·∫øt kh√°c nhau,
trong ƒë√≥ 14 lo·∫°i ƒë∆∞·ª£c th·ªÉ hi·ªán trong b·∫£ng.)</p>

<p>ƒê√¢y c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† m·ªôt b√†i to√°n d·ª± ƒëo√°n li·ªáu ƒë·ªôi b√≥ng c√≥ ch∆°i b√≥ng kh√¥ng
d·ª±a tr√™n c√°c quan s√°t th·ªùi ti·∫øt. ·ªû ƒë√¢y, c√°c quan s√°t ƒë·ªÅu ·ªü d·∫°ng categorical.
C√°ch d·ª± ƒëo√°n d∆∞·ªõi ƒë√¢y t∆∞∆°ng ƒë·ªëi ƒë∆°n gi·∫£n v√† kh√° ch√≠nh x√°c, c√≥ th·ªÉ kh√¥ng ph·∫£i l√†
c√°ch ra quy·∫øt ƒë·ªãnh t·ªët nh·∫•t:</p>
<ul>
  <li>
    <p>N·∫øu <em>outlook = sunny</em> v√† <em>humidity = high</em> th√¨
<em>play = no</em>.</p>
  </li>
  <li>
    <p>N·∫øu <em>outlook = rainy</em> v√† <em>windy = true</em> th√¨
<em>play = no</em>.</p>
  </li>
  <li>
    <p>N·∫øu <em>outlook = overcast</em> th√¨ <em>play = yes</em>.</p>
  </li>
  <li>
    <p>Ngo√†i ra, n·∫øu <em>humidity = normal</em> th√¨ <em>play = yes</em>.</p>
  </li>
  <li>
    <p>Ngo√†i ra, <em>play = yes</em>.</p>
  </li>
</ul>

<p>Ch√∫ng ta s·∫Ω c√πng t√¨m th·ª© t·ª± c√°c thu·ªôc t√≠nh b·∫±ng thu·∫≠t to√°n ID3.</p>

<p>Trong 14 gi√° tr·ªã ƒë·∫ßu ra ·ªü B·∫£ng tr√™n, c√≥ nƒÉm gi√° tr·ªã b·∫±ng <em>no</em> v√† ch√≠n gi√° tr·ªã
b·∫±ng <em>yes</em>. Entroy t·∫°i <em>root node</em> c·ªßa b√†i to√°n l√†:
\[
    H(\mathcal{S}) = - \frac{5}{14}\log\left(\frac{5}{14}\right) - \frac{9}{14}\log\left(\frac{9}{14}\right)
    \approx 0.65 
\]
Ti·∫øp theo, ch√∫ng ta t√≠nh t·ªïng c√≥ tr·ªçng s·ªë entropy c·ªßa c√°c <em>child node</em> n·∫øu ch·ªçn
m·ªôt trong c√°c thu·ªôc t√≠nh <em>outlook, temperature, humidity, wind, play</em> ƒë·ªÉ ph√¢n
chia d·ªØ li·ªáu.</p>

<p>X√©t thu·ªôc t√≠nh <em>outlook</em>. Thu·ªôc t√≠nh n√†y c√≥ th·ªÉ nh·∫≠n m·ªôt trong ba gi√° tr·ªã
<em>sunny, overcast, rainy</em>. M·ªói m·ªôt gi√° tr·ªã s·∫Ω t∆∞∆°ng ·ª©ng v·ªõi m·ªôt
<em>child node</em>. G·ªçi t·∫≠p h·ª£p c√°c ƒëi·ªÉm trong m·ªói child node n√†y l·∫ßn l∆∞·ª£t l√†
\(\mathcal{S}_s, \mathcal{S}_o, \mathcal{S}_r\) v·ªõi t∆∞∆°ng ·ª©ng \(m_s, m_o,
m_r\) ph·∫ßn t·ª≠. S·∫Øp x·∫øp l·∫°i B·∫£ng ban ƒë·∫ßu theo thu·ªôc t√≠nh outlook ta ƒë·∫°t ƒë∆∞·ª£c ba
B·∫£ng nh·ªè sau ƒë√¢y.</p>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>2</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>8</td>
      <td>sunny</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>9</td>
      <td>sunny</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>11</td>
      <td>sunny</td>
      <td>mild</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3</td>
      <td>overcast</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>7</td>
      <td>overcast</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>12</td>
      <td>overcast</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>13</td>
      <td>overcast</td>
      <td>hot</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>4</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>5</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>6</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>10</td>
      <td>rainy</td>
      <td>mild</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>14</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
  </tbody>
</table>

<hr />

<p>Quan s√°t nhanh ta th·∫•y r·∫±ng <em>child node</em> ·ª©ng v·ªõi <em>outlook = overcast</em> s·∫Ω c√≥
entropy b·∫±ng 0 v√¨ t·∫•t c·∫£ \(m_o = 4\) output ƒë·ªÅu l√† <em>yes</em>. Hai <em>child node</em> c√≤n
l·∫°i v·ªõi \(m_s = m_r = 5\) c√≥ entropy kh√° cao v√¨ t·∫ßn su·∫•t output b·∫±ng <em>yes</em>
ho·∫∑c <em>no</em> l√† x·∫•p x·ªâ nhau. Tuy nhi√™n, hai <em>child node</em> n√†y c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n chia
ti·∫øp d·ª±a tr√™n hai thu·ªôc t√≠nh <em>humidity</em> v√† <em>wind</em>.</p>

<p>B·∫°n ƒë·ªçc c√≥ th·ªÉ ki·ªÉm tra ƒë∆∞·ª£c r·∫±ng
\[ 
\begin{eqnarray}
    H(\mathcal{S}_s) &amp;=&amp;-\frac{2}{5}\log\left(\frac{2}{5}\right) - \frac{3}{5}\log\left(\frac{3}{5}\right)
            \approx 0.673 \\ 
    H(\mathcal{S}_o) &amp;=&amp; 0  \\ 
    H(\mathcal{S}_r) &amp;=&amp; -\frac{3}{5}\log\left(\frac{2}{5}\right) - \frac{3}{5}\log\left(\frac{3}{5}\right) 
    \approx 0.673 \\ 
    H({outlook}, \mathcal{S}) &amp;=&amp; \frac{5}{14}H(\mathcal{S}_s) + \frac{4}{14}H(\mathcal{S}_o) +
    \frac{5}{14}H(\mathcal{S}_r) \approx 0.48
 \end{eqnarray}
\]</p>

<p>X√©t thu·ªôc t√≠nh <em>temperature</em>, ta c√≥ ph√¢n chia nh∆∞ c√°c B·∫£ng d∆∞·ªõi ƒë√¢y.</p>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>2</td>
      <td>sunny</td>
      <td>hot</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>3</td>
      <td>overcast</td>
      <td>hot</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>13</td>
      <td>overcast</td>
      <td>hot</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>4</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>8</td>
      <td>sunny</td>
      <td>mild</td>
      <td>high</td>
      <td>weak</td>
      <td>no</td>
    </tr>
    <tr>
      <td>10</td>
      <td>rainy</td>
      <td>mild</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>11</td>
      <td>sunny</td>
      <td>mild</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>12</td>
      <td>overcast</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>14</td>
      <td>rainy</td>
      <td>mild</td>
      <td>high</td>
      <td>strong</td>
      <td>no</td>
    </tr>
  </tbody>
</table>

<hr />

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>outlook</th>
      <th>temperature</th>
      <th>humidity</th>
      <th>wind</th>
      <th>play</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>6</td>
      <td>rainy</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>no</td>
    </tr>
    <tr>
      <td>7</td>
      <td>overcast</td>
      <td>cool</td>
      <td>normal</td>
      <td>strong</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>9</td>
      <td>sunny</td>
      <td>cool</td>
      <td>normal</td>
      <td>weak</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<hr />

<p>G·ªçi \(\mathcal{S}_h, \mathcal{S}_m, \mathcal{S}_c\) l√† ba t·∫≠p con t∆∞∆°ng ·ª©ng v·ªõi <em>temperature</em> b·∫±ng <em>hot, mild, cool</em>. B·∫°n ƒë·ªçc c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c
\[
\begin{eqnarray}
    H(\mathcal{S}_h) &amp;=&amp; -\frac{2}{4}\log\left(\frac{2}{4}\right)-\frac{2}{4}\log\left(\frac{2}{4}\right)
    \approx 0.693 \\ 
    H(\mathcal{S}_m) &amp;=&amp; - \frac{4}{6}\log\left(\frac{4}{6}\right) - \frac{2}{6}\log\left(\frac{2}{6}\right)
    \approx 0.637 \\ 
    H(\mathcal{S}_c) &amp;=&amp; - \frac{3}{4}\log\left(\frac{3}{4}\right) - \frac{1}{4}\log\left(\frac{1}{4}\right)
    \approx 0.562 \\ 
    H(temperature, \mathcal{S}) &amp;=&amp; \frac{4}{14}H(\mathcal{S}_h) + \frac{6}{14}H(\mathcal{S}_m) +
    \frac{4}{14}H(\mathcal{S}_c) \approx 0.631
\end{eqnarray}
\]</p>

<p>Vi·ªác t√≠nh to√°n v·ªõi hai thu·ªôc t√≠nh c√≤n l·∫°i ƒë∆∞·ª£c d√†nh cho b·∫°n ƒë·ªçc. N·∫øu c√°c k·∫øt
qu·∫£ l√† gi·ªëng nhau, ch√∫ng s·∫Ω b·∫±ng: 
\[
    H(humidity, \mathcal{S}) \approx 0.547, \quad H(wind, \mathcal{S}) \approx 0.618
\]
Nh∆∞ v·∫≠y, thu·ªôc t√≠nh c·∫ßn ch·ªçn ·ªü b∆∞·ªõc ƒë·∫ßu ti√™n l√† <em>outlook</em> v√¨
\(H(outlook, \mathcal{S})\) ƒë·∫°t gi√° tr·ªã nh·ªè nh·∫•t (information gain l√† l·ªõn nh·∫•t).</p>

<p>Sau b∆∞·ªõc ph√¢n chia ƒë·∫ßu ti√™n n√†y, ta nh·∫≠n ƒë∆∞·ª£c ba child node v·ªõi c√°c ph·∫ßn t·ª≠ nh∆∞
trong ba B·∫£ng ph√¢n chia theo <em>outlook</em>. Child node th·ª© hai kh√¥ng c·∫ßn ph√¢n chia ti·∫øp v√¨ n√≥
ƒë√£ <em>tinh khi·∫øt</em>. V·ªõi child node th·ª© nh·∫•t, ·ª©ng v·ªõi <em>outlook =
sunny</em>, k·∫øt qu·∫£ t√≠nh ƒë∆∞·ª£c b·∫±ng ID3 s·∫Ω cho ch√∫ng ta thu·ªôc t√≠nh <em>humidity</em>
v√¨ t·ªïng tr·ªçng s·ªë c·ªßa entropy sau b∆∞·ªõc n√†y s·∫Ω b·∫±ng 0 v·ªõi output b·∫±ng <em>yes</em>
khi v√† ch·ªâ khi <em>humidity = normal</em>. T∆∞∆°ng t·ª±, child node ·ª©ng v·ªõi
<em>outlook = wind</em> s·∫Ω ƒë∆∞·ª£c ti·∫øp t·ª•c ph√¢n chia b·ªüi thu·ªôc t√≠nh <em>wind</em>
v·ªõi output b·∫±ng <em>yes</em> khi v√† ch·ªâ khi <em>wind = weak</em>.</p>

<p>Nh∆∞ v·∫≠y, c√¢y quy·∫øt ƒë·ªãnh cho b√†i to√°n n√†y d·ª±a tr√™n ID3 s·∫Ω c√≥ d·∫°ng nh∆∞ trong
H√¨nh 4.</p>

<hr />

<table width="100%" style="border: 0px solid white">
   <tr>
        <td width="40%" style="border: 0px solid white">
        <img style="display:block;" width="100%" src="/assets/34_id3/dt_res.png" />
         </td>
        <td width="40%" style="border: 0px solid white">
        H√¨nh 4: Decision tree cho b√†i to√°n v√≠ d·ª• s·ª≠ d·ª•ng thu·∫≠t to√°n ID3. 
        </td>
    </tr>
</table>
<hr />

<p><a name="-dieu-kien-dung"></a></p>

<h3 id="25-ƒëi·ªÅu-ki·ªán-d·ª´ng">2.5. ƒêi·ªÅu ki·ªán d·ª´ng</h3>

<p>Trong c√°c thu·∫≠t to√°n decision tree n√≥i chung v√† ID3 n√≥i ri√™ng, n·∫øu ta ti·∫øp t·ª•c
ph√¢n chia c√°c node <em>ch∆∞a tinh khi·∫øt</em>, ta s·∫Ω thu ƒë∆∞·ª£c m·ªôt tree m√† m·ªçi ƒëi·ªÉm
trong t·∫≠p hu·∫•n luy·ªán ƒë·ªÅu ƒë∆∞·ª£c d·ª± ƒëo√°n ƒë√∫ng (gi·∫£ s·ª≠ r·∫±ng kh√¥ng c√≥ hai input gi·ªëng
nhau n√†o cho output kh√°c nhau). Khi ƒë√≥, tree c√≥ th·ªÉ s·∫Ω r·∫•t ph·ª©c t·∫°p (nhi·ªÅu node)
v·ªõi nhi·ªÅu leaf node ch·ªâ c√≥ m·ªôt v√†i ƒëi·ªÉm d·ªØ li·ªáu. Nh∆∞ v·∫≠y, nhi·ªÅu kh·∫£ nƒÉng
overfitting s·∫Ω x·∫£y ra.</p>

<p>ƒê·ªÉ tr√°nh overfitting, m·ªôt trong s·ªë c√°c ph∆∞∆°ng ph√°p sau c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng. T·∫°i m·ªôt node,
n·∫øu m·ªôt trong s·ªë c√°c ƒëi·ªÅu ki·ªán sau ƒë√¢y x·∫£y ra, ta kh√¥ng ti·∫øp t·ª•c ph√¢n chia node ƒë√≥ v√† coi n√≥
l√† m·ªôt leaf node:</p>

<ul>
  <li>
    <p>n·∫øu node ƒë√≥ c√≥ entropy b·∫±ng 0, t·ª©c m·ªçi ƒëi·ªÉm trong node ƒë·ªÅu thu·ªôc m·ªôt
  class.</p>
  </li>
  <li>
    <p>n·∫øu node ƒë√≥ c√≥ s·ªë ph·∫ßn t·ª≠ nh·ªè h∆°n m·ªôt ng∆∞·ª°ng n√†o ƒë√≥. Trong tr∆∞·ªùng
  h·ª£p n√†y, ta ch·∫•p nh·∫≠n c√≥ m·ªôt s·ªë ƒëi·ªÉm b·ªã ph√¢n l·ªõp sai ƒë·ªÉ tr√°nh overfitting.
  Class cho leaf node n√†y c√≥ th·ªÉ ƒë∆∞·ª£c x√°c ƒë·ªãnh d·ª±a tr√™n class chi·∫øm ƒëa s·ªë
  trong node.</p>
  </li>
  <li>
    <p>n·∫øu kho·∫£ng c√°ch t·ª´ node ƒë√≥ ƒë·∫øn root node ƒë·∫°t t·ªõi m·ªôt gi√° tr·ªã n√†o ƒë√≥.
  Vi·ªác h·∫°n ch·∫ø <em>chi·ªÅu s√¢u c·ªßa tree</em> n√†y l√†m gi·∫£m ƒë·ªô ph·ª©c t·∫°p c·ªßa tree v√† ph·∫ßn n√†o gi√∫p tr√°nh overfitting.</p>
  </li>
  <li>
    <p>n·∫øu t·ªïng s·ªë leaf node v∆∞·ª£t qu√° m·ªôt ng∆∞·ª°ng n√†o ƒë√≥.</p>
  </li>
  <li>
    <p>n·∫øu vi·ªác ph√¢n chia node ƒë√≥ kh√¥ng l√†m gi·∫£m entropy qu√° nhi·ªÅu
  (information gain nh·ªè h∆°n m·ªôt ng∆∞·ª°ng n√†o ƒë√≥).</p>
  </li>
</ul>

<p>Ngo√†i c√°c ph∆∞∆°ng ph√°p tr√™n, m·ªôt ph∆∞∆°ng ph√°p ph·ªï bi·∫øn kh√°c ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh
overfitting l√† <em>pruning</em>, t·∫°m d·ªãch l√† <em>c·∫Øt t·ªâa</em>.</p>

<p><a name="-pruning"></a></p>

<h3 id="26-pruning">2.6. Pruning</h3>
<p>Pruning l√† m·ªôt k·ªπ thu·∫≠t regularization ƒë·ªÉ tr√°nh overfitting cho decision tree
n√≥i chung. Trong pruning, m·ªôt decision tree s·∫Ω ƒë∆∞·ª£c x√¢y d·ª±ng t·ªõi khi m·ªçi ƒëi·ªÉm
trong training set ƒë·ªÅu ƒë∆∞·ª£c ph√¢n l·ªõp ƒë√∫ng. Sau ƒë√≥, c√°c leaf node c√≥ chung m·ªôt
non-leaf node s·∫Ω ƒë∆∞·ª£c <em>c·∫Øt t·ªâa</em> v√† non-leaf node ƒë√≥ tr·ªü th√†nh m·ªôt
leaf-node, v·ªõi class t∆∞∆°ng ·ª©ng v·ªõi class chi·∫øm ƒëa s·ªë trong s·ªë m·ªçi ƒëi·ªÉm ƒë∆∞·ª£c
ph√¢n v√†o node ƒë√≥. Vi·ªác c·∫Øt t·ªâa c√¢y quy·∫øt ƒë·ªãnh n√†y c√≥ th·ªÉ ƒë∆∞·ª£c x√°c ƒë·ªãnh d·ª±a
v√†o c√°c c√°ch sau.</p>
<ol>
  <li>
    <p>D·ª±a v√†o m·ªôt validation set. Tr∆∞·ªõc ti√™n, training set ƒë∆∞·ª£c t√°ch ra
th√†nh m·ªôt training set nh·ªè h∆°n v√† m·ªôt validation set. Decision tree ƒë∆∞·ª£c
x√¢y d·ª±ng tr√™n training set cho t·ªõi khi m·ªçi ƒëi·ªÉm trong training set ƒë∆∞·ª£c
ph√¢n l·ªõp ƒë√∫ng. Sau ƒë√≥, ƒëi ng∆∞·ª£c t·ª´ c√°c leaf node, c·∫Øt t·ªâa c√°c sibling node
c·ªßa n√≥ v√† gi·ªØ l·∫°i node <em>b·ªë m·∫π</em> n·∫øu ƒë·ªô ch√≠nh x√°c tr√™n validation set
ƒë∆∞·ª£c c·∫£i thi·ªán. Khi n√†o ƒë·ªô ch√≠nh x√°c tr√™n validation set kh√¥ng ƒë∆∞·ª£c c·∫£i
thi·ªán n·ªØa, qu√° tr√¨nh pruning d·ª´ng l·∫°i. Ph∆∞∆°ng ph√°p n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√†
<em>reduced error pruning</em>.</p>
  </li>
  <li>
    <p>D·ª±a v√†o to√†n b·ªô data set. Trong ph∆∞∆°ng ph√°p n√†y, ta kh√¥ng t√°ch t·∫≠p
training ban ƒë·∫ßu ra m√† s·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu trong t·∫≠p n√†y cho vi·ªác x√¢y
d·ª±ng decision tree. M·ªôt v√≠ d·ª• cho vi·ªác n√†y l√† c·ªông th√™m m·ªôt ƒë·∫°i l∆∞·ª£ng
regularization v√†o h√†m m·∫•t m√°t. ƒê·∫°i l∆∞·ª£ng regularization s·∫Ω l·ªõn n·∫øu s·ªë leaf
node l√† l·ªõn. C·ª• th·ªÉ, gi·∫£ s·ª≠ decision tree cu·ªëi c√πng c√≥ \(K\) leaf node, t·∫≠p
h·ª£p c√°c ƒëi·ªÉm hu·∫•n luy·ªán r∆°i v√†o m·ªói leaf node l·∫ßn l∆∞·ª£t l√† \(\mathcal{S}_1, \dots,
\mathcal{S}_K\). Khi ƒë√≥, regularized loss c·ªßa ID3 c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh t∆∞∆°ng t·ª±
nh∆∞ (3):
\[
 \mathcal{L} = \sum_{k = 1}^K \frac{|\mathcal{S}_k|}{|\mathcal{S}|}
 H(\mathcal{S}_k) + \lambda K \quad\quad (5)
\]
v·ªõi \(|\mathcal{S}_k|\) k√Ω hi·ªáu s·ªë ph·∫ßn t·ª≠ c·ªßa t·∫≠p h·ª£p \(\mathcal{S}_k\) v√† \(H(\mathcal{S}_k)\) ch√≠nh l√†
entropy c·ªßa leaf node t∆∞∆°ng ·ª©ng v·ªõi \(\mathcal{S}_k\), ƒë∆∞·ª£c t√≠nh t∆∞∆°ng t·ª±
nh∆∞ (2), v√† \(\lambda\) l√† m·ªôt s·ªë th·ª±c d∆∞∆°ng kh√¥ng
qu√° l·ªõn. Gi√° tr·ªã c·ªßa h√†m s·ªë n√†y nh·ªè n·∫øu c·∫£ data loss‚Äìs·ªë h·∫°ng th·ª© nh·∫•t‚Äình·ªè (entropy t·∫°i m·ªói
node l√† th·∫•p) v√† regularization‚Äìs·ªë h·∫°ng th·ª© hai‚Äìc≈©ng nh·ªè (s·ªë leaf node l√† √≠t).
V√¨ h√†m m·∫•t m√°t trong (5) l√† m·ªôt h√†m r·ªùi r·∫°c, r·∫•t kh√≥ ƒë·ªÉ
tr·ª±c ti·∫øp t·ªëi ∆∞u h√†m n√†y. Vi·ªác t·ªëi ∆∞u c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán th√¥ng qua
pruning nh∆∞ sau. Tr∆∞·ªõc h·∫øt, x√¢y d·ª±ng m·ªôt decision tree m√† m·ªçi ƒëi·ªÉm trong t·∫≠p
hu·∫•n luy·ªán ƒë·ªÅu ƒë∆∞·ª£c ph√¢n lo·∫°i ƒë√∫ng (to√†n b·ªô c√°c entopy c·ªßa c√°c node b·∫±ng 0).
L√∫c n√†y data loss b·∫±ng 0 nh∆∞ng regularization c√≥ th·ªÉ l·ªõn, khi·∫øn cho
\(\mathcal{L}\) l·ªõn. 
Sau ƒë√≥, ta c√≥ th·ªÉ <em>t·ªâa</em> d·∫ßn c√°c leaf node sao cho \(\mathcal{L}\) gi·∫£m.
Vi·ªác c·∫Øt t·ªâa ƒë∆∞·ª£c l·∫∑p l·∫°i ƒë·∫øn khi \(\mathcal{L}\) kh√¥ng th·ªÉ gi·∫£m ƒë∆∞·ª£c n·ªØa.</p>
  </li>
  <li>
    <p>C√°c k·ªπ thu·∫≠t pruning kh√°c c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y <a href="https://link.springer.com/article/10.1023/A:1022604100933">t·∫°i ƒë√¢y</a>.</p>
  </li>
</ol>

<p><a name="-lap-trinh-python-cho-id"></a></p>

<h2 id="3-l·∫≠p-tr√¨nh-python-cho-id3">3. L·∫≠p tr√¨nh Python cho ID3</h2>

<p>Module DecisionTree trong sklearn kh√¥ng th·ª±c hi·ªán thu·∫≠t to√°n ID3 m√† l√† m·ªôt
thu·∫≠t to√°n kh√°c ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong b√†i ti·∫øp theo. Phi√™n b·∫£n hi·ªán t·∫°i trong
sklearn ch∆∞a h·ªó tr·ª£ c√°c thu·ªôc t√≠nh ·ªü d·∫°ng categorical. V·ªõi d·ªØ li·ªáu c√≥ thu·ªôc
t√≠nh categorical, c√°ch th∆∞·ªùng d√πng l√† chuy·ªÉn ƒë·ªïi c√°c thu·ªôc t√≠nh ƒë√≥ sang d·∫°ng
numerical (1, 2, 3 cho m·ªói gi√° tr·ªã). Ch·∫≥ng h·∫°n, c√°c gi√° tr·ªã <em>hot, mild,
cool</em> c√≥ th·ªÉ l·∫ßn l∆∞·ª£t ƒë∆∞·ª£c thay b·∫±ng <em>1, 2, 3</em>. C√°ch l√†m  n√†y c√≥ h·∫°n ch·∫ø
v√¨ trong c√°ch chuy·ªÉn ƒë·ªïi n√†y, <em>mild</em> l√† trung b√¨nh c·ªông c·ªßa <em>hot</em>
v√† <em>cool</em>, nh∆∞ng n·∫øu th·ª© t·ª± c√°c gi√° tr·ªã ƒë∆∞·ª£c ƒë·∫∑t kh√°c ƒëi, vi·ªác chuy·ªÉn
ƒë·ªïi c√≥ th·ªÉ ·∫£nh h∆∞·ªüng l·ªõn t·ªõi k·∫øt qu·∫£. Nh·∫Øc l·∫°i r·∫±ng c√°c thu·ªôc t√≠nh
categorical, v√≠ d·ª• m√†u s·∫Øc, th∆∞·ªùng kh√¥ng c√≥ t√≠nh th·ª© t·ª±.</p>

<p>D∆∞·ªõi ƒë√¢y l√† c√°ch l·∫≠p tr√¨nh c·ªßa t√¥i cho ID3, l√†m vi·ªác v·ªõi c·∫£ d·ªØ li·ªáu ·ªü d·∫°ng
categorical. (Source code c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y <a href="https://goo.gl/Kz6S9E">t·∫°i ƒë√¢y</a>)</p>

<p><strong>X√¢y d·ª±ng <code class="language-plaintext highlighter-rouge">class TreeNode</code></strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span> 
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> 

<span class="k">class</span> <span class="nc">TreeNode</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">children</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">entropy</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ids</span> <span class="o">=</span> <span class="n">ids</span>           <span class="c1"># index of data in this node
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">entropy</span> <span class="o">=</span> <span class="n">entropy</span>   <span class="c1"># entropy, will fill later
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>       <span class="c1"># distance to root node
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">split_attribute</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># which attribute is chosen, it non-leaf
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">children</span> <span class="o">=</span> <span class="n">children</span> <span class="c1"># list of its child nodes
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="bp">None</span>       <span class="c1"># order of values of split_attribute in children
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">label</span> <span class="o">=</span> <span class="bp">None</span>       <span class="c1"># label of node if it is a leaf
</span>
    <span class="k">def</span> <span class="nf">set_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split_attribute</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">split_attribute</span> <span class="o">=</span> <span class="n">split_attribute</span> <span class="c1"># split at which attribute
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">order</span> <span class="c1"># order of this node's children 
</span>
    <span class="k">def</span> <span class="nf">set_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">label</span> <span class="c1"># set label if the node is a leaf 
</span></code></pre></div></div>

<p><strong>H√†m t√≠nh entropy d·ª±a tr√™n t·∫ßn su·∫•t</strong></p>

<p>Trong h√†m n√†y, ch√∫ng ta ph·∫£i ch√∫ √Ω b·ªè c√°c t·∫ßn su·∫•t b·∫±ng 0 ƒëi v√¨ logarit t·∫°i ƒë√¢y
kh√¥ng x√°c ƒë·ªãnh.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">freq</span><span class="p">):</span>
    <span class="c1"># remove prob 0 
</span>    <span class="n">freq_0</span> <span class="o">=</span> <span class="n">freq</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">freq</span><span class="p">).</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">prob_0</span> <span class="o">=</span> <span class="n">freq_0</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">freq_0</span><span class="p">.</span><span class="nb">sum</span><span class="p">())</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">prob_0</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">prob_0</span><span class="p">))</span>
</code></pre></div></div>

<p>Ph·∫ßn c√≤n l·∫°i c·ªßa source code (bao g·ªìm <code class="language-plaintext highlighter-rouge">class DecisionTreeID3</code>) c√≥
th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y <a href="https://goo.gl/Kz6S9E">t·∫°i ƒë√¢y</a>.</p>

<p>D·ªØ li·ªáu trong trong v√≠ d·ª• ƒë∆∞·ª£c ƒë∆∞·ª£c l∆∞u trong file
<a href="https://github.com/tiepvupsu/DecisionTreeID3/blob/master/weather.csv"><code class="language-plaintext highlighter-rouge">weather.csv</code></a>. Vi·ªác hu·∫•n luy·ªán decision tree d·ª±a tr√™n ID3 cho t·∫≠p
d·ªØ li·ªáu n√†y v√† ƒë·∫ßu ra d·ª± ƒëo√°n cho training set ƒë∆∞·ª£c cho b·ªüi</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_csv</span><span class="p">(</span><span class="s">'weather.csv'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeID3</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</code></pre></div></div>

<p><em>K·∫øt qu·∫£</em></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']
</code></pre></div></div>

<p>Kh√¥ng c√≥ g√¨ b·∫•t ng·ªù, decision tree d·ª± ƒëo√°n ƒë√∫ng 100% c√°c ƒëi·ªÉm trong training
set.</p>

<p><a name="-thao-luan"></a></p>

<h2 id="4-th·∫£o-lu·∫≠n">4. Th·∫£o lu·∫≠n</h2>
<ol>
  <li>
    <p>N·∫øu m·ªôt thu·ªôc t√≠nh c√≥ th·ªÉ nh·∫≠n r·∫•t nhi·ªÅu gi√° tr·ªã, decision tree thu
ƒë∆∞·ª£c c√≥ th·ªÉ s·∫Ω c√≥ r·∫•t nhi·ªÅu node. X√©t m·ªôt v√≠ d·ª• v·ªÅ c√°c tri·ªáu ch·ª©ng c·ªßa c√°c
b·ªánh nh√¢n trong m·ªôt b·ªánh vi·ªán v√† ƒë·∫ßu ra l√† m·∫Øc b·ªánh hay kh√¥ng. M·ªói b·ªánh nh√¢n
c√≥ m·ªôt m√£ s·ªë (id) kh√°c nhau. N·∫øu ta s·ª≠ d·ª•ng thu·ªôc t√≠nh n√†y cho vi·ªác hu·∫•n
luy·ªán, ta r·∫•t c√≥ th·ªÉ s·∫Ω thu ƒë∆∞·ª£c m·ªô decision tree m√† m·ªói leaf node ·ª©ng v·ªõi
m·ªôt b·ªánh nh√¢n. L√∫c ƒë√≥ m√¥ h√¨nh n√†y l√† v√¥ d·ª•ng, v√¨ kh√¥ng th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c vi·ªác
m·∫Øc b·ªánh hay kh√¥ng c·ªßa m·ªôt b·ªánh nh√¢n m·ªõi.</p>
  </li>
  <li>
    <p>Khi m·ªôt thu·ªôc t√≠nh nh·∫≠n gi√° tr·ªã li√™n t·ª•c, ch·∫≥ng h·∫°n
<em>temperature</em> kh√¥ng c√≤n l√† <em>hot, mild, cool</em> n·ªØa m√† l√† c√°c
gi√° tr·ªã th·ª±c li√™n t·ª•c, v·∫´n c√≥ m·ªôt c√°ch ƒë·ªÉ √°p d·ª•ng ID3. Ta c√≥ th·ªÉ chia
kho·∫£ng gi√° tr·ªã c·ªßa thu·ªôc t√≠nh n√†y th√†nh nhi·ªÅu ph·∫ßn, m·ªói ph·∫ßn c√≥ s·ªë l∆∞·ª£ng
ƒëi·ªÉm t∆∞∆°ng ƒë∆∞∆°ng, ho·∫∑c c≈©ng c√≥ th·ªÉ d√πng c√°c thu·∫≠t to√°n clustering ƒë∆°n gi·∫£n
cho m·ªôt chi·ªÅu d·ªØ li·ªáu ƒë·ªÉ chia thu·ªôc t√≠nh th√†nh c√°c cluster nh·ªè. L√∫c n√†y,
thu·ªôc t√≠nh li√™n t·ª•c ƒë∆∞·ª£c chuy·ªÉn v·ªÅ thu·ªôc t√≠nh d·∫°ng categorical.</p>
  </li>
  <li>
    <p>H·∫°n ch·∫ø l·ªõn nh·∫•t c·ªßa ID3 v√† decision tree n√≥i chung l√† vi·ªác n·∫øu m·ªôt
ƒëi·ªÉm d·ªØ li·ªáu m·ªõi r∆°i v√†o <em>nh·∫ßm</em> nh√°nh ·ªü ngay nh·ªØng l·∫ßn ph√¢n chia ƒë·∫ßu
ti√™n, k·∫øt qu·∫£ cu·ªëi c√πng s·∫Ω kh√°c ƒëi r·∫•t nhi·ªÅu. Vi·ªác r∆°i v√†o nh·∫ßm nh√°nh n√†y
r·∫•t d·ªÖ x·∫£y ra trong tr∆∞·ªùng h·ª£p thu·ªôc t√≠nh li√™n t·ª•c ƒë∆∞·ª£c chia th√†nh nhi·ªÅu
nh√≥m nh·ªè, v√¨ hai ƒëi·ªÉm c√≥ thu·ªôc t√≠nh t∆∞∆°ng ·ª©ng r·∫•t g·∫ßn nhau c√≥ th·ªÉ r∆°i v√†o
hai nh√≥m kh√°c nhau.</p>
  </li>
</ol>

<p><a name="-tai-lieu-tham-khao"></a></p>

<h2 id="5-t√†i-li·ªáu-tham-kh·∫£o">5. T√†i li·ªáu tham kh·∫£o</h2>

<p>[1] <a href="http://web.info.uvt.ro/~dzaharie/dm2016/projects/DecisionTrees/DecisionTrees_ID3Tutorial.pdf">CSE5230 Tutorial: The ID3 Decision Tree Algorithm</a>.</p>

<p>[2] <a href="http://shop.oreilly.com/product/0636920052289.do">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a></p>

:ET